from __future__ import annotations
from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Dict, Any, Optional, Union, Literal
from pathlib import Path
import os
import json
import pymysql
import requests
from requests import Session
import yaml
from datetime import datetime
import frontmatter
import re
import subprocess

# æ–‡æ¡£æ ¹ç›®å½•å®šä½ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ DOCS_PROJECT_ROOTï¼Œå…¶æ¬¡ä½¿ç”¨è¿›ç¨‹å¯åŠ¨æ—¶çš„å·¥ä½œç›®å½•
# è¿™æ ·å¯å°†è¾“å‡ºå†™å…¥â€œè°ƒç”¨æ–¹é¡¹ç›®â€çš„ Docs ç›®å½•ï¼Œè€Œä¸æ˜¯ MCP è‡ªèº«ä»“åº“
PROJECT_ROOT = Path(os.getenv("DOCS_PROJECT_ROOT") or os.getcwd()).resolve()
DOCS_ROOT = PROJECT_ROOT / "Docs"
TASKS_DIR = DOCS_ROOT / ".tasks"
PROCESS_DIR = DOCS_ROOT / "ProcessDocuments"

# å†…ç½®å®ç°ï¼Œæ— éœ€å¤–éƒ¨MCPè·¯å¾„

app = FastMCP("devflow-mcp")

# ---------- Models (Inputs/Outputs) ----------
class PrepareDocsInput(BaseModel):
    """å‡†å¤‡ä»»åŠ¡ä¸»æ–‡æ¡£ä¸è¿‡ç¨‹æ–‡æ¡£çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="PrepareDocsInput", description="å‡†å¤‡ä»»åŠ¡ä¸»æ–‡æ¡£ä¸è¿‡ç¨‹æ–‡æ¡£çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†ï¼Œä¾‹å¦‚ PROJ-123")
    title: str = Field(..., description="ä»»åŠ¡æ ‡é¢˜")
    owner: str = Field(..., description="è´£ä»»äºº")
    reviewers: List[str] = Field(default_factory=list, description="å®¡æ ¸äººåˆ—è¡¨")
    force: bool = Field(False, description="è‹¥å·²å­˜åœ¨æ–‡æ¡£ï¼Œæ˜¯å¦å¼ºåˆ¶è¦†ç›–éª¨æ¶ï¼ˆè°¨æ…ï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ DOCS_PROJECT_ROOT æˆ–å½“å‰å·¥ä½œç›®å½•")

class PrepareDocsOutput(BaseModel):
    taskKey: str
    mainDocPath: str
    mainDocPathRelative: Optional[str] = None
    processDir: str
    processDirRelative: Optional[str] = None
    status: str

class CodeGenInput(BaseModel):
    """ä»£ç ç”Ÿæˆè®¡åˆ’çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="CodeGenInput", description="ä»£ç ç”Ÿæˆè®¡åˆ’çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    requirements: str = Field(..., description="éœ€æ±‚/ç›®æ ‡çš„æ–‡å­—è¯´æ˜")
    constraints: List[str] = Field(default_factory=list, description="å®ç°çº¦æŸï¼ˆè·¯å¾„/è§„èŒƒ/å®‰å…¨ç­‰ï¼‰")
    targetModules: List[str] = Field(default_factory=list, description="ç›®æ ‡æ¨¡å—åˆ—è¡¨ï¼Œä¾‹å¦‚ devflow_mcp")
    acceptanceCriteria: List[str] = Field(default_factory=list, description="éªŒæ”¶æ ‡å‡†åˆ—è¡¨")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class CodeGenOutput(BaseModel):
    codePlanDoc: str
    codePlanDocRelative: Optional[str] = None
    statusHint: str

class CurlGenInput(BaseModel):
    """curl æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="CurlGenInput", description="curl æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆçš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    baseUrl: Optional[str] = Field(None, description="æ¥å£åŸºç¡€åœ°å€ï¼Œä¾‹å¦‚ https://api.example.comï¼›è‹¥ä» OpenAPI servers æ¨æ–­å¯çœç•¥")
    endpoints: List[Dict[str, Any]] = Field(default_factory=list, description="è¦ç”Ÿæˆçš„æ¥å£æ¸…å•ï¼ˆmethod/path/headers/payloadï¼‰ï¼Œè‹¥ç•™ç©ºå°†å°è¯•ä» OpenAPI æ¨æ–­")
    envVars: Dict[str, str] = Field(default_factory=dict, description="env å˜é‡ç¤ºä¾‹ï¼Œå¦‚ API_TOKEN")
    openapiUrl: Optional[str] = Field(None, description="OpenAPI æ–‡æ¡£çš„ URLï¼ˆjson/yamlï¼‰")
    openapiPath: Optional[str] = Field(None, description="OpenAPI æ–‡æ¡£çš„æœ¬åœ°è·¯å¾„ï¼ˆjson/yamlï¼‰")
    maxEndpoints: int = Field(20, description="ä» OpenAPI æå–çš„æœ€å¤§æ¥å£æ•°é‡ä¸Šé™")
    authMode: Literal['none', 'authorization_bearer', 'header_token', 'query_token'] = Field('none', description="é‰´æƒæ–¹å¼ï¼šæ— /Authorization Bearer/è‡ªå®šä¹‰è¯·æ±‚å¤´/Query å‚æ•°")
    tokenEnvVar: str = Field('API_TOKEN', description="ç”¨äº curl çš„ä»¤ç‰Œç¯å¢ƒå˜é‡åï¼Œä¾‹å¦‚ API_TOKENï¼Œå°†ä»¥ $API_TOKEN å¼•ç”¨")
    headerName: str = Field('accessToken', description="å½“ authMode=header_token æ—¶ä½¿ç”¨çš„è¯·æ±‚å¤´åç§°ï¼ˆé»˜è®¤ accessTokenï¼‰")
    queryParamName: str = Field('accessToken', description="å½“ authMode=query_token æ—¶ä½¿ç”¨çš„æŸ¥è¯¢å‚æ•°åï¼ˆé»˜è®¤ accessTokenï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class CurlGenOutput(BaseModel):
    curlDoc: str
    curlDocRelative: Optional[str] = None
    snippets: List[str]

class MySQLPlanInput(BaseModel):
    """MySQL éªŒè¯è®¡åˆ’çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="MySQLPlanInput", description="MySQL éªŒè¯è®¡åˆ’çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    tables: List[str] = Field(default_factory=list, description="æ¶‰åŠçš„è¡¨ï¼ˆå¯é€‰ï¼‰")
    preconditions: List[str] = Field(default_factory=list, description="å‰ç½® SQL è¯­å¥åˆ—è¡¨ï¼Œå¦‚å»ºè¡¨/å‡†å¤‡æ•°æ®")
    assertions: List[Dict[str, Any]] = Field(default_factory=list, description="æ–­è¨€ SQL ä¸æœŸæœ›æè¿°")
    cleanup: List[str] = Field(default_factory=list, description="æ¸…ç† SQL è¯­å¥åˆ—è¡¨")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class MySQLStatementResult(BaseModel):
    sql: str
    success: bool
    rowsAffected: Optional[int] = None
    rows: Optional[List[Dict[str, Any]]] = None
    error: Optional[str] = None

class MySQLPlanOutput(BaseModel):
    verificationPlanDoc: str
    verificationPlanDocRelative: Optional[str] = None
    sqlPlan: Dict[str, Any]
    executionResults: Optional[List[MySQLStatementResult]] = None
    executed: bool = False

class IntegrationDocInput(BaseModel):
    """å¯¹æ¥æ–‡æ¡£ç”Ÿæˆçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="IntegrationDocInput", description="å¯¹æ¥æ–‡æ¡£ç”Ÿæˆçš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    audience: str = Field(..., description="ç›®æ ‡è¯»è€…ï¼šinternal|external")
    systems: List[str] = Field(default_factory=list, description="æ¶‰åŠç³»ç»Ÿåˆ—è¡¨")
    interfaces: List[Dict[str, Any]] = Field(default_factory=list, description="æ¥å£å®šä¹‰åˆ—è¡¨ï¼ˆname/method/path/schemasï¼‰")
    notes: Optional[str] = Field(None, description="è¡¥å……è¯´æ˜ï¼ˆå¯é€‰ï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class IntegrationDocOutput(BaseModel):
    integrationDoc: str
    integrationDocRelative: Optional[str] = None
    toc: List[str]

class JiraPublishInput(BaseModel):
    """ç”Ÿæˆ Jira æäº¤è®¡åˆ’çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraPublishInput", description="ç”Ÿæˆ Jira æäº¤è®¡åˆ’çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    projectKey: Optional[str] = Field(None, description="Jira é¡¹ç›® Keyï¼ˆå¯é€‰ï¼Œä¸ºç©ºæ—¶è‡ªåŠ¨ä»Gitåˆ†æ”¯è§£æï¼‰")
    issueType: str = Field(..., description="å·¥å•ç±»å‹ï¼Œå¦‚ Task/Story/Documentation")
    summary: str = Field(..., description="å·¥å•æ ‡é¢˜")
    description: str = Field(..., description="å·¥å•æè¿°")
    labels: List[str] = Field(default_factory=list, description="æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")
    attachments: List[str] = Field(default_factory=list, description="è¦ä¸Šä¼ çš„é™„ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")
    links: List[Dict[str, str]] = Field(default_factory=list, description="è¦å…³è”çš„å·¥å•åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•ï¼Œç”¨äºè§£æé™„ä»¶ç›¸å¯¹è·¯å¾„")
    autoDetectFromBranch: bool = Field(True, description="æ˜¯å¦è‡ªåŠ¨ä»Gitåˆ†æ”¯æ£€æµ‹é¡¹ç›®ä¿¡æ¯ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")

class JiraCreateIssueOutput(BaseModel):
    issueKey: Optional[str] = None
    url: Optional[str] = None
    hint: str

class JiraAttachFilesOutput(BaseModel):
    attached: List[str]
    failed: List[Dict[str, Any]]
    hint: str

class JiraPublishOutput(BaseModel):
    jiraPlanDoc: str
    jiraPlanDocRelative: Optional[str] = None
    jiraPayload: Dict[str, Any]
    createdIssue: Optional[JiraCreateIssueOutput] = None
    attachmentResults: Optional[JiraAttachFilesOutput] = None
    executed: bool = False

class ReviewStatusInput(BaseModel):
    """æ–‡æ¡£çŠ¶æ€æµè½¬çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="ReviewStatusInput", description="æ–‡æ¡£çŠ¶æ€æµè½¬çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    newStatus: str = Field(..., description="ç›®æ ‡çŠ¶æ€ï¼šPENDING_REVIEW/APPROVED/CHANGES_REQUESTED/PUBLISHED")
    by: str = Field(..., description="æ“ä½œè€…")
    notes: Optional[str] = Field(None, description="å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ DOCS_PROJECT_ROOT æˆ–å½“å‰å·¥ä½œç›®å½•")

class ReviewStatusOutput(BaseModel):
    taskKey: str
    oldStatus: str
    newStatus: str

class ReviewChecklistInput(BaseModel):
    """ä¸€è‡´æ€§æ£€æŸ¥çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="ReviewChecklistInput", description="ä¸€è‡´æ€§æ£€æŸ¥çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    checks: List[str] = Field(..., description="éœ€è¦æ‰§è¡Œçš„æ£€æŸ¥é¡¹æ ‡è¯†åˆ—è¡¨")

class ReviewChecklistOutput(BaseModel):
    passed: bool
    failedItems: List[Dict[str, str]]

# æ–°å¢ï¼šçŠ¶æ€ç®¡ç†ç›¸å…³æ¨¡å‹
class StatusQueryInput(BaseModel):
    """æŸ¥è¯¢çŠ¶æ€ä¿¡æ¯çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="StatusQueryInput", description="æŸ¥è¯¢çŠ¶æ€ä¿¡æ¯çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    includeHistory: bool = Field(True, description="æ˜¯å¦åŒ…å«å†å²è®°å½•")
    includeStats: bool = Field(True, description="æ˜¯å¦åŒ…å«ç»Ÿè®¡ä¿¡æ¯")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class StatusQueryOutput(BaseModel):
    taskKey: str
    currentStatus: str
    allowedTransitions: List[str]
    history: Optional[List[Dict[str, Any]]] = None
    stats: Optional[Dict[str, Any]] = None

class StatusBatchInput(BaseModel):
    """æ‰¹é‡çŠ¶æ€æ“ä½œçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="StatusBatchInput", description="æ‰¹é‡çŠ¶æ€æ“ä½œçš„è¾“å…¥å‚æ•°") 
    operations: List[Dict[str, Any]] = Field(..., description="æ‰¹é‡æ“ä½œåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«taskKeyã€newStatusã€byã€notesç­‰")
    continueOnError: bool = Field(False, description="é‡åˆ°é”™è¯¯æ—¶æ˜¯å¦ç»§ç»­æ‰§è¡Œ")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class StatusBatchOutput(BaseModel):
    successful: List[Dict[str, Any]]
    failed: List[Dict[str, Any]]
    summary: Dict[str, int]

class StatusReportInput(BaseModel):
    """çŠ¶æ€æŠ¥å‘Šçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="StatusReportInput", description="çŠ¶æ€æŠ¥å‘Šçš„è¾“å…¥å‚æ•°")
    includeAll: bool = Field(True, description="æ˜¯å¦åŒ…å«æ‰€æœ‰ä»»åŠ¡")
    statusFilter: Optional[List[str]] = Field(None, description="çŠ¶æ€è¿‡æ»¤å™¨")
    userFilter: Optional[str] = Field(None, description="ç”¨æˆ·è¿‡æ»¤å™¨")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class StatusReportOutput(BaseModel):
    totalTasks: int
    statusBreakdown: Dict[str, int]
    recentActivity: List[Dict[str, Any]]
    blockedTasks: List[Dict[str, Any]]
    summary: Dict[str, Any]

# ---------- Jiraåˆ†æä¸æµ‹è¯•å¯¹æ¯”ç›¸å…³æ¨¡å‹ ----------

class JiraFetchInput(BaseModel):
    """Jiraå·¥å•è·å–çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraFetchInput", description="Jiraå·¥å•è·å–çš„è¾“å…¥å‚æ•°")
    issueKey: str = Field(..., description="Jiraå·¥å•Keyï¼Œå¦‚ PROJ-123")
    includeSubtasks: bool = Field(True, description="æ˜¯å¦åŒ…å«å­ä»»åŠ¡")
    includeAttachments: bool = Field(True, description="æ˜¯å¦ä¸‹è½½é™„ä»¶")
    includeHistory: bool = Field(False, description="æ˜¯å¦åŒ…å«å˜æ›´å†å²")
    attachmentPath: Optional[str] = Field(None, description="é™„ä»¶ä¸‹è½½è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰")
    
class JiraIssueInfo(BaseModel):
    """Jiraå·¥å•ä¿¡æ¯"""
    key: str
    summary: str
    description: str
    status: str
    issueType: str
    priority: str
    assignee: Optional[str] = None
    reporter: Optional[str] = None
    created: str
    updated: str
    customFields: Dict[str, Any] = Field(default_factory=dict)
    
class JiraSubtask(BaseModel):
    """Jiraå­ä»»åŠ¡ä¿¡æ¯"""
    key: str
    summary: str
    description: str
    status: str
    assignee: Optional[str] = None
    
class JiraAttachment(BaseModel):
    """Jiraé™„ä»¶ä¿¡æ¯"""
    id: str
    filename: str
    size: int
    mimeType: str
    author: str
    created: str
    downloadUrl: str
    localPath: Optional[str] = None  # ä¸‹è½½åçš„æœ¬åœ°è·¯å¾„
    
class JiraFetchOutput(BaseModel):
    issueInfo: JiraIssueInfo
    subtasks: List[JiraSubtask] = Field(default_factory=list)
    attachments: List[JiraAttachment] = Field(default_factory=list)
    downloadedFiles: List[str] = Field(default_factory=list)
    
class TestAnalysisInput(BaseModel):
    """æµ‹è¯•åˆ†æçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="TestAnalysisInput", description="æµ‹è¯•åˆ†æçš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="DevFlowä»»åŠ¡Key")
    jiraIssueKey: str = Field(..., description="å…³è”çš„Jiraå·¥å•Key")
    analysisType: str = Field("coverage", description="åˆ†æç±»å‹ï¼šcoverage/gap/recommendation")
    includeAttachments: bool = Field(True, description="æ˜¯å¦åˆ†æé™„ä»¶å†…å®¹")
    projectRoot: Optional[str] = Field(None, description="é¡¹ç›®æ ¹ç›®å½•")
    
class RequirementItem(BaseModel):
    """éœ€æ±‚æ¡ç›®"""
    id: str
    title: str
    description: str
    priority: str = "Medium"
    category: str = "åŠŸèƒ½æ€§"
    source: str  # æ¥æºï¼šdescription/subtask/attachment
    
class TestCaseMatch(BaseModel):
    """æµ‹è¯•ç”¨ä¾‹åŒ¹é…ä¿¡æ¯"""
    requirementId: str
    testCases: List[str] = Field(default_factory=list)
    coverage: float  # 0-1ä¹‹é—´çš„è¦†ç›–åº¦
    gaps: List[str] = Field(default_factory=list)
    
class TestAnalysisOutput(BaseModel):
    taskKey: str
    jiraIssueKey: str
    requirements: List[RequirementItem]
    testMatches: List[TestCaseMatch] 
    overallCoverage: float
    missingTests: List[str]
    recommendedTests: List[str]
    analysisReport: str  # è¯¦ç»†çš„åˆ†ææŠ¥å‘Šè·¯å¾„
    
class RequirementSyncInput(BaseModel):
    """éœ€æ±‚åŒæ­¥çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="RequirementSyncInput", description="éœ€æ±‚åŒæ­¥çš„è¾“å…¥å‚æ•°")
    jiraIssueKey: str = Field(..., description="Jiraå·¥å•Key")
    targetTaskKey: Optional[str] = Field(None, description="ç›®æ ‡DevFlowä»»åŠ¡Keyï¼Œä¸ºç©ºåˆ™è‡ªåŠ¨åˆ›å»º")
    syncMode: str = Field("update", description="åŒæ­¥æ¨¡å¼ï¼šcreate/update/merge")
    autoGenerateTests: bool = Field(False, description="æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
    projectRoot: Optional[str] = Field(None, description="é¡¹ç›®æ ¹ç›®å½•")
    
class RequirementSyncOutput(BaseModel):
    taskKey: str
    jiraIssueKey: str
    createdFiles: List[str]
    updatedFiles: List[str]
    generatedTests: List[str]
    syncReport: str

# ---------- Git Utils ----------

def _get_recent_git_commits(limit: int = 5) -> List[Dict[str, str]]:
    """è·å–æœ€è¿‘çš„Gitæäº¤è®°å½•"""
    try:
        result = subprocess.run(
            ["git", "log", f"--max-count={limit}", "--pretty=format:%h|%s|%an|%ar"],
            capture_output=True,
            text=True,
            check=True
        )
        commits = []
        for line in result.stdout.strip().split('\n'):
            if line:
                parts = line.split('|')
                if len(parts) >= 4:
                    commits.append({
                        "hash": parts[0],
                        "message": parts[1],
                        "author": parts[2],
                        "time": parts[3]
                    })
        return commits
    except (subprocess.CalledProcessError, FileNotFoundError):
        return []

def _get_current_git_branch() -> str:
    """è·å–å½“å‰Gitåˆ†æ”¯åç§°"""
    try:
        result = subprocess.run(
            ["git", "branch", "--show-current"], 
            capture_output=True, 
            text=True, 
            check=True
        )
        return result.stdout.strip()
    except (subprocess.CalledProcessError, FileNotFoundError):
        return "main"  # é»˜è®¤åˆ†æ”¯

def _extract_ticket_from_branch(branch_name: str) -> Optional[str]:
    """ä»åˆ†æ”¯åç§°ä¸­æå–ticketå·ç """
    if not branch_name:
        return None
        
    # å¸¸è§çš„åˆ†æ”¯å‘½åæ¨¡å¼
    patterns = [
        r'^feature/([A-Z]+-\d+)',     # feature/DTS-7442
        r'^bugfix/([A-Z]+-\d+)',      # bugfix/DTS-7442
        r'^hotfix/([A-Z]+-\d+)',      # hotfix/DTS-7442
        r'^([A-Z]+-\d+)-.*',          # DTS-7442-some-description
        r'^([A-Z]+-\d+)$',            # DTS-7442
        r'([A-Z]+-\d+)',              # ä»»æ„ä½ç½®çš„ DTS-7442 æ ¼å¼
    ]
    
    for pattern in patterns:
        match = re.search(pattern, branch_name, re.IGNORECASE)
        if match:
            return match.group(1).upper()
    
    return None

def _get_project_key_from_ticket(ticket_key: str) -> Optional[str]:
    """ä»ticketå·ç ä¸­æå–é¡¹ç›®key"""
    if not ticket_key:
        return None
    
    # æå–é¡¹ç›®å‰ç¼€ï¼Œä¾‹å¦‚ DTS-7442 -> DTS
    match = re.match(r'^([A-Z]+)-\d+', ticket_key)
    if match:
        return match.group(1)
    
    return None

def _auto_detect_jira_context() -> Dict[str, Optional[str]]:
    """è‡ªåŠ¨æ£€æµ‹å½“å‰ä¸Šä¸‹æ–‡çš„Jiraç›¸å…³ä¿¡æ¯"""
    branch_name = _get_current_git_branch()
    ticket_key = _extract_ticket_from_branch(branch_name)
    project_key = _get_project_key_from_ticket(ticket_key) if ticket_key else None
    
    return {
        "branch_name": branch_name,
        "ticket_key": ticket_key,
        "project_key": project_key
    }

# ---------- Utils ----------

def _ensure_dirs_for(project_root: Optional[Path], task_key: Optional[str] = None) -> Dict[str, Path]:
    base = (project_root or PROJECT_ROOT)
    docs_root = base / "Docs"
    tasks_dir = docs_root / ".tasks"
    process_dir = docs_root / "ProcessDocuments"
    if task_key:
        process_dir = process_dir / f"task-{task_key}"
    tasks_dir.mkdir(parents=True, exist_ok=True)
    process_dir.mkdir(parents=True, exist_ok=True)
    return {"docs_root": docs_root, "tasks_dir": tasks_dir, "process_dir": process_dir}


def _timestamp() -> str:
    return datetime.utcnow().isoformat()


def _resolve_project_root(explicit: Optional[str]) -> Path:
    if explicit:
        return Path(explicit).resolve()
    env = os.getenv("DOCS_PROJECT_ROOT")
    if env:
        return Path(env).resolve()
    return Path(os.getcwd()).resolve()


def _relpath(path: Path, root: Path) -> str:
    try:
        return str(path.resolve().relative_to(root.resolve()))
    except Exception:
        return str(path)


def _read_task_status(project_root: Path, task_key: str) -> str:
    main_doc = (project_root / "Docs" / ".tasks" / f"{task_key}.md")
    if not main_doc.exists():
        return "DRAFT"
    try:
        post = frontmatter.load(main_doc)
        status = str(post.metadata.get("status", "DRAFT")).strip().upper()
        return status or "DRAFT"
    except Exception:
        return "DRAFT"


# çŠ¶æ€å®šä¹‰å’Œè½¬æ¢è§„åˆ™
_STATUS_ORDER = {"DRAFT": 1, "PENDING_REVIEW": 2, "CHANGES_REQUESTED": 2, "APPROVED": 3, "PUBLISHED": 4}

# åˆæ³•çš„çŠ¶æ€è½¬æ¢è·¯å¾„
_STATUS_TRANSITIONS = {
    "DRAFT": ["PENDING_REVIEW"],
    "PENDING_REVIEW": ["APPROVED", "CHANGES_REQUESTED"],
    "CHANGES_REQUESTED": ["PENDING_REVIEW", "DRAFT"], 
    "APPROVED": ["PUBLISHED", "CHANGES_REQUESTED"],
    "PUBLISHED": []  # ç»ˆæ€ï¼Œä¸å…è®¸è½¬æ¢
}

def _validate_status_transition(from_status: str, to_status: str) -> bool:
    """éªŒè¯çŠ¶æ€è½¬æ¢æ˜¯å¦åˆæ³•"""
    if from_status not in _STATUS_TRANSITIONS:
        return False
    return to_status in _STATUS_TRANSITIONS[from_status]

def _require_min_status(project_root: Path, task_key: str, min_status: str) -> None:
    current = _read_task_status(project_root, task_key)
    if _STATUS_ORDER.get(current, 0) < _STATUS_ORDER.get(min_status, 0):
        raise ValueError(f"Action not allowed: require >= {min_status}, current={current}")

class StatusValidationError(Exception):
    """çŠ¶æ€éªŒè¯é”™è¯¯"""
    pass

def _get_task_metadata(project_root: Path, task_key: str) -> Dict[str, Any]:
    """è·å–ä»»åŠ¡çš„å…ƒæ•°æ®"""
    main_doc = (project_root / "Docs" / ".tasks" / f"{task_key}.md")
    if not main_doc.exists():
        return {}
    try:
        post = frontmatter.load(main_doc)
        return post.metadata or {}
    except Exception:
        return {}

# ---------- Jiraä¸æµ‹è¯•åˆ†æè¾…åŠ©å‡½æ•° ----------

def _download_jira_attachment(session: Session, attachment_info: Dict[str, Any], download_dir: Path) -> Optional[str]:
    """ä¸‹è½½Jiraé™„ä»¶åˆ°æŒ‡å®šç›®å½•"""
    try:
        download_url = attachment_info.get("content", "")
        filename = attachment_info.get("filename", f"attachment_{attachment_info.get('id', 'unknown')}")
        
        if not download_url:
            return None
            
        response = session.get(download_url, stream=True, timeout=60)
        if response.status_code >= 400:
            return None
            
        download_dir.mkdir(parents=True, exist_ok=True)
        file_path = download_dir / filename
        
        with open(file_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    
        return str(file_path)
        
    except Exception:
        return None

def _parse_requirements_from_text(text: str, source: str = "description") -> List[RequirementItem]:
    """ä»æ–‡æœ¬ä¸­è§£æéœ€æ±‚æ¡ç›®"""
    requirements = []
    
    if not text or not text.strip():
        return requirements
    
    # ç®€å•çš„éœ€æ±‚è¯†åˆ«ç®—æ³•
    lines = text.split('\n')
    current_req = None
    req_id = 1
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # è¯†åˆ«éœ€æ±‚æ ‡è¯†ï¼ˆå¦‚ï¼šéœ€æ±‚1ã€Featureã€åŠŸèƒ½ç­‰ï¼‰
        req_patterns = [
            r'^(\d+[\.\)]\s*)',  # 1. æˆ– 1) å¼€å¤´
            r'^([éœ€æ±‚åŠŸèƒ½ç‰¹æ€§]\d*[\.\:ï¼š]\s*)',  # éœ€æ±‚1. æˆ– åŠŸèƒ½:
            r'^(.*åº”è¯¥|.*å¿…é¡»|.*éœ€è¦)',  # éœ€æ±‚æ€§è¯­è¨€
            r'^(User Story|Feature|éœ€æ±‚)[\s\:ï¼š]',  # æ˜ç¡®æ ‡è¯†
        ]
        
        is_requirement = False
        for pattern in req_patterns:
            if re.search(pattern, line):
                is_requirement = True
                break
        
        if is_requirement or len(line) > 20:  # é•¿å¥å­å¯èƒ½æ˜¯éœ€æ±‚æè¿°
            # ç¡®å®šä¼˜å…ˆçº§
            priority = "Medium"
            if "é‡è¦" in line or "å…³é”®" in line or "é«˜ä¼˜å…ˆçº§" in line:
                priority = "High"
            elif "å¯é€‰" in line or "ä½ä¼˜å…ˆçº§" in line:
                priority = "Low"
            
            # ç¡®å®šç±»åˆ«
            category = "åŠŸèƒ½æ€§"
            if "æ€§èƒ½" in line or "å“åº”æ—¶é—´" in line:
                category = "æ€§èƒ½"
            elif "å®‰å…¨" in line or "æƒé™" in line:
                category = "å®‰å…¨æ€§"
            elif "ç•Œé¢" in line or "UI" in line or "ç”¨æˆ·ä½“éªŒ" in line:
                category = "ç•Œé¢"
            
            requirements.append(RequirementItem(
                id=f"REQ-{source}-{req_id:03d}",
                title=line[:50] + ("..." if len(line) > 50 else ""),
                description=line,
                priority=priority,
                category=category,
                source=source
            ))
            req_id += 1
    
    return requirements

def _extract_test_cases_from_file(file_path: Path) -> List[str]:
    """ä»æµ‹è¯•æ–‡ä»¶ä¸­æå–æµ‹è¯•ç”¨ä¾‹"""
    test_cases = []
    
    if not file_path.exists():
        return test_cases
        
    try:
        content = file_path.read_text(encoding="utf-8")
        
        # æŸ¥æ‰¾curlå‘½ä»¤
        curl_pattern = r'curl\s+.*'
        curl_matches = re.findall(curl_pattern, content, re.MULTILINE)
        test_cases.extend([f"APIæµ‹è¯•: {match[:80]}..." for match in curl_matches])
        
        # æŸ¥æ‰¾æµ‹è¯•æè¿°
        test_patterns = [
            r'###?\s*æµ‹è¯•ç”¨ä¾‹\s*\d*[\:\s]+(.*)',
            r'###?\s*Test Case\s*\d*[\:\s]+(.*)',
            r'###?\s*ç”¨ä¾‹\s*\d*[\:\s]+(.*)',
            r'-\s*æµ‹è¯•[ï¼š:]\s*(.*)',
        ]
        
        for pattern in test_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            test_cases.extend(matches)
    
    except Exception:
        pass
        
    return test_cases

def _calculate_coverage(requirements: List[RequirementItem], test_cases: List[str]) -> List[TestCaseMatch]:
    """è®¡ç®—éœ€æ±‚è¦†ç›–åº¦"""
    matches = []
    
    for req in requirements:
        matched_tests = []
        coverage = 0.0
        gaps = []
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ç®—æ³•
        req_keywords = set(re.findall(r'\w+', req.description.lower()))
        
        for test_case in test_cases:
            test_keywords = set(re.findall(r'\w+', test_case.lower()))
            
            # è®¡ç®—å…³é”®è¯é‡å åº¦
            overlap = len(req_keywords.intersection(test_keywords))
            if overlap > 0:
                matched_tests.append(test_case)
                coverage += min(overlap / len(req_keywords), 1.0)
        
        coverage = min(coverage, 1.0)
        
        if coverage < 0.5:
            gaps.append("ç¼ºå°‘è¶³å¤Ÿçš„æµ‹è¯•ç”¨ä¾‹è¦†ç›–")
        if coverage == 0:
            gaps.append("å®Œå…¨æ²¡æœ‰ç›¸å…³æµ‹è¯•ç”¨ä¾‹")
            
        matches.append(TestCaseMatch(
            requirementId=req.id,
            testCases=matched_tests,
            coverage=coverage,
            gaps=gaps
        ))
    
    return matches

def _generate_task_progress_report(project_root: Path, task_key: str, include_status: bool = True, include_changes: bool = True, include_next_steps: bool = True) -> Dict[str, Any]:
    """ç”Ÿæˆä»»åŠ¡è¿›å±•æŠ¥å‘Š"""
    report = {
        "taskKey": task_key,
        "timestamp": _timestamp(),
        "status": None,
        "recentChanges": [],
        "nextSteps": [],
        "processDocuments": []
    }
    
    # 1. è·å–ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
    if include_status:
        try:
            task_metadata = _get_task_metadata(project_root, task_key)
            current_status = _read_task_status(project_root, task_key)
            
            report["status"] = {
                "current": current_status,
                "title": task_metadata.get("title", ""),
                "owner": task_metadata.get("owner", ""),
                "reviewers": task_metadata.get("reviewers", []),
                "updatedAt": task_metadata.get("updatedAt", ""),
                "reviews": task_metadata.get("reviews", [])[-3:]  # æœ€è¿‘3æ¬¡å®¡æ ¸è®°å½•
            }
        except Exception:
            report["status"] = {"current": "UNKNOWN", "error": "æ— æ³•è¯»å–ä»»åŠ¡çŠ¶æ€"}
    
    # 2. è·å–æœ€è¿‘çš„Gitæ”¹åŠ¨
    if include_changes:
        report["recentChanges"] = _get_recent_git_commits(5)
    
    # 3. æ‰«æè¿‡ç¨‹æ–‡æ¡£çŠ¶æ€
    try:
        process_dir = project_root / "Docs" / "ProcessDocuments" / f"task-{task_key}"
        if process_dir.exists():
            docs_info = []
            doc_names = [
                ("01-Context.md", "èƒŒæ™¯ä¸ç›®æ ‡"),
                ("02-Design.md", "è®¾è®¡æ–¹æ¡ˆ"),
                ("03-CodePlan.md", "ä»£ç è®¡åˆ’"),
                ("04-TestCurls.md", "æµ‹è¯•ç”¨ä¾‹"),
                ("05-MySQLVerificationPlan.md", "MySQLéªŒè¯"),
                ("06-Integration.md", "é›†æˆæ–‡æ¡£"),
                ("07-JiraPublishPlan.md", "Jiraå‘å¸ƒ")
            ]
            
            for doc_file, doc_title in doc_names:
                doc_path = process_dir / f"{task_key}_{doc_file}"
                if doc_path.exists():
                    try:
                        # è¯»å–æ–‡æ¡£çŠ¶æ€
                        post = frontmatter.load(doc_path)
                        doc_status = post.metadata.get("status", "UNKNOWN")
                        updated_at = post.metadata.get("updatedAt", "")
                        
                        docs_info.append({
                            "name": doc_title,
                            "file": doc_file,
                            "status": doc_status,
                            "updatedAt": updated_at,
                            "exists": True
                        })
                    except Exception:
                        docs_info.append({
                            "name": doc_title,
                            "file": doc_file,
                            "status": "ERROR",
                            "exists": True
                        })
                else:
                    docs_info.append({
                        "name": doc_title,
                        "file": doc_file,
                        "status": "MISSING",
                        "exists": False
                    })
            
            report["processDocuments"] = docs_info
    except Exception:
        report["processDocuments"] = []
    
    # 4. ç”Ÿæˆä¸‹ä¸€æ­¥å»ºè®®
    if include_next_steps:
        next_steps = []
        current_status = report.get("status", {}).get("current", "UNKNOWN")
        
        if current_status == "DRAFT":
            next_steps.append("å®Œå–„ä»»åŠ¡æ–‡æ¡£å†…å®¹ï¼Œå‡†å¤‡æäº¤å®¡æ ¸")
            next_steps.append("ç¡®ä¿æ‰€æœ‰å¿…è¦çš„è¿‡ç¨‹æ–‡æ¡£å·²åˆ›å»º")
        elif current_status == "PENDING_REVIEW":
            next_steps.append("ç­‰å¾…å®¡æ ¸äººå‘˜å®¡æ ¸")
            next_steps.append("å‡†å¤‡æ ¹æ®å®¡æ ¸æ„è§è¿›è¡Œä¿®æ”¹")
        elif current_status == "APPROVED":
            next_steps.append("å¼€å§‹æ‰§è¡Œå¼€å‘ä»»åŠ¡")
            next_steps.append("ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å’ŒéªŒè¯è®¡åˆ’")
        elif current_status == "CHANGES_REQUESTED":
            next_steps.append("æ ¹æ®å®¡æ ¸æ„è§ä¿®æ”¹æ–‡æ¡£")
            next_steps.append("é‡æ–°æäº¤å®¡æ ¸")
        elif current_status == "PUBLISHED":
            next_steps.append("ä»»åŠ¡å·²å®Œæˆï¼Œè¿›è¡Œåç»­ç»´æŠ¤")
            next_steps.append("æ”¶é›†ä½¿ç”¨åé¦ˆ")
        
        # åŸºäºæ–‡æ¡£çŠ¶æ€æ·»åŠ å»ºè®®
        for doc in report.get("processDocuments", []):
            if not doc["exists"]:
                next_steps.append(f"åˆ›å»ºç¼ºå¤±çš„æ–‡æ¡£ï¼š{doc['name']}")
            elif doc["status"] == "DRAFT":
                next_steps.append(f"å®Œå–„æ–‡æ¡£å†…å®¹ï¼š{doc['name']}")
        
        report["nextSteps"] = next_steps[:5]  # é™åˆ¶å»ºè®®æ•°é‡
    
    return report

def _generate_test_recommendations(requirements: List[RequirementItem], test_matches: List[TestCaseMatch]) -> List[str]:
    """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ¨è"""
    recommendations = []
    
    for req, match in zip(requirements, test_matches):
        if match.coverage < 0.8:  # è¦†ç›–åº¦ä½äº80%
            # åŸºäºéœ€æ±‚ç±»åˆ«ç”Ÿæˆæ¨è
            if req.category == "åŠŸèƒ½æ€§":
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ åŠŸèƒ½æµ‹è¯•ï¼šéªŒè¯{req.title}")
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ è¾¹ç•Œæµ‹è¯•ï¼šå¼‚å¸¸è¾“å…¥å¤„ç†")
            elif req.category == "æ€§èƒ½":
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ æ€§èƒ½æµ‹è¯•ï¼šå“åº”æ—¶é—´éªŒè¯")
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ è´Ÿè½½æµ‹è¯•ï¼šå¹¶å‘å¤„ç†èƒ½åŠ›")
            elif req.category == "å®‰å…¨æ€§":
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ å®‰å…¨æµ‹è¯•ï¼šæƒé™éªŒè¯")
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ å®‰å…¨æµ‹è¯•ï¼šè¾“å…¥éªŒè¯")
            elif req.category == "ç•Œé¢":
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ UIæµ‹è¯•ï¼šç•Œé¢å…ƒç´ éªŒè¯")
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ UXæµ‹è¯•ï¼šç”¨æˆ·äº¤äº’æµç¨‹")
    
    return recommendations[:10]  # é™åˆ¶æ¨èæ•°é‡


# ---------- Tool Stubs (no-op implementations) ----------

@app.tool()
def task_prepare_docs(input: PrepareDocsInput) -> PrepareDocsOutput:
    """å‡†å¤‡ä»»åŠ¡ä¸»æ–‡æ¡£ä¸åˆ†æ­¥éª¤æ–‡æ¡£çš„éª¨æ¶ï¼Œç›´æ¥ç”Ÿæˆæ–‡æ¡£æ–‡ä»¶ã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    main_doc = dirs["tasks_dir"] / f"{input.taskKey}.md"
    process_dir = dirs["process_dir"]
    
    # åˆ›å»ºä¸»ä»»åŠ¡æ–‡æ¡£
    if not main_doc.exists() or input.force:
        main_content = f"""---
status: DRAFT
taskKey: {input.taskKey}
title: {input.title}
owner: {input.owner}
reviewers: {input.reviewers}
updatedAt: {_timestamp()}
---

# ä»»åŠ¡æ¦‚è¿°
{input.title}

# è´£ä»»äºº
- è´Ÿè´£äººï¼š{input.owner}
- å®¡æ ¸äººï¼š{", ".join(input.reviewers)}

# çŠ¶æ€æœº
DRAFT â†’ PENDING_REVIEW â†’ (APPROVED | CHANGES_REQUESTED) â†’ PUBLISHED

# è¿‡ç¨‹æ–‡æ¡£
- ä¸Šä¸‹æ–‡ï¼š01-Context.md
- è®¾è®¡ï¼š02-Design.md  
- ä»£ç è®¡åˆ’ï¼š03-CodePlan.md
- æµ‹è¯•ç”¨ä¾‹ï¼š04-TestCurls.md
- MySQLéªŒè¯ï¼š05-MySQLVerificationPlan.md
- é›†æˆæ–‡æ¡£ï¼š06-Integration.md
- Jiraå‘å¸ƒï¼š07-JiraPublishPlan.md
"""
        main_doc.write_text(main_content, encoding="utf-8")
    
    # åˆ›å»ºè¿‡ç¨‹æ–‡æ¡£éª¨æ¶
    process_docs = [
        ("01-Context.md", "èƒŒæ™¯ä¸ç›®æ ‡"),
        ("02-Design.md", "è®¾è®¡æ–¹æ¡ˆ"),
        ("03-CodePlan.md", "ä»£ç ç”Ÿæˆè®¡åˆ’"),
        ("04-TestCurls.md", "æµ‹è¯•ç”¨ä¾‹"),
        ("05-MySQLVerificationPlan.md", "MySQLéªŒè¯è®¡åˆ’"),
        ("06-Integration.md", "é›†æˆæ–‡æ¡£"),
        ("07-JiraPublishPlan.md", "Jiraå‘å¸ƒè®¡åˆ’")
    ]
    
    for doc_name, doc_title in process_docs:
        doc_path = process_dir / f"{input.taskKey}_{doc_name}"
        if not doc_path.exists() or input.force:
            doc_content = f"""---
status: DRAFT
updatedAt: {_timestamp()}
---

# {doc_title}

å¾…è¡¥å……å†…å®¹...
"""
            doc_path.write_text(doc_content, encoding="utf-8")
    
    return PrepareDocsOutput(
        taskKey=input.taskKey,
        mainDocPath=str(main_doc),
        mainDocPathRelative=_relpath(main_doc, project_root),
        processDir=str(process_dir),
        processDirRelative=_relpath(process_dir, project_root),
        status="DRAFT",
    )


@app.tool()
def task_request_code_generation(input: CodeGenInput) -> CodeGenOutput:
    """ç”Ÿæˆé¢å‘ AI çš„ä»£ç ç¼–å†™è®¡åˆ’æ–‡æ¡£ï¼ŒåŒ…å«è¯¦ç»†çš„å®ç°æŒ‡å¯¼ã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    code_doc = dirs["process_dir"] / f"{input.taskKey}_03-CodePlan.md"
    
    # ç”Ÿæˆè¯¦ç»†çš„ä»£ç è®¡åˆ’æ–‡æ¡£
    code_content = f"""---
status: DRAFT
updatedAt: {_timestamp()}
---

# ä»£ç ç”Ÿæˆè®¡åˆ’ï¼ˆé¢å‘ AIï¼‰

## éœ€æ±‚æè¿°
{input.requirements}

## ç›®æ ‡æ¨¡å—
{chr(10).join(f"- {module}" for module in input.targetModules)}

## å®ç°çº¦æŸ
{chr(10).join(f"- {constraint}" for constraint in input.constraints)}

## éªŒæ”¶æ ‡å‡†
{chr(10).join(f"- {criteria}" for criteria in input.acceptanceCriteria)}

## å¼€å‘æŒ‡å¯¼

### æ¶æ„è¦æ±‚
- è¯­è¨€ï¼šPython 3.10+
- æ¡†æ¶ï¼šFastMCP
- æ¨¡å—ç»“æ„ï¼šéµå¾ªç°æœ‰ devflow_mcp åŒ…ç»“æ„

### å®ç°æ­¥éª¤
1. **æ¨¡å‹å®šä¹‰**ï¼šå®šä¹‰è¾“å…¥è¾“å‡º Pydantic æ¨¡å‹
2. **å·¥å…·å‡½æ•°**ï¼šå®ç°æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
3. **æ–‡æ¡£ç”Ÿæˆ**ï¼šç”Ÿæˆå®é™…æ–‡æ¡£å†…å®¹ï¼Œéä»…è·¯å¾„
4. **çŠ¶æ€ç®¡ç†**ï¼šå®ç°çŠ¶æ€æµè½¬å’Œæƒé™æ§åˆ¶
5. **é”™è¯¯å¤„ç†**ï¼šæ·»åŠ å®Œå–„çš„å¼‚å¸¸å¤„ç†

### è´¨é‡è¦æ±‚
- æ‰€æœ‰å‡½æ•°å¿…é¡»æœ‰å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
- è¾“å…¥å‚æ•°å¿…é¡»è¿›è¡ŒéªŒè¯
- é”™è¯¯ä¿¡æ¯å¿…é¡»ç”¨æˆ·å‹å¥½
- æ”¯æŒç›¸å¯¹å’Œç»å¯¹è·¯å¾„

## AI æ‰§è¡Œæ¸…å•
- [ ] è¡¥å…¨å·¥å…·å®ç°é€»è¾‘
- [ ] ç”Ÿæˆå®é™…æ–‡æ¡£å†…å®¹
- [ ] æ·»åŠ è¾“å…¥éªŒè¯
- [ ] å®Œå–„é”™è¯¯å¤„ç†
- [ ] æ›´æ–°çŠ¶æ€ä¸º PENDING_REVIEW
"""
    
    code_doc.write_text(code_content, encoding="utf-8")
    
    return CodeGenOutput(
        codePlanDoc=str(code_doc),
        codePlanDocRelative=_relpath(code_doc, project_root),
        statusHint="Document created, ready for PENDING_REVIEW",
    )


@app.tool()
def test_generate_curl_calls(input: CurlGenInput) -> CurlGenOutput:
    """ç”Ÿæˆå¯æ‰§è¡Œçš„ curl æµ‹è¯•æ–‡æ¡£è·¯å¾„ä¸ç‰‡æ®µåˆ—è¡¨ï¼Œè¦†ç›–æ­£/åç”¨ä¾‹ï¼ˆè¿”å›è®¡åˆ’ï¼‰ã€‚
    
    âš ï¸ å‰ç½®æ¡ä»¶ï¼šä»»åŠ¡çŠ¶æ€å¿…é¡» >= APPROVEDã€‚
    ğŸ‘¤ AI æé†’ï¼šè°ƒç”¨å‰è¯·å…ˆç¡®è®¤ä»»åŠ¡çš„çŠ¶æ€æ˜¯å¦å·²é€šè¿‡äººå·¥å®¡æ ¸(APPROVED)ã€‚
    å¦‚å½“å‰çŠ¶æ€ä¸º DRAFT/PENDING_REVIEWï¼Œè¯·å…ˆä¸ç”¨æˆ·ç¡®è®¤æ˜¯å¦éœ€è¦ï¼š
    1. ä½¿ç”¨ review_set_status å°†çŠ¶æ€æ”¹ä¸º APPROVEDï¼Œæˆ–
    2. ç”¨æˆ·æ‰‹åŠ¨å®¡æ ¸é€šè¿‡åå†è°ƒç”¨æ­¤å·¥å…·
    
    æ”¯æŒä¸¤ç§æ¥æºï¼š
    - ç›´æ¥ä¼ å…¥ endpointsï¼ˆmethod/path/...ï¼‰
    - é€šè¿‡ openapiUrl/openapiPath è§£æ OpenAPIï¼Œè‡ªåŠ¨æå– endpoints
    """
    project_root = _resolve_project_root(input.projectRoot)
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    doc_path = dirs["process_dir"] / f"{input.taskKey}_04-TestCurls.md"

    def _load_openapi() -> Optional[Dict[str, Any]]:
        spec_text: Optional[str] = None
        if input.openapiUrl:
            resp = requests.get(input.openapiUrl, timeout=30)
            if resp.status_code >= 400:
                raise ValueError(f"OpenAPI url fetch failed: {resp.status_code}")
            spec_text = resp.text
        elif input.openapiPath:
            p = Path(input.openapiPath)
            if not p.is_absolute():
                p = (PROJECT_ROOT / p).resolve()
            if not p.is_file():
                raise ValueError(f"OpenAPI file not found: {p}")
            spec_text = p.read_text(encoding="utf-8")
        if not spec_text:
            return None
        try:
            return json.loads(spec_text)
        except Exception:
            return yaml.safe_load(spec_text)

    def _extract_endpoints_from_openapi(spec: Dict[str, Any]) -> tuple[List[Dict[str, Any]], Optional[str]]:
        endpoints: List[Dict[str, Any]] = []
        derived_base: Optional[str] = None
        # derive baseUrl from servers (OpenAPI v3)
        servers = spec.get("servers")
        if isinstance(servers, list) and servers:
            srv = servers[0]
            if isinstance(srv, dict):
                derived_base = srv.get("url")
        # paths
        paths = spec.get("paths", {})
        for path, ops in paths.items():
            if not isinstance(ops, dict):
                continue
            for method in ["get", "post", "put", "delete", "patch", "head", "options"]:
                if method in ops:
                    op = ops[method]
                    desc = op.get("summary") or op.get("operationId") or ""
                    endpoints.append({
                        "method": method.upper(),
                        "path": path,
                        "description": desc,
                    })
                    if len(endpoints) >= max(1, input.maxEndpoints):
                        return endpoints, derived_base
        return endpoints, derived_base

    # é—¨ç¦ï¼šåªæœ‰åœ¨ APPROVED ä¹‹åæ‰å…è®¸ç”Ÿæˆ curl
    _require_min_status(project_root, input.taskKey, "APPROVED")

    endpoints = list(input.endpoints or [])
    derived_base = None
    if not endpoints:
        spec = _load_openapi()
        if spec:
            endpoints, derived_base = _extract_endpoints_from_openapi(spec)
    if not endpoints:
        raise ValueError("éœ€è¦æä¾› endpoints æˆ– openapiUrl/openapiPath ä»¥ç”Ÿæˆ curl ç”¨ä¾‹")

    base_url = input.baseUrl or derived_base or ""
    snippets: List[str] = []
    default_auth_mode = input.authMode or 'none'
    default_header_name = input.headerName or 'accessToken'
    default_query_name = input.queryParamName or 'accessToken'
    token_shell = f"${input.tokenEnvVar}" if input.tokenEnvVar else "$API_TOKEN"
    for ep in endpoints:
        method = (ep.get("method") or "GET").upper()
        path = ep.get("path") or "/"
        headers = ep.get("headers") or {}
        payload = ep.get("samplePayload")
        # è®¡ç®—é‰´æƒç­–ç•¥ï¼ˆç«¯ç‚¹å¯è¦†ç›–å…¨å±€ï¼‰
        auth_mode = (ep.get("authMode") or default_auth_mode) if isinstance(ep, dict) else default_auth_mode
        header_name = ep.get("headerName") if isinstance(ep, dict) else None
        query_name = ep.get("queryParamName") if isinstance(ep, dict) else None
        eff_header_name = header_name or default_header_name
        eff_query_name = query_name or default_query_name
        parts = ["curl -sS -X", method]
        # æ³¨å…¥é‰´æƒ
        if auth_mode == 'authorization_bearer':
            headers = {**headers, "Authorization": f"Bearer {token_shell}"}
        elif auth_mode == 'header_token':
            headers = {**headers, eff_header_name: token_shell}
        # å†™å…¥å¤´éƒ¨
        for k, v in headers.items():
            parts += ["-H", f"\"{k}: {v}\""]
        # æ„é€  URL å¹¶æ³¨å…¥ query tokenï¼ˆå¦‚éœ€è¦ï¼‰
        url = (base_url.rstrip("/") + path) if base_url else path
        if auth_mode == 'query_token':
            sep = '&' if ('?' in url) else '?'
            url = f"{url}{sep}{eff_query_name}={token_shell}"
        if payload is not None:
            parts += ["-H", "\"Content-Type: application/json\"", "--data", json.dumps(payload)]
        parts += [f"\"{url}\""]
        snippets.append(" ".join(parts))

    # å°†ç”Ÿæˆçš„ curl ç”¨ä¾‹å†™å…¥æ–‡æ¡£æ–‡ä»¶
    try:
        doc_path.parent.mkdir(parents=True, exist_ok=True)
        lines: List[str] = []
        lines.append("---")
        lines.append("status: DRAFT")
        lines.append(f"generatedAt: {_timestamp()}")
        if base_url:
            lines.append(f"baseUrl: {base_url}")
        lines.append("---\n")
        lines.append("## è¿è¡Œå‰")
        lines.append(f"- å¯¼å‡ºä»¤ç‰Œ: export {input.tokenEnvVar or 'API_TOKEN'}=\"<token>\"\n")
        lines.append("## ç”¨ä¾‹")
        for idx, snip in enumerate(snippets, start=1):
            lines.append(f"\n### ç”¨ä¾‹ {idx}")
            lines.append("```bash")
            lines.append(snip)
            lines.append("```")
        content = "\n".join(lines) + "\n"
        doc_path.write_text(content, encoding="utf-8")
    except Exception:
        # å†™å…¥å¤±è´¥ä¸é˜»å¡è¿”å›
        pass

    return CurlGenOutput(curlDoc=str(doc_path), curlDocRelative=_relpath(doc_path, project_root), snippets=snippets)


@app.tool()
def verify_plan_with_mysql_mcp(input: MySQLPlanInput) -> MySQLPlanOutput:
    """ç”Ÿæˆå¹¶æ‰§è¡Œ MySQL éªŒè¯è®¡åˆ’ï¼ˆå‰ç½®/æ–­è¨€/æ¸…ç†ï¼‰ï¼Œç›´æ¥è¿”å›æ‰§è¡Œç»“æœã€‚
    
    âš ï¸ å‰ç½®æ¡ä»¶ï¼šä»»åŠ¡çŠ¶æ€å¿…é¡» >= APPROVEDã€‚
    ğŸ‘¤ AI æé†’ï¼šè°ƒç”¨å‰è¯·å…ˆç¡®è®¤ä»»åŠ¡çš„çŠ¶æ€æ˜¯å¦å·²é€šè¿‡äººå·¥å®¡æ ¸(APPROVED)ã€‚
    å¦‚å½“å‰çŠ¶æ€ä¸æ»¡è¶³ï¼Œè¯·ä¸»åŠ¨ä¸ç”¨æˆ·ç¡®è®¤æ˜¯å¦éœ€è¦å…ˆè¿›è¡ŒçŠ¶æ€æµè½¬ã€‚
    """
    project_root = _resolve_project_root(input.projectRoot)
    # é—¨ç¦ï¼šè¦æ±‚ APPROVED
    _require_min_status(project_root, input.taskKey, "APPROVED")
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    doc_path = dirs["process_dir"] / f"{input.taskKey}_05-MySQLVerificationPlan.md"
    
    plan = {
        "preconditions": input.preconditions,
        "assertions": input.assertions,
        "cleanup": input.cleanup,
        "execution_order": ["preconditions", "assertions", "cleanup"],
    }
    
    # æ‰§è¡ŒMySQLéªŒè¯è®¡åˆ’
    execution_results = []
    executed = False
    
    try:
        # æŒ‰é¡ºåºæ‰§è¡Œï¼šå‰ç½®æ¡ä»¶ -> æ–­è¨€ -> æ¸…ç†
        all_statements = []
        
        # 1. æ‰§è¡Œå‰ç½®æ¡ä»¶
        if input.preconditions:
            all_statements.extend(input.preconditions)
        
        # 2. æ‰§è¡Œæ–­è¨€ï¼ˆè½¬æ¢ä¸ºSQLæŸ¥è¯¢ï¼‰
        if input.assertions:
            for assertion in input.assertions:
                if isinstance(assertion, dict) and 'sql' in assertion:
                    all_statements.append(assertion['sql'])
                elif isinstance(assertion, str):
                    all_statements.append(assertion)
        
        # 3. æ‰§è¡Œæ¸…ç†è¯­å¥
        if input.cleanup:
            all_statements.extend(input.cleanup)
        
        if all_statements:
            # ç›´æ¥ä½¿ç”¨å†…ç½®çš„MySQLæ‰§è¡ŒåŠŸèƒ½
            mysql_result = mysql_execute_statements(MySQLExecuteInput(
                taskKey=input.taskKey,
                statements=all_statements,
                continueOnError=True
            ))
            execution_results = mysql_result.results
            executed = True
            
    except Exception as e:
        # å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­ç”Ÿæˆæ–‡æ¡£
        execution_results = [MySQLStatementResult(
            sql="EXECUTION_ERROR",
            success=False,
            error=str(e)
        )]
    
    # ç”ŸæˆéªŒè¯è®¡åˆ’æ–‡æ¡£
    doc_content = f"""---
status: {"EXECUTED" if executed else "DRAFT"}
updatedAt: {_timestamp()}
executed: {executed}
---

# MySQL éªŒè¯è®¡åˆ’

## éªŒè¯ç›®æ ‡
éªŒè¯ä»»åŠ¡ {input.taskKey} çš„æ•°æ®åº“ç›¸å…³åŠŸèƒ½

## æ¶‰åŠè¡¨
{chr(10).join(f"- {table}" for table in input.tables)}

## æ‰§è¡Œè®¡åˆ’

### 1. å‰ç½®æ¡ä»¶
```sql
{chr(10).join(input.preconditions)}
```

### 2. æ–­è¨€æ£€æŸ¥
{chr(10).join(f"- {assertion.get('description', str(assertion)) if isinstance(assertion, dict) else assertion}" for assertion in input.assertions)}

### 3. æ¸…ç†æ“ä½œ
```sql
{chr(10).join(input.cleanup)}
```

## æ‰§è¡Œç»“æœ
{'âœ… å·²æ‰§è¡Œ' if executed else 'âŒ æœªæ‰§è¡Œ'}

{chr(10).join(f"**{i+1}.** {result.sql} - {'âœ… æˆåŠŸ' if result.success else 'âŒ å¤±è´¥: ' + (result.error or '')}" for i, result in enumerate(execution_results)) if execution_results else 'æ— æ‰§è¡Œè®°å½•'}
"""
    
    doc_path.write_text(doc_content, encoding="utf-8")
    
    return MySQLPlanOutput(
        verificationPlanDoc=str(doc_path),
        verificationPlanDocRelative=_relpath(doc_path, project_root),
        sqlPlan=plan,
        executionResults=execution_results,
        executed=executed
    )


@app.tool()
def docs_generate_integration(input: IntegrationDocInput) -> IntegrationDocOutput:
    """ç”Ÿæˆå®Œæ•´çš„é›†æˆå¯¹æ¥æ–‡æ¡£ï¼ŒåŒ…å«æ¦‚è§ˆã€é‰´æƒã€æ¥å£ã€Schemaã€é”™è¯¯ç å’Œæ ·ä¾‹ã€‚
    
    âš ï¸ å‰ç½®æ¡ä»¶ï¼šä»»åŠ¡çŠ¶æ€å¿…é¡» >= APPROVEDã€‚
    ğŸ‘¤ AI æé†’ï¼šè°ƒç”¨å‰è¯·å…ˆç¡®è®¤ä»»åŠ¡çš„çŠ¶æ€æ˜¯å¦å·²é€šè¿‡äººå·¥å®¡æ ¸(APPROVED)ã€‚
    å¦‚å½“å‰çŠ¶æ€ä¸æ»¡è¶³ï¼Œè¯·ä¸»åŠ¨ä¸ç”¨æˆ·ç¡®è®¤æ˜¯å¦éœ€è¦å…ˆè¿›è¡ŒçŠ¶æ€æµè½¬ã€‚
    """
    project_root = _resolve_project_root(input.projectRoot)
    # é—¨ç¦ï¼šè¦æ±‚ APPROVED
    _require_min_status(project_root, input.taskKey, "APPROVED")
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    doc_path = dirs["process_dir"] / f"{input.taskKey}_06-Integration.md"
    
    # ç”Ÿæˆå®Œæ•´çš„é›†æˆæ–‡æ¡£å†…å®¹
    doc_content = f"""---
status: DRAFT
updatedAt: {_timestamp()}
audience: {input.audience}
---

# é›†æˆå¯¹æ¥æ–‡æ¡£ - {input.taskKey}

## 1. æ¦‚è§ˆ (Overview)

### ç³»ç»Ÿç®€ä»‹
ä»»åŠ¡ {input.taskKey} çš„ç³»ç»Ÿé›†æˆæ–‡æ¡£ï¼Œé¢å‘ {input.audience} ç”¨æˆ·ã€‚

### æ¶‰åŠç³»ç»Ÿ
{chr(10).join(f"- {system}" for system in input.systems)}

## 2. é‰´æƒ (Authentication)

### é‰´æƒæ–¹å¼
- **ç±»å‹**: Bearer Token / API Key
- **è¯·æ±‚å¤´**: `Authorization: Bearer <token>`
- **è·å–æ–¹å¼**: è”ç³»ç³»ç»Ÿç®¡ç†å‘˜

### ç¤ºä¾‹
```bash
curl -H "Authorization: Bearer your-api-token" \\
     https://api.example.com/endpoint
```

## 3. æ¥å£ (Endpoints)

{chr(10).join(f'''### {interface.get("name", "Unknown")}
**æ–¹æ³•**: {interface.get("method", "GET")}  
**è·¯å¾„**: {interface.get("path", "/")}  
**æè¿°**: {interface.get("description", "æš‚æ— æè¿°")}

**è¯·æ±‚ç¤ºä¾‹**:
```json
{{"example": "request"}}
```

**å“åº”ç¤ºä¾‹**:
```json
{{"status": "success", "data": {{}}}}
```
''' for interface in input.interfaces)}

## 4. æ•°æ®ç»“æ„ (Schemas)

### é€šç”¨å“åº”æ ¼å¼
```json
{{
  "status": "success|error",
  "message": "æ“ä½œç»“æœæè¿°",
  "data": {{}},
  "timestamp": "2024-01-01T00:00:00Z"
}}
```

### ä¸šåŠ¡æ•°æ®ç»“æ„
```json
{{
  "id": "string",
  "name": "string", 
  "status": "active|inactive",
  "createdAt": "2024-01-01T00:00:00Z",
  "updatedAt": "2024-01-01T00:00:00Z"
}}
```

## 5. é”™è¯¯ç  (Error Codes)

| é”™è¯¯ç  | æè¿° | è§£å†³æ–¹æ¡ˆ |
|--------|------|----------|
| 400 | è¯·æ±‚å‚æ•°é”™è¯¯ | æ£€æŸ¥è¯·æ±‚å‚æ•°æ ¼å¼å’Œå¿…å¡«å­—æ®µ |
| 401 | æœªæˆæƒ | æ£€æŸ¥ API Token æ˜¯å¦æ­£ç¡® |
| 403 | ç¦æ­¢è®¿é—® | æ£€æŸ¥è´¦å·æƒé™ |
| 404 | èµ„æºä¸å­˜åœ¨ | æ£€æŸ¥è¯·æ±‚çš„èµ„æºIDæ˜¯å¦æ­£ç¡® |
| 500 | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ | è”ç³»æŠ€æœ¯æ”¯æŒ |

## 6. é›†æˆæ ·ä¾‹ (Samples)

### Python ç¤ºä¾‹
```python
import requests

def call_api(endpoint, data=None):
    headers = {{
        'Authorization': 'Bearer your-api-token',
        'Content-Type': 'application/json'
    }}
    
    response = requests.post(
        f'https://api.example.com{{endpoint}}',
        headers=headers,
        json=data
    )
    
    return response.json()

# ä½¿ç”¨ç¤ºä¾‹
result = call_api('/api/v1/resource', {{'name': 'test'}})
print(result)
```

### curl ç¤ºä¾‹
```bash
# GET è¯·æ±‚
curl -H "Authorization: Bearer your-api-token" \\
     https://api.example.com/api/v1/resource

# POST è¯·æ±‚  
curl -X POST \\
     -H "Authorization: Bearer your-api-token" \\
     -H "Content-Type: application/json" \\
     -d '{{"name": "test"}}' \\
     https://api.example.com/api/v1/resource
```

## 7. æŠ€æœ¯æ”¯æŒ

### è”ç³»æ–¹å¼
- **æŠ€æœ¯æ”¯æŒ**: tech-support@example.com
- **æ–‡æ¡£é—®é¢˜**: docs@example.com
- **ç´§æ€¥è”ç³»**: emergency@example.com

### æ›´æ–°æ—¥å¿—
- {_timestamp()[:10]}: åˆå§‹ç‰ˆæœ¬åˆ›å»º

## 8. è¡¥å……è¯´æ˜
{input.notes or "æš‚æ— è¡¥å……è¯´æ˜"}
"""
    
    doc_path.write_text(doc_content, encoding="utf-8")
    toc = ["Overview", "Authentication", "Endpoints", "Schemas", "Error Codes", "Samples", "Support", "Notes"]
    
    return IntegrationDocOutput(
        integrationDoc=str(doc_path), 
        integrationDocRelative=_relpath(doc_path, project_root), 
        toc=toc
    )


@app.tool()
def jira_publish_integration_doc(input: JiraPublishInput) -> JiraPublishOutput:
    """ç›´æ¥åˆ›å»º Jira å·¥å•å¹¶ä¸Šä¼ é™„ä»¶ï¼Œè¿”å›å®Œæ•´çš„æ‰§è¡Œç»“æœã€‚
    
    âš ï¸ å‰ç½®æ¡ä»¶ï¼šä»»åŠ¡çŠ¶æ€å¿…é¡» >= APPROVED ä¸”ç›¸å…³æ–‡æ¡£å·²ç”Ÿæˆã€‚
    ğŸ‘¤ AI æé†’ï¼šè°ƒç”¨å‰è¯·å…ˆç¡®è®¤ï¼š
    1. ä»»åŠ¡çš„çŠ¶æ€æ˜¯å¦å·²é€šè¿‡äººå·¥å®¡æ ¸(APPROVED)
    2. å¯¹æ¥æ–‡æ¡£ç­‰é™„ä»¶æ˜¯å¦å·²ç”Ÿæˆå®Œæˆ
    å¦‚æ¡ä»¶ä¸æ»¡è¶³ï¼Œè¯·ä¸»åŠ¨ä¸ç”¨æˆ·ç¡®è®¤åç»­æ­¥éª¤ã€‚
    
    ğŸ”„ è‡ªåŠ¨æ£€æµ‹ï¼šæ”¯æŒä»å½“å‰Gitåˆ†æ”¯è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Keyå’Œç›¸å…³ticketä¿¡æ¯
    """
    project_root = _resolve_project_root(input.projectRoot)
    # é—¨ç¦ï¼šè¦æ±‚æ‰€æœ‰æ£€æŸ¥é€šè¿‡ä¸”çŠ¶æ€ APPROVED
    _require_min_status(project_root, input.taskKey, "APPROVED")
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    doc_path = dirs["process_dir"] / f"{input.taskKey}_07-JiraPublishPlan.md"
    
    # è‡ªåŠ¨æ£€æµ‹Gitåˆ†æ”¯ä¿¡æ¯
    git_context = _auto_detect_jira_context()
    detected_project_key = input.projectKey
    
    if input.autoDetectFromBranch and not detected_project_key:
        detected_project_key = git_context.get("project_key")
        if not detected_project_key:
            raise ValueError(f"æ— æ³•ä»å½“å‰åˆ†æ”¯ '{git_context.get('branch_name', 'unknown')}' è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Keyï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š projectKey å‚æ•°")
    
    if not detected_project_key:
        raise ValueError("å¿…é¡»æŒ‡å®š projectKey æˆ–å¯ç”¨ autoDetectFromBranch è‡ªåŠ¨æ£€æµ‹")
    
    payload = {
        "fields": {
            "project": {"key": detected_project_key},
            "issuetype": {"name": input.issueType},
            "summary": input.summary,
            "description": input.description,
            "labels": input.labels,
        },
        "attachments": input.attachments,
        "links": input.links,
        "git_context": git_context,  # è®°å½•æ£€æµ‹åˆ°çš„Gitä¸Šä¸‹æ–‡
    }
    
    # ç›´æ¥æ‰§è¡ŒJiraå·¥å•åˆ›å»º
    created_issue = None
    attachment_results = None
    executed = False
    
    try:
        # 1. åˆ›å»ºJiraå·¥å•
        created_issue = jira_create_issue(JiraCreateIssueInput(
            projectKey=detected_project_key,
            issueType=input.issueType,
            summary=input.summary,
            description=input.description,
            labels=input.labels,
            fields={}
        ))
        
        if created_issue and created_issue.issueKey:
            executed = True
            
            # 2. ä¸Šä¼ é™„ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
            if input.attachments:
                attachment_results = jira_attach_files(JiraAttachFilesInput(
                    issueKey=created_issue.issueKey,
                    filePaths=input.attachments
                ))
            
            # 3. å…³è”å·¥å•ï¼ˆå¦‚æœæœ‰ï¼‰
            if input.links:
                for link in input.links:
                    if isinstance(link, dict) and 'issueKey' in link and 'linkType' in link:
                        jira_link_issues(JiraLinkIssuesInput(
                            inwardIssue=created_issue.issueKey,
                            outwardIssue=link['issueKey'],
                            linkType=link.get('linkType', 'relates to')
                        ))
                        
    except Exception as e:
        # å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­ç”Ÿæˆæ–‡æ¡£
        executed = False
        created_issue = JiraCreateIssueOutput(
            issueKey=None,
            url=None,
            hint=f"Failed to create issue: {str(e)}"
        )
    
    # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’æ–‡æ¡£
    doc_content = f"""---
status: {"PUBLISHED" if executed else "DRAFT"}
updatedAt: {_timestamp()}
executed: {executed}
---

# Jira å‘å¸ƒè®¡åˆ’ - {input.taskKey}

## æ‰§è¡ŒçŠ¶æ€
{'âœ… å·²æ‰§è¡Œ' if executed else 'âŒ æ‰§è¡Œå¤±è´¥'}

## å·¥å•ä¿¡æ¯
- **é¡¹ç›®**: {detected_project_key}
- **ç±»å‹**: {input.issueType}  
- **æ ‡é¢˜**: {input.summary}
- **åˆ›å»ºç»“æœ**: {'æˆåŠŸ - ' + (created_issue.issueKey or 'N/A') if created_issue and created_issue.issueKey else 'å¤±è´¥'}
- **å·¥å•é“¾æ¥**: {created_issue.url if created_issue and created_issue.url else 'æ— '}

## Gitä¸Šä¸‹æ–‡ä¿¡æ¯
- **å½“å‰åˆ†æ”¯**: {git_context.get('branch_name', 'unknown')}
- **æ£€æµ‹åˆ°çš„Ticket**: {git_context.get('ticket_key', 'æ— ')}
- **è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Key**: {git_context.get('project_key', 'æ— ')}
- **æ£€æµ‹æ¨¡å¼**: {'å¯ç”¨' if input.autoDetectFromBranch else 'ç¦ç”¨'}

## é™„ä»¶ä¸Šä¼ 
{f'- æˆåŠŸ: {len(attachment_results.attached if attachment_results else [])} ä¸ªæ–‡ä»¶' if attachment_results else '- æ— é™„ä»¶'}
{f'- å¤±è´¥: {len(attachment_results.failed if attachment_results else [])} ä¸ªæ–‡ä»¶' if attachment_results else ''}

## åŸå§‹ Payload
```json
{json.dumps(payload, indent=2, ensure_ascii=False)}
```

## æ‰§è¡Œæ—¥å¿—
- å·¥å•åˆ›å»º: {'âœ…' if created_issue and created_issue.issueKey else 'âŒ'}
- é™„ä»¶ä¸Šä¼ : {'âœ…' if attachment_results and not attachment_results.failed else 'âŒ' if attachment_results else 'N/A'}
- å·¥å•å…³è”: {'âœ…' if input.links else 'N/A'}

## åç»­æ­¥éª¤
{f'1. è®¿é—®å·¥å•: {created_issue.url}' if created_issue and created_issue.url else '1. å·¥å•åˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®'}
2. é€šçŸ¥ç›¸å…³äººå‘˜
3. è·Ÿè¸ªå·¥å•è¿›åº¦
"""
    
    doc_path.write_text(doc_content, encoding="utf-8")
    
    return JiraPublishOutput(
        jiraPlanDoc=str(doc_path),
        jiraPlanDocRelative=_relpath(doc_path, project_root),
        jiraPayload=payload,
        createdIssue=created_issue,
        attachmentResults=attachment_results,
        executed=executed
    )


@app.tool()
def review_set_status(input: ReviewStatusInput) -> ReviewStatusOutput:
    """åˆ‡æ¢ä¸»ä»»åŠ¡æ–‡æ¡£çŠ¶æ€ï¼ŒåŒ…å«çŠ¶æ€è½¬æ¢è·¯å¾„éªŒè¯å’Œå†å²è®°å½•ã€‚
    
    âš ï¸ çŠ¶æ€éªŒè¯ï¼š
    1. éªŒè¯çŠ¶æ€è½¬æ¢è·¯å¾„æ˜¯å¦åˆæ³•
    2. è®°å½•çŠ¶æ€å˜æ›´å†å²å’ŒåŸå› 
    3. æ”¯æŒäº‹åŠ¡æ€§çŠ¶æ€æ›´æ–°
    
    ğŸ‘¤ AI æé†’ï¼šçŠ¶æ€æµè½¬é€šå¸¸éœ€è¦äººå·¥å®¡æ ¸å†³ç­–ã€‚å»ºè®®è°ƒç”¨å‰ï¼š
    1. å‘ç”¨æˆ·è¯´æ˜å½“å‰çŠ¶æ€å’Œæ‹Ÿå˜æ›´çš„ç›®æ ‡çŠ¶æ€
    2. ç¡®è®¤å˜æ›´åŸå› å’Œåç»­å½±å“
    3. è·å¾—ç”¨æˆ·æ˜ç¡®åŒæ„åå†æ‰§è¡ŒçŠ¶æ€åˆ‡æ¢
    """
    project_root = _resolve_project_root(input.projectRoot)
    dirs = _ensure_dirs_for(project_root, None)
    main_doc = dirs["tasks_dir"] / f"{input.taskKey}.md"

    # è·å–å½“å‰çŠ¶æ€
    old_status = _read_task_status(project_root, input.taskKey)
    
    # 1. éªŒè¯çŠ¶æ€è½¬æ¢æ˜¯å¦åˆæ³•
    if not _validate_status_transition(old_status, input.newStatus):
        valid_transitions = _STATUS_TRANSITIONS.get(old_status, [])
        raise StatusValidationError(
            f"éæ³•çŠ¶æ€è½¬æ¢: {old_status} -> {input.newStatus}. "
            f"å…è®¸çš„è½¬æ¢: {valid_transitions}"
        )

    # 2. éªŒè¯å¿…éœ€çš„åŸå› è¯´æ˜ï¼ˆå¯¹æŸäº›å…³é”®è½¬æ¢ï¼‰
    critical_transitions = [
        ("PENDING_REVIEW", "CHANGES_REQUESTED"),
        ("APPROVED", "CHANGES_REQUESTED"), 
        ("APPROVED", "PUBLISHED")
    ]
    if (old_status, input.newStatus) in critical_transitions and not input.notes:
        raise StatusValidationError(
            f"å…³é”®çŠ¶æ€è½¬æ¢ {old_status} -> {input.newStatus} å¿…é¡»æä¾›åŸå› è¯´æ˜"
        )

    # è¯»å–æˆ–åˆ›å»º Front Matter
    if main_doc.exists():
        post = frontmatter.load(main_doc)
    else:
        post = frontmatter.Post("")

    metadata = dict(post.metadata or {})
    
    # 3. æ›´æ–°çŠ¶æ€å’Œæ—¶é—´æˆ³
    metadata["status"] = input.newStatus
    metadata["updatedAt"] = _timestamp()
    
    # 4. è®°å½•çŠ¶æ€å˜æ›´å†å²
    reviews = list(metadata.get("reviews", []))
    review_entry = {
        "by": input.by,
        "from": old_status,
        "to": input.newStatus,
        "notes": input.notes or "",
        "time": _timestamp(),
        "valid": True  # æ ‡è®°ä¸ºç»è¿‡éªŒè¯çš„è½¬æ¢
    }
    reviews.append(review_entry)
    metadata["reviews"] = reviews
    
    # 5. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    stats = metadata.get("statusStats", {})
    stats[input.newStatus] = stats.get(input.newStatus, 0) + 1
    stats["totalTransitions"] = stats.get("totalTransitions", 0) + 1
    metadata["statusStats"] = stats
    
    post.metadata = metadata

    # 6. è½ç›˜ä¿å­˜ï¼ˆåŒ…å«äº‹åŠ¡æ€§æ£€æŸ¥ï¼‰
    try:
        main_doc.parent.mkdir(parents=True, exist_ok=True)
        content_str = frontmatter.dumps(post)
        main_doc.write_text(content_str, encoding="utf-8")
        
        # éªŒè¯å†™å…¥æˆåŠŸ
        if _read_task_status(project_root, input.taskKey) != input.newStatus:
            raise StatusValidationError("çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œæ–‡ä»¶å†™å…¥å¼‚å¸¸")
            
    except Exception as e:
        raise StatusValidationError(f"çŠ¶æ€æ›´æ–°å¤±è´¥: {str(e)}")

    return ReviewStatusOutput(taskKey=input.taskKey, oldStatus=old_status, newStatus=input.newStatus)


@app.tool()
def review_validate_checklist(input: ReviewChecklistInput) -> ReviewChecklistOutput:
    """æ‰§è¡Œä¸€è‡´æ€§æ ¡éªŒï¼ˆæ–‡æ¡£å­˜åœ¨æ€§ã€çŠ¶æ€é—¨ç¦ã€é…ç½®å®Œæ•´æ€§ç­‰ï¼‰ï¼Œè¿”å›é€šè¿‡ä¸å¤±è´¥é¡¹ã€‚"""
    failed: List[Dict[str, str]] = []
    project_root = PROJECT_ROOT
    
    # å¯ç”¨çš„æ£€æŸ¥é¡¹
    available_checks = {
        "task_doc_exists": "æ£€æŸ¥ä¸»ä»»åŠ¡æ–‡æ¡£æ˜¯å¦å­˜åœ¨",
        "process_docs_exist": "æ£€æŸ¥è¿‡ç¨‹æ–‡æ¡£æ˜¯å¦å­˜åœ¨", 
        "status_valid": "æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æ˜¯å¦æœ‰æ•ˆ",
        "front_matter_valid": "æ£€æŸ¥ Front Matter æ ¼å¼",
        "mysql_config": "æ£€æŸ¥ MySQL é…ç½®",
        "jira_config": "æ£€æŸ¥ Jira é…ç½®",
        "file_permissions": "æ£€æŸ¥æ–‡ä»¶æƒé™",
        "directory_structure": "æ£€æŸ¥ç›®å½•ç»“æ„"
    }
    
    for check_id in input.checks:
        if check_id not in available_checks:
            failed.append({
                "check": check_id,
                "reason": f"æœªçŸ¥çš„æ£€æŸ¥é¡¹: {check_id}"
            })
            continue
            
        try:
            if check_id == "task_doc_exists":
                main_doc = project_root / "Docs" / ".tasks" / f"{input.taskKey}.md"
                if not main_doc.exists():
                    failed.append({
                        "check": check_id,
                        "reason": f"ä¸»ä»»åŠ¡æ–‡æ¡£ä¸å­˜åœ¨: {main_doc}"
                    })
                    
            elif check_id == "process_docs_exist":
                process_dir = project_root / "Docs" / "ProcessDocuments" / f"task-{input.taskKey}"
                if not process_dir.exists():
                    failed.append({
                        "check": check_id,
                        "reason": f"è¿‡ç¨‹æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {process_dir}"
                    })
                else:
                    required_docs = [
                        "01-Context.md", "02-Design.md", "03-CodePlan.md",
                        "04-TestCurls.md", "05-MySQLVerificationPlan.md", 
                        "06-Integration.md", "07-JiraPublishPlan.md"
                    ]
                    for doc in required_docs:
                        doc_path = process_dir / f"{input.taskKey}_{doc}"
                        if not doc_path.exists():
                            failed.append({
                                "check": check_id,
                                "reason": f"ç¼ºå¤±è¿‡ç¨‹æ–‡æ¡£: {doc_path.name}"
                            })
                            
            elif check_id == "status_valid":
                try:
                    current_status = _read_task_status(project_root, input.taskKey)
                    valid_statuses = ["DRAFT", "PENDING_REVIEW", "APPROVED", "CHANGES_REQUESTED", "PUBLISHED"]
                    if current_status not in valid_statuses:
                        failed.append({
                            "check": check_id,
                            "reason": f"æ— æ•ˆçŠ¶æ€: {current_status}"
                        })
                except Exception as e:
                    failed.append({
                        "check": check_id,
                        "reason": f"æ— æ³•è¯»å–çŠ¶æ€: {str(e)}"
                    })
                    
            elif check_id == "front_matter_valid":
                main_doc = project_root / "Docs" / ".tasks" / f"{input.taskKey}.md"
                if main_doc.exists():
                    try:
                        post = frontmatter.load(main_doc)
                        required_fields = ["status", "taskKey", "title", "owner"]
                        for field in required_fields:
                            if field not in post.metadata:
                                failed.append({
                                    "check": check_id,
                                    "reason": f"ç¼ºå¤± Front Matter å­—æ®µ: {field}"
                                })
                    except Exception as e:
                        failed.append({
                            "check": check_id,
                            "reason": f"Front Matter æ ¼å¼é”™è¯¯: {str(e)}"
                        })
                        
            elif check_id == "mysql_config":
                required_env = ["MYSQL_HOST", "MYSQL_USER", "MYSQL_PASSWORD", "MYSQL_DB"]
                missing_env = [env for env in required_env if not os.getenv(env)]
                if missing_env:
                    failed.append({
                        "check": check_id,
                        "reason": f"ç¼ºå¤± MySQL ç¯å¢ƒå˜é‡: {', '.join(missing_env)}"
                    })
                    
            elif check_id == "jira_config":
                base_url = os.getenv("JIRA_BASE_URL")
                user = os.getenv("JIRA_USER")
                password = os.getenv("JIRA_USER_PASSWORD")
                bearer = os.getenv("JIRA_BEARER_TOKEN")
                token = os.getenv("JIRA_API_TOKEN")
                
                if not base_url:
                    failed.append({
                        "check": check_id,
                        "reason": "ç¼ºå¤± JIRA_BASE_URL ç¯å¢ƒå˜é‡"
                    })
                    
                if not (user and password) and not bearer and not (user and token):
                    failed.append({
                        "check": check_id,
                        "reason": "ç¼ºå¤± Jira è®¤è¯é…ç½®ï¼ˆéœ€è¦ç”¨æˆ·åå¯†ç ã€Bearer Token æˆ– API Tokenï¼‰"
                    })
                    
            elif check_id == "directory_structure":
                required_dirs = [
                    project_root / "Docs",
                    project_root / "Docs" / ".tasks",
                    project_root / "Docs" / "ProcessDocuments"
                ]
                for dir_path in required_dirs:
                    if not dir_path.exists():
                        failed.append({
                            "check": check_id,
                            "reason": f"ç›®å½•ä¸å­˜åœ¨: {dir_path}"
                        })
                        
            elif check_id == "file_permissions":
                docs_dir = project_root / "Docs"
                if docs_dir.exists() and not os.access(docs_dir, os.W_OK):
                    failed.append({
                        "check": check_id,
                        "reason": f"æ²¡æœ‰å†™æƒé™: {docs_dir}"
                    })
                    
        except Exception as e:
            failed.append({
                "check": check_id,
                "reason": f"æ£€æŸ¥æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            })
    
    return ReviewChecklistOutput(passed=len(failed) == 0, failedItems=failed)


# ---------- External MCP Features (Integrated Implementations) ----------

# MySQL MCP parity: execute SQL statements sequentially
class MySQLExecuteInput(BaseModel):
    """ç›´æ¥æ‰§è¡Œ SQL è¯­å¥çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="MySQLExecuteInput", description="ç›´æ¥æ‰§è¡Œ SQL è¯­å¥çš„è¾“å…¥å‚æ•°")
    taskKey: Optional[str] = Field(None, description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†ï¼ˆå¯é€‰ï¼Œç”¨äºå®¡è®¡ï¼‰")
    statements: List[str] = Field(..., description="è¦é¡ºåºæ‰§è¡Œçš„ SQL åˆ—è¡¨")
    continueOnError: bool = Field(False, description="é‡åˆ°é”™è¯¯æ˜¯å¦ç»§ç»­æ‰§è¡Œåç»­è¯­å¥")


class MySQLExecuteOutput(BaseModel):
    results: List[MySQLStatementResult]
    hint: str


def _get_mysql_connection():
    host = os.getenv("MYSQL_HOST")
    user = os.getenv("MYSQL_USER")
    password = os.getenv("MYSQL_PASSWORD")
    database = os.getenv("MYSQL_DB")
    port = int(os.getenv("MYSQL_PORT", "3306"))
    charset = os.getenv("MYSQL_CHARSET", "utf8mb4")
    if not all([host, user, password, database]):
        missing = [n for n, v in [("MYSQL_HOST", host), ("MYSQL_USER", user), ("MYSQL_PASSWORD", password), ("MYSQL_DB", database)] if not v]
        raise ValueError(f"Missing MySQL env vars: {', '.join(missing)}")
    return pymysql.connect(host=host, port=port, user=user, password=password, database=database, charset=charset, cursorclass=pymysql.cursors.DictCursor, autocommit=True)


@app.tool()
def mysql_execute_statements(input: MySQLExecuteInput) -> MySQLExecuteOutput:
    """æ‰§è¡Œä¸€ç»„ SQL è¯­å¥ã€‚
    éœ€è¦ç¯å¢ƒå˜é‡ï¼šMYSQL_HOST, MYSQL_PORT(å¯é€‰), MYSQL_USER, MYSQL_PASSWORD, MYSQL_DB, MYSQL_CHARSET(å¯é€‰)
    """
    results: List[MySQLStatementResult] = []
    try:
        connection = _get_mysql_connection()
    except Exception as exc:  # pragma: no cover
        for sql in input.statements:
            results.append(MySQLStatementResult(sql=sql, success=False, error=f"ConnectionError: {exc}"))
        return MySQLExecuteOutput(results=results, hint="Ensure MySQL env vars are set and reachable")

    try:
        with connection.cursor() as cursor:
            for sql in input.statements:
                try:
                    is_select = sql.strip().lower().startswith("select")
                    cursor.execute(sql)
                    if is_select:
                        rows = cursor.fetchall()
                        results.append(MySQLStatementResult(sql=sql, success=True, rows=rows, rowsAffected=None))
                    else:
                        rows_affected = cursor.rowcount
                        results.append(MySQLStatementResult(sql=sql, success=True, rows=None, rowsAffected=rows_affected))
                except Exception as stmt_exc:  # pragma: no cover
                    results.append(MySQLStatementResult(sql=sql, success=False, error=str(stmt_exc)))
                    if not input.continueOnError:
                        break
    finally:
        try:
            connection.close()
        except Exception:
            pass

    return MySQLExecuteOutput(results=results, hint="Executed using direct MySQL connection from devflow-mcp")


# Jira MCP parity: create issue, attach files, link issues
class JiraCreateIssueInput(BaseModel):
    """åœ¨ Jira ä¸­åˆ›å»ºå·¥å•çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraCreateIssueInput", description="åœ¨ Jira ä¸­åˆ›å»ºå·¥å•çš„è¾“å…¥å‚æ•°")
    projectKey: Optional[str] = Field(None, description="Jira é¡¹ç›® Keyï¼ˆå¯é€‰ï¼Œä¸ºç©ºæ—¶è‡ªåŠ¨ä»Gitåˆ†æ”¯è§£æï¼‰")
    issueType: str = Field(..., description="å·¥å•ç±»å‹ï¼Œå¦‚ Task/Story/Documentation")
    summary: str = Field(..., description="å·¥å•æ ‡é¢˜")
    description: str = Field(..., description="å·¥å•æè¿°")
    labels: List[str] = Field(default_factory=list, description="æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")
    fields: Dict[str, Any] = Field(default_factory=dict, description="é¢å¤–è‡ªå®šä¹‰å­—æ®µï¼ˆå¯é€‰ï¼‰")
    autoDetectFromBranch: bool = Field(True, description="æ˜¯å¦è‡ªåŠ¨ä»Gitåˆ†æ”¯æ£€æµ‹é¡¹ç›®ä¿¡æ¯ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")


def _get_jira_session() -> Session:
    base_url = os.getenv("JIRA_BASE_URL")
    user = os.getenv("JIRA_USER")
    password = os.getenv("JIRA_USER_PASSWORD")
    token = os.getenv("JIRA_API_TOKEN")  # å…¼å®¹æ—§é…ç½®
    bearer = os.getenv("JIRA_BEARER_TOKEN")
    if not base_url:
        raise ValueError("Missing env: JIRA_BASE_URL")
    session = requests.Session()
    session.headers.update({"Accept": "application/json"})
    # ä¼˜å…ˆé¡ºåºï¼šç”¨æˆ·+å¯†ç  > Bearer > ç”¨æˆ·+API Tokenï¼ˆå…¼å®¹ï¼‰
    if user and password:
        session.auth = (user, password)
    elif bearer:
        session.headers.update({"Authorization": f"Bearer {bearer}"})
    elif user and token:
        session.auth = (user, token)
    else:
        raise ValueError("Missing Jira auth: set JIRA_USER + JIRA_USER_PASSWORD (preferred), or JIRA_BEARER_TOKEN, or JIRA_USER + JIRA_API_TOKEN")
    return session


def _jira_api_url(path: str) -> str:
    base_url = os.getenv("JIRA_BASE_URL", "").rstrip("/")
    # æ”¯æŒ context pathï¼Œä¾‹å¦‚ /jiraï¼Œå‚è€ƒ Jira Server 7.x REST ç»“æ„
    context_path = os.getenv("JIRA_CONTEXT_PATH", "").strip()
    if context_path and not context_path.startswith("/"):
        context_path = "/" + context_path
    # Jira Server 7.x é»˜è®¤ä½¿ç”¨ REST v2ã€‚å¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ã€‚
    api_version = os.getenv("JIRA_API_VERSION", "2")
    return f"{base_url}{context_path}/rest/api/{api_version}/{path.lstrip('/')}"


@app.tool()
def jira_create_issue(input: JiraCreateIssueInput) -> JiraCreateIssueOutput:
    """åœ¨ Jira ä¸­åˆ›å»ºå·¥å•ï¼ˆREST v3ï¼Œæ”¯æŒè‡ªå®šä¹‰å­—æ®µï¼‰ã€‚è®¤è¯ä¼˜å…ˆ JIRA_USER/JIRA_USER_PASSWORDã€‚æ”¯æŒä»Gitåˆ†æ”¯è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Keyã€‚"""
    try:
        # è‡ªåŠ¨æ£€æµ‹Gitåˆ†æ”¯ä¿¡æ¯
        detected_project_key = input.projectKey
        if input.autoDetectFromBranch and not detected_project_key:
            git_context = _auto_detect_jira_context()
            detected_project_key = git_context.get("project_key")
            if not detected_project_key:
                return JiraCreateIssueOutput(
                    issueKey=None, 
                    url=None, 
                    hint=f"æ— æ³•ä»å½“å‰åˆ†æ”¯ '{git_context.get('branch_name', 'unknown')}' è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Keyï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š projectKey å‚æ•°"
                )
        
        if not detected_project_key:
            return JiraCreateIssueOutput(
                issueKey=None, 
                url=None, 
                hint="å¿…é¡»æŒ‡å®š projectKey æˆ–å¯ç”¨ autoDetectFromBranch è‡ªåŠ¨æ£€æµ‹"
            )
        
        session = _get_jira_session()
        payload = {"fields": {"project": {"key": detected_project_key}, "issuetype": {"name": input.issueType}, "summary": input.summary, "description": input.description, "labels": input.labels}}
        # åˆå¹¶è‡ªå®šä¹‰å­—æ®µ
        payload["fields"].update(input.fields or {})
        url = _jira_api_url("issue")
        resp = session.post(url, json=payload, timeout=30)
        if resp.status_code >= 400:
            return JiraCreateIssueOutput(issueKey=None, url=None, hint=f"Jira create failed: {resp.status_code} {resp.text}")
        data = resp.json()
        issue_key = data.get("key")
        browse_base = os.getenv("JIRA_BROWSE_BASE", os.getenv("JIRA_BASE_URL", "").rstrip("/"))
        issue_url = f"{browse_base}/browse/{issue_key}" if issue_key else None
        return JiraCreateIssueOutput(issueKey=issue_key, url=issue_url, hint=f"Created via Jira REST API (project: {detected_project_key})")
    except Exception as exc:  # pragma: no cover
        return JiraCreateIssueOutput(issueKey=None, url=None, hint=f"Jira error: {exc}")


class JiraAttachFilesInput(BaseModel):
    """Jira ä¸Šä¼ é™„ä»¶çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraAttachFilesInput", description="Jira ä¸Šä¼ é™„ä»¶çš„è¾“å…¥å‚æ•°")
    issueKey: str = Field(..., description="ç›®æ ‡å·¥å• Key")
    filePaths: List[str] = Field(..., description="è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨")


@app.tool()
def jira_attach_files(input: JiraAttachFilesInput) -> JiraAttachFilesOutput:
    """å‘æŒ‡å®šå·¥å•ä¸Šä¼ é™„ä»¶ï¼ˆéœ€ X-Atlassian-Token:no-checkï¼‰ã€‚æ”¯æŒå¤šæ–‡ä»¶æ‰¹é‡ä¸Šä¼ ï¼Œå¹¶è¿”å›å¤±è´¥åŸå› ã€‚"""
    try:
        session = _get_jira_session()
        url = _jira_api_url(f"issue/{input.issueKey}/attachments")
        session.headers.update({"X-Atlassian-Token": "no-check"})
        attached: List[str] = []
        failed: List[Dict[str, Any]] = []
        for original_path in input.filePaths:
            p = Path(original_path)
            if not p.is_absolute():
                p = (PROJECT_ROOT / p).resolve()
            if not p.is_file():
                failed.append({"path": str(p), "reason": "file not found"})
                continue
            try:
                with open(p, "rb") as f:
                    files = {"file": (p.name, f)}
                    resp = session.post(url, files=files, timeout=60)
                if resp.status_code < 400:
                    attached.append(str(p))
                else:
                    failed.append({
                        "path": str(p),
                        "status": resp.status_code,
                        "reason": resp.text[:500]
                    })
            except Exception as file_exc:  # pragma: no cover
                failed.append({"path": str(p), "reason": str(file_exc)})
        hint = f"Uploaded {len(attached)} file(s), failed {len(failed)} via Jira REST API"
        return JiraAttachFilesOutput(attached=attached, failed=failed, hint=hint)
    except Exception as exc:  # pragma: no cover
        return JiraAttachFilesOutput(attached=[], failed=[{"error": str(exc)}], hint=f"Jira attach error")


class JiraLinkIssuesInput(BaseModel):
    """Jira å…³è”å·¥å•çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraLinkIssuesInput", description="Jira å…³è”å·¥å•çš„è¾“å…¥å‚æ•°")
    inwardIssue: str = Field(..., description="å…³è”æ–¹å‘çš„å†…å‘å·¥å• Key")
    outwardIssue: str = Field(..., description="å…³è”æ–¹å‘çš„å¤–å‘å·¥å• Key")
    linkType: str = Field("relates to", description="å…³è”ç±»å‹ï¼šRelates/Blocks/Duplicate ç­‰")


class JiraLinkIssuesOutput(BaseModel):
    ok: bool
    hint: str


class JiraAddCommentInput(BaseModel):
    """Jira æ·»åŠ è¯„è®ºçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraAddCommentInput", description="Jira æ·»åŠ è¯„è®ºçš„è¾“å…¥å‚æ•°")
    issueKey: str = Field(..., description="ç›®æ ‡å·¥å• Key")
    comment: str = Field(..., description="è¯„è®ºå†…å®¹ï¼Œæ”¯æŒ Jira æ ‡è®°è¯­æ³•")
    visibility: Optional[str] = Field(None, description="è¯„è®ºå¯è§æ€§ï¼špublic/internal æˆ–æŒ‡å®šç”¨æˆ·ç»„")
    mentionUsers: List[str] = Field(default_factory=list, description="è¦@æåŠçš„ç”¨æˆ·åˆ—è¡¨ï¼ˆç”¨æˆ·åæˆ–é‚®ç®±ï¼‰")


class JiraAddCommentOutput(BaseModel):
    commentId: Optional[str] = None
    url: Optional[str] = None
    hint: str


class JiraUpdateStatusInput(BaseModel):
    """Jira æ›´æ–°çŠ¶æ€çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraUpdateStatusInput", description="Jira æ›´æ–°çŠ¶æ€çš„è¾“å…¥å‚æ•°")
    issueKey: str = Field(..., description="ç›®æ ‡å·¥å• Key")
    newStatus: str = Field(..., description="æ–°çŠ¶æ€åç§°")
    transitionComment: Optional[str] = Field(None, description="çŠ¶æ€è½¬æ¢æ—¶æ·»åŠ çš„è¯„è®º")
    validateTransition: bool = Field(True, description="æ˜¯å¦éªŒè¯çŠ¶æ€è½¬æ¢çš„åˆæ³•æ€§")
    fields: Dict[str, Any] = Field(default_factory=dict, description="çŠ¶æ€è½¬æ¢æ—¶éœ€è¦æ›´æ–°çš„å­—æ®µ")


class JiraUpdateStatusOutput(BaseModel):
    success: bool
    oldStatus: Optional[str] = None
    newStatus: Optional[str] = None
    transitionId: Optional[str] = None
    hint: str


class JiraBatchUpdateInput(BaseModel):
    """Jira æ‰¹é‡çŠ¶æ€æ›´æ–°çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraBatchUpdateInput", description="Jira æ‰¹é‡çŠ¶æ€æ›´æ–°çš„è¾“å…¥å‚æ•°")
    updates: List[Dict[str, Any]] = Field(..., description="æ‰¹é‡æ›´æ–°æ“ä½œåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« issueKey, newStatus ç­‰")
    continueOnError: bool = Field(True, description="é‡åˆ°é”™è¯¯æ—¶æ˜¯å¦ç»§ç»­æ‰§è¡Œåç»­æ“ä½œ")
    addComment: bool = Field(True, description="æ˜¯å¦ä¸ºæ¯ä¸ªçŠ¶æ€è½¬æ¢æ·»åŠ è¯„è®º")


class JiraBatchUpdateOutput(BaseModel):
    successful: List[Dict[str, Any]]
    failed: List[Dict[str, Any]]
    summary: Dict[str, int]


class JiraMarkProgressInput(BaseModel):
    """Jira è¿›å±•æ ‡è®°çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraMarkProgressInput", description="Jira è¿›å±•æ ‡è®°çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="DevFlow ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    jiraIssueKey: Optional[str] = Field(None, description="å…³è”çš„ Jira å·¥å• Keyï¼Œä¸ºç©ºæ—¶è‡ªåŠ¨ä»Gitåˆ†æ”¯æ£€æµ‹")
    markType: str = Field("progress", description="æ ‡è®°ç±»å‹ï¼šprogress/milestone/completion/issue/solution")
    title: str = Field(..., description="è¿›å±•æ ‡è®°çš„æ ‡é¢˜")
    description: Optional[str] = Field(None, description="è¯¦ç»†æè¿°ï¼ˆå¯é€‰ï¼‰")
    includeTaskStatus: bool = Field(True, description="æ˜¯å¦åŒ…å«å½“å‰ä»»åŠ¡çŠ¶æ€ä¿¡æ¯")
    includeChanges: bool = Field(True, description="æ˜¯å¦åŒ…å«æœ€è¿‘çš„æ”¹åŠ¨ä¿¡æ¯")
    includeNextSteps: bool = Field(True, description="æ˜¯å¦åŒ…å«ä¸‹ä¸€æ­¥è®¡åˆ’")
    mentionUsers: List[str] = Field(default_factory=list, description="è¦@æåŠçš„ç”¨æˆ·åˆ—è¡¨")
    visibility: Optional[str] = Field("public", description="è¯„è®ºå¯è§æ€§ï¼špublic/internal")
    autoDetectFromBranch: bool = Field(True, description="æ˜¯å¦è‡ªåŠ¨ä»Gitåˆ†æ”¯æ£€æµ‹Jiraä¿¡æ¯")


class JiraMarkProgressOutput(BaseModel):
    taskKey: str
    jiraIssueKey: Optional[str] = None
    commentId: Optional[str] = None
    commentUrl: Optional[str] = None
    markContent: str
    timestamp: str
    success: bool
    hint: str


@app.tool()
def jira_link_issues(input: JiraLinkIssuesInput) -> JiraLinkIssuesOutput:
    """å…³è”ä¸¤ä¸ªå·¥å•ï¼ˆlinkType: Relates/Blocks/Duplicate ç­‰ï¼‰ã€‚"""
    try:
        session = _get_jira_session()
        url = _jira_api_url("issueLink")
        payload = {"type": {"name": input.linkType}, "inwardIssue": {"key": input.inwardIssue}, "outwardIssue": {"key": input.outwardIssue}}
        resp = session.post(url, json=payload, timeout=30)
        if resp.status_code >= 400:
            return JiraLinkIssuesOutput(ok=False, hint=f"Jira link failed: {resp.status_code} {resp.text}")
        return JiraLinkIssuesOutput(ok=True, hint="Linked via Jira REST API")
    except Exception as exc:  # pragma: no cover
        return JiraLinkIssuesOutput(ok=False, hint=f"Jira link error: {exc}")


@app.tool()
def jira_add_comment(input: JiraAddCommentInput) -> JiraAddCommentOutput:
    """å‘ Jira å·¥å•æ·»åŠ è¯„è®ºï¼Œæ”¯æŒå¯Œæ–‡æœ¬ã€ç”¨æˆ·æåŠå’Œå¯è§æ€§æ§åˆ¶ã€‚"""
    try:
        session = _get_jira_session()
        url = _jira_api_url(f"issue/{input.issueKey}/comment")
        
        # æ„å»ºè¯„è®ºå†…å®¹ï¼Œå¤„ç†ç”¨æˆ·æåŠ
        comment_text = input.comment
        if input.mentionUsers:
            mention_text = " ".join([f"[~{user}]" for user in input.mentionUsers])
            comment_text = f"{mention_text}\n\n{comment_text}"
        
        # æ„å»ºè¯·æ±‚ payload
        payload = {
            "body": comment_text
        }
        
        # å¤„ç†å¯è§æ€§è®¾ç½®
        if input.visibility and input.visibility != "public":
            if input.visibility == "internal":
                # å†…éƒ¨å¯è§æ€§ï¼Œé€šå¸¸é™åˆ¶ç»™å¼€å‘å›¢é˜Ÿ
                payload["visibility"] = {
                    "type": "role",
                    "value": "Developers"
                }
            else:
                # æŒ‡å®šç”¨æˆ·ç»„å¯è§
                payload["visibility"] = {
                    "type": "group", 
                    "value": input.visibility
                }
        
        resp = session.post(url, json=payload, timeout=30)
        if resp.status_code >= 400:
            return JiraAddCommentOutput(
                commentId=None, 
                url=None, 
                hint=f"Failed to add comment: {resp.status_code} {resp.text}"
            )
        
        comment_data = resp.json()
        comment_id = comment_data.get("id")
        
        # æ„å»ºè¯„è®ºé“¾æ¥
        base_url = os.getenv("JIRA_BASE_URL", "").rstrip("/")
        comment_url = f"{base_url}/browse/{input.issueKey}?focusedCommentId={comment_id}" if comment_id else None
        
        return JiraAddCommentOutput(
            commentId=comment_id,
            url=comment_url,
            hint=f"Comment added successfully to {input.issueKey}"
        )
        
    except Exception as exc:  # pragma: no cover
        return JiraAddCommentOutput(
            commentId=None, 
            url=None, 
            hint=f"Error adding comment: {exc}"
        )


@app.tool()
def jira_update_status(input: JiraUpdateStatusInput) -> JiraUpdateStatusOutput:
    """æ›´æ–° Jira å·¥å•çŠ¶æ€ï¼Œæ”¯æŒçŠ¶æ€è½¬æ¢éªŒè¯å’Œè¯„è®ºæ·»åŠ ã€‚"""
    try:
        session = _get_jira_session()
        
        # 1. è·å–å½“å‰å·¥å•çŠ¶æ€
        issue_url = _jira_api_url(f"issue/{input.issueKey}")
        issue_resp = session.get(issue_url)
        if issue_resp.status_code >= 400:
            return JiraUpdateStatusOutput(
                success=False,
                hint=f"Failed to fetch issue {input.issueKey}: {issue_resp.status_code}"
            )
        
        issue_data = issue_resp.json()
        current_status = issue_data.get("fields", {}).get("status", {}).get("name", "")
        
        # 2. è·å–å¯ç”¨çš„çŠ¶æ€è½¬æ¢
        transitions_url = _jira_api_url(f"issue/{input.issueKey}/transitions")
        trans_resp = session.get(transitions_url)
        if trans_resp.status_code >= 400:
            return JiraUpdateStatusOutput(
                success=False,
                oldStatus=current_status,
                hint=f"Failed to get transitions: {trans_resp.status_code}"
            )
        
        transitions_data = trans_resp.json()
        transitions = transitions_data.get("transitions", [])
        
        # 3. æŸ¥æ‰¾ç›®æ ‡çŠ¶æ€çš„è½¬æ¢ID
        target_transition = None
        for transition in transitions:
            if transition.get("to", {}).get("name", "").lower() == input.newStatus.lower():
                target_transition = transition
                break
        
        if not target_transition:
            available_statuses = [t.get("to", {}).get("name", "") for t in transitions]
            return JiraUpdateStatusOutput(
                success=False,
                oldStatus=current_status,
                hint=f"Status '{input.newStatus}' not available. Available: {available_statuses}"
            )
        
        # 4. æ‰§è¡ŒçŠ¶æ€è½¬æ¢
        transition_id = target_transition.get("id")
        transition_payload = {
            "transition": {"id": transition_id}
        }
        
        # æ·»åŠ è½¬æ¢è¯„è®º
        if input.transitionComment:
            transition_payload["update"] = {
                "comment": [{"add": {"body": input.transitionComment}}]
            }
        
        # æ·»åŠ éœ€è¦æ›´æ–°çš„å­—æ®µ
        if input.fields:
            if "fields" not in transition_payload:
                transition_payload["fields"] = {}
            transition_payload["fields"].update(input.fields)
        
        # æ‰§è¡Œè½¬æ¢
        transition_resp = session.post(transitions_url, json=transition_payload, timeout=30)
        if transition_resp.status_code >= 400:
            return JiraUpdateStatusOutput(
                success=False,
                oldStatus=current_status,
                transitionId=transition_id,
                hint=f"Status transition failed: {transition_resp.status_code} {transition_resp.text}"
            )
        
        return JiraUpdateStatusOutput(
            success=True,
            oldStatus=current_status,
            newStatus=input.newStatus,
            transitionId=transition_id,
            hint=f"Status updated from '{current_status}' to '{input.newStatus}'"
        )
        
    except Exception as exc:  # pragma: no cover
        return JiraUpdateStatusOutput(
            success=False,
            hint=f"Error updating status: {exc}"
        )


@app.tool()
def jira_batch_update_status(input: JiraBatchUpdateInput) -> JiraBatchUpdateOutput:
    """æ‰¹é‡æ›´æ–°å¤šä¸ª Jira å·¥å•çš„çŠ¶æ€ã€‚"""
    successful = []
    failed = []
    
    for i, update_item in enumerate(input.updates):
        try:
            # éªŒè¯å¿…è¦å‚æ•°
            issue_key = update_item.get("issueKey")
            new_status = update_item.get("newStatus")
            
            if not issue_key or not new_status:
                failed.append({
                    "index": i,
                    "issueKey": issue_key or "unknown",
                    "error": "Missing issueKey or newStatus"
                })
                continue
            
            # æ„å»ºçŠ¶æ€æ›´æ–°è¯·æ±‚
            status_input = JiraUpdateStatusInput(
                issueKey=issue_key,
                newStatus=new_status,
                transitionComment=update_item.get("comment", f"Batch status update to {new_status}" if input.addComment else None),
                validateTransition=update_item.get("validateTransition", True),
                fields=update_item.get("fields", {})
            )
            
            # æ‰§è¡ŒçŠ¶æ€æ›´æ–°
            result = jira_update_status(status_input)
            
            if result.success:
                successful.append({
                    "index": i,
                    "issueKey": issue_key,
                    "oldStatus": result.oldStatus,
                    "newStatus": result.newStatus,
                    "transitionId": result.transitionId
                })
            else:
                failed.append({
                    "index": i,
                    "issueKey": issue_key,
                    "error": result.hint
                })
                
        except Exception as e:
            failed.append({
                "index": i,
                "issueKey": update_item.get("issueKey", "unknown"),
                "error": str(e)
            })
            
            if not input.continueOnError:
                break
    
    summary = {
        "total": len(input.updates),
        "successful": len(successful),
        "failed": len(failed)
    }
    
    return JiraBatchUpdateOutput(
        successful=successful,
        failed=failed,
        summary=summary
    )


@app.tool()
def jira_mark_progress(input: JiraMarkProgressInput) -> JiraMarkProgressOutput:
    """æ ‡è®°ä»»åŠ¡è¿›å±•åˆ° Jiraï¼Œè‡ªåŠ¨ç”ŸæˆåŒ…å«ä»»åŠ¡çŠ¶æ€ã€æ”¹åŠ¨å’Œä¸‹ä¸€æ­¥è®¡åˆ’çš„è¯„è®ºã€‚
    
    è¿™ä¸ªåŠŸèƒ½ä¸“é—¨ä¸º AI è®¾è®¡ï¼Œç”¨äºè‡ªåŠ¨åŒ–åœ°å°†å¼€å‘è¿›å±•ã€çŠ¶æ€å˜æ›´ã€åŠŸèƒ½å®ç°ç­‰ä¿¡æ¯
    ä»¥ç»“æ„åŒ–çš„æ–¹å¼è®°å½•åˆ° Jira å·¥å•ä¸­ï¼Œæä¾›å®Œæ•´çš„é¡¹ç›®è¿½è¸ªå’Œæ²Ÿé€šè®°å½•ã€‚
    """
    project_root = _resolve_project_root(None)
    timestamp = _timestamp()
    
    try:
        # 1. è‡ªåŠ¨æ£€æµ‹ Jira å·¥å•ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
        jira_issue_key = input.jiraIssueKey
        if input.autoDetectFromBranch and not jira_issue_key:
            git_context = _auto_detect_jira_context()
            jira_issue_key = git_context.get("ticket_key")
            
            if not jira_issue_key:
                return JiraMarkProgressOutput(
                    taskKey=input.taskKey,
                    jiraIssueKey=None,
                    commentId=None,
                    commentUrl=None,
                    markContent="",
                    timestamp=timestamp,
                    success=False,
                    hint=f"æ— æ³•è‡ªåŠ¨æ£€æµ‹ Jira å·¥å•ï¼Œå½“å‰åˆ†æ”¯ï¼š{git_context.get('branch_name', 'unknown')}"
                )
        
        if not jira_issue_key:
            return JiraMarkProgressOutput(
                taskKey=input.taskKey,
                jiraIssueKey=None,
                commentId=None,
                commentUrl=None,
                markContent="",
                timestamp=timestamp,
                success=False,
                hint="å¿…é¡»æŒ‡å®š jiraIssueKey æˆ–å¯ç”¨ autoDetectFromBranch"
            )
        
        # 2. ç”Ÿæˆä»»åŠ¡è¿›å±•æŠ¥å‘Š
        progress_report = _generate_task_progress_report(
            project_root, 
            input.taskKey, 
            input.includeTaskStatus, 
            input.includeChanges, 
            input.includeNextSteps
        )
        
        # 3. æ ¹æ®markTypeæ„å»ºè¯„è®ºå†…å®¹
        mark_icons = {
            "progress": "ğŸ”„",
            "milestone": "ğŸ¯", 
            "completion": "âœ…",
            "issue": "âš ï¸",
            "solution": "ğŸ’¡"
        }
        
        icon = mark_icons.get(input.markType, "ğŸ“")
        
        # æ„å»ºè¯„è®ºå†…å®¹ï¼ˆä½¿ç”¨æ™®é€šæ–‡æœ¬æ ¼å¼ï¼‰
        comment_lines = [
            f"{icon} {input.title}",
            f"æ ‡è®°æ—¶é—´: {timestamp}",
            f"æ ‡è®°ç±»å‹: {input.markType}",
            ""
        ]
        
        # æ·»åŠ æè¿°
        if input.description:
            comment_lines.extend([
                "è¯¦ç»†è¯´æ˜:",
                input.description,
                ""
            ])
        
        # æ·»åŠ ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
        if input.includeTaskStatus and progress_report.get("status"):
            status_info = progress_report["status"]
            comment_lines.extend([
                "ğŸ“Š ä»»åŠ¡çŠ¶æ€:",
                f"å½“å‰çŠ¶æ€: {status_info.get('current', 'UNKNOWN')}",
                f"ä»»åŠ¡æ ‡é¢˜: {status_info.get('title', 'N/A')}",
                f"è´Ÿè´£äºº: {status_info.get('owner', 'N/A')}",
                f"æœ€åæ›´æ–°: {status_info.get('updatedAt', 'N/A')}",
                ""
            ])
            
            # æ·»åŠ æœ€è¿‘çš„å®¡æ ¸è®°å½•
            reviews = status_info.get("reviews", [])
            if reviews:
                comment_lines.append("æœ€è¿‘å®¡æ ¸è®°å½•:")
                for review in reviews[-2:]:  # æœ€è¿‘2æ¬¡
                    # å®‰å…¨å¤„ç†æ—¶é—´å­—æ®µï¼Œå¯èƒ½æ˜¯datetimeå¯¹è±¡æˆ–å­—ç¬¦ä¸²
                    review_time = review.get('time', '')
                    if hasattr(review_time, 'strftime'):
                        # å¦‚æœæ˜¯datetimeå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        time_str = review_time.strftime('%Y-%m-%d')
                    elif isinstance(review_time, str):
                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå–å‰10ä¸ªå­—ç¬¦
                        time_str = review_time[:10]
                    else:
                        time_str = str(review_time)[:10] if review_time else 'N/A'
                    
                    comment_lines.append(f"  {review.get('from', '')} -> {review.get('to', '')} by {review.get('by', '')} ({time_str})")
                comment_lines.append("")
        
        # æ·»åŠ è¿‡ç¨‹æ–‡æ¡£çŠ¶æ€
        if input.includeTaskStatus and progress_report.get("processDocuments"):
            comment_lines.extend([
                "ğŸ“‹ æ–‡æ¡£çŠ¶æ€:",
                ""
            ])
            
            for doc in progress_report["processDocuments"]:
                status_emoji = {
                    "DRAFT": "ğŸ“",
                    "APPROVED": "âœ…", 
                    "COMPLETED": "âœ…",
                    "MISSING": "âŒ",
                    "ERROR": "âš ï¸"
                }.get(doc["status"], "â“")
                
                # å®‰å…¨å¤„ç†æ›´æ–°æ—¶é—´å­—æ®µ
                updated_at = doc.get("updatedAt", "")
                if hasattr(updated_at, 'strftime'):
                    # å¦‚æœæ˜¯datetimeå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    updated_time = updated_at.strftime('%Y-%m-%d')
                elif isinstance(updated_at, str):
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå–å‰10ä¸ªå­—ç¬¦
                    updated_time = updated_at[:10] if updated_at else "N/A"
                else:
                    updated_time = str(updated_at)[:10] if updated_at else "N/A"
                comment_lines.append(f"  {doc['name']}: {status_emoji} {doc['status']} ({updated_time})")
            
            comment_lines.append("")
        
        # æ·»åŠ æœ€è¿‘æ”¹åŠ¨
        if input.includeChanges and progress_report.get("recentChanges"):
            comment_lines.extend([
                "ğŸ”§ æœ€è¿‘æ”¹åŠ¨:",
            ])
            
            for commit in progress_report["recentChanges"][:3]:  # æœ€è¿‘3ä¸ªæäº¤
                comment_lines.append(f"  {commit['hash']} {commit['message']} - {commit['author']} ({commit['time']})")
            
            comment_lines.append("")
        
        # æ·»åŠ ä¸‹ä¸€æ­¥è®¡åˆ’
        if input.includeNextSteps and progress_report.get("nextSteps"):
            comment_lines.extend([
                "ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’:",
            ])
            
            for i, step in enumerate(progress_report["nextSteps"], 1):
                comment_lines.append(f"{i}. {step}")
            
            comment_lines.append("")
        
        # æ·»åŠ æ—¶é—´æˆ³å’Œç­¾å
        comment_lines.extend([
            "---",
            f"è‡ªåŠ¨ç”Ÿæˆäº {timestamp} by DevFlow MCP"
        ])
        
        comment_content = "\n".join(comment_lines)
        
        # 4. æ·»åŠ è¯„è®ºåˆ° Jira
        comment_input = JiraAddCommentInput(
            issueKey=jira_issue_key,
            comment=comment_content,
            visibility=input.visibility,
            mentionUsers=input.mentionUsers
        )
        
        comment_result = jira_add_comment(comment_input)
        
        return JiraMarkProgressOutput(
            taskKey=input.taskKey,
            jiraIssueKey=jira_issue_key,
            commentId=comment_result.commentId,
            commentUrl=comment_result.url,
            markContent=comment_content,
            timestamp=timestamp,
            success=comment_result.commentId is not None,
            hint=comment_result.hint
        )
        
    except Exception as e:
        return JiraMarkProgressOutput(
            taskKey=input.taskKey,
            jiraIssueKey=jira_issue_key,
            commentId=None,
            commentUrl=None,
            markContent="",
            timestamp=timestamp,
            success=False,
            hint=f"æ ‡è®°è¿›å±•å¤±è´¥: {str(e)}"
        )

# ---------- Wiki (Confluence) é›†æˆåŠŸèƒ½ ----------

def _get_wiki_session() -> Session:
    """è·å– Wiki (Confluence) ä¼šè¯"""
    session = Session()
    
    # åŸºæœ¬è®¤è¯
    wiki_user = os.getenv("WIKI_USER")
    wiki_password = os.getenv("WIKI_USER_PASSWORD") or os.getenv("WIKI_PASSWORD")
    
    if wiki_user and wiki_password:
        session.auth = (wiki_user, wiki_password)
    
    # è®¾ç½®è¯·æ±‚å¤´
    session.headers.update({
        "Content-Type": "application/json",
        "Accept": "application/json",
        "User-Agent": "DevFlow-MCP/1.0"
    })
    
    return session


def _wiki_api_url(endpoint: str) -> str:
    """æ„å»º Wiki API URL"""
    base_url = os.getenv("WIKI_BASE_URL", "").rstrip("/")
    context_path = os.getenv("WIKI_CONTEXT_PATH", "").strip("/")
    api_version = os.getenv("WIKI_API_VERSION", "latest")
    
    # æ ¹æ®æ‚¨çš„Wikiç³»ç»ŸAPIç»“æ„è°ƒæ•´
    if context_path:
        if api_version == "1":
            return f"{base_url}/{context_path}/rest/api/{endpoint}"
        elif api_version == "1.0":
            return f"{base_url}/{context_path}/rest/api/1.0/{endpoint}"
        elif api_version == "" or api_version == "latest":
            return f"{base_url}/{context_path}/rest/api/{endpoint}"
        else:
            return f"{base_url}/{context_path}/rest/api/{api_version}/{endpoint}"
    else:
        if api_version == "1":
            return f"{base_url}/rest/api/{endpoint}"
        elif api_version == "1.0":
            return f"{base_url}/rest/api/1.0/{endpoint}"
        elif api_version == "" or api_version == "latest":
            return f"{base_url}/rest/api/{endpoint}"
        else:
            return f"{base_url}/rest/api/{api_version}/{endpoint}"


def _parse_wiki_url(wiki_url: str) -> Dict[str, Optional[str]]:
    """è§£æWiki URLï¼Œæå–ç©ºé—´é”®å’Œé¡µé¢æ ‡é¢˜æˆ–ID"""
    try:
        from urllib.parse import urlparse, parse_qs, unquote
        
        parsed = urlparse(wiki_url)
        result = {"spaceKey": None, "pageTitle": None, "pageId": None}
        
        # å¤„ç†ä¸åŒç±»å‹çš„Wiki URL
        path = parsed.path
        query = parse_qs(parsed.query)
        
        # ç±»å‹1: /display/SPACE/Page+Title
        if "/display/" in path:
            parts = path.split("/display/")
            if len(parts) > 1:
                remaining = parts[1].split("/", 1)
                if len(remaining) >= 1:
                    result["spaceKey"] = remaining[0]
                if len(remaining) >= 2:
                    # è§£ç URLç¼–ç çš„æ ‡é¢˜ï¼Œå¹¶å°†+æ›¿æ¢ä¸ºç©ºæ ¼
                    page_title = unquote(remaining[1]).replace("+", " ")
                    result["pageTitle"] = page_title
        
        # ç±»å‹2: /pages/viewpage.action?spaceKey=SPACE&title=Page+Title
        elif "/pages/viewpage.action" in path:
            if "spaceKey" in query:
                result["spaceKey"] = query["spaceKey"][0]
            if "title" in query:
                result["pageTitle"] = unquote(query["title"][0]).replace("+", " ")
            if "pageId" in query:
                result["pageId"] = query["pageId"][0]
        
        # ç±»å‹3: /spaces/SPACE/pages/123456/Page+Title
        elif "/spaces/" in path and "/pages/" in path:
            parts = path.split("/")
            try:
                space_idx = parts.index("spaces")
                pages_idx = parts.index("pages")
                if space_idx + 1 < len(parts):
                    result["spaceKey"] = parts[space_idx + 1]
                if pages_idx + 1 < len(parts):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—ID
                    potential_id = parts[pages_idx + 1]
                    if potential_id.isdigit():
                        result["pageId"] = potential_id
                        # å¦‚æœè¿˜æœ‰åç»­éƒ¨åˆ†ï¼Œé‚£å¯èƒ½æ˜¯æ ‡é¢˜
                        if pages_idx + 2 < len(parts):
                            result["pageTitle"] = unquote(parts[pages_idx + 2]).replace("+", " ")
            except ValueError:
                pass
        
        return result
        
    except Exception as e:
        print(f"Error parsing Wiki URL: {e}")
        return {"spaceKey": None, "pageTitle": None, "pageId": None}


class WikiCreatePageInput(BaseModel):
    """Wiki åˆ›å»ºé¡µé¢çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiCreatePageInput", description="Wiki åˆ›å»ºé¡µé¢çš„è¾“å…¥å‚æ•°")
    spaceKey: str = Field(..., description="ç©ºé—´é”®å€¼")
    title: str = Field(..., description="é¡µé¢æ ‡é¢˜")
    content: str = Field(..., description="é¡µé¢å†…å®¹ï¼ˆæ”¯æŒConfluenceå­˜å‚¨æ ¼å¼æˆ–HTMLï¼‰")
    parentPageId: Optional[str] = Field(None, description="çˆ¶é¡µé¢IDï¼ˆå¯é€‰ï¼‰")
    labels: List[str] = Field(default_factory=list, description="é¡µé¢æ ‡ç­¾")
    contentFormat: str = Field("storage", description="å†…å®¹æ ¼å¼ï¼šstorage/view/html")


class WikiCreatePageOutput(BaseModel):
    pageId: Optional[str] = None
    title: str
    url: Optional[str] = None
    spaceKey: str
    version: int = 1
    hint: str


class WikiUpdatePageInput(BaseModel):
    """Wiki æ›´æ–°é¡µé¢çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiUpdatePageInput", description="Wiki æ›´æ–°é¡µé¢çš„è¾“å…¥å‚æ•°")
    pageId: str = Field(..., description="é¡µé¢ID")
    title: Optional[str] = Field(None, description="æ–°æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰")
    content: Optional[str] = Field(None, description="æ–°å†…å®¹ï¼ˆå¯é€‰ï¼‰")
    labels: Optional[List[str]] = Field(None, description="æ–°æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰")
    contentFormat: str = Field("storage", description="å†…å®¹æ ¼å¼ï¼šstorage/view/html")
    versionComment: str = Field("Updated by DevFlow MCP", description="ç‰ˆæœ¬æ³¨é‡Š")


class WikiUpdatePageOutput(BaseModel):
    pageId: str
    title: str
    url: Optional[str] = None
    version: int
    hint: str


class WikiSearchInput(BaseModel):
    """Wiki æœç´¢çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiSearchInput", description="Wiki æœç´¢çš„è¾“å…¥å‚æ•°")
    query: str = Field(..., description="æœç´¢æŸ¥è¯¢")
    spaceKey: Optional[str] = Field(None, description="é™åˆ¶æœç´¢çš„ç©ºé—´ï¼ˆå¯é€‰ï¼‰")
    searchType: str = Field("content", description="æœç´¢ç±»å‹ï¼šcontent/title/space")
    limit: int = Field(10, description="è¿”å›ç»“æœæ•°é‡é™åˆ¶")
    includeContent: bool = Field(False, description="æ˜¯å¦åŒ…å«é¡µé¢å†…å®¹")


class WikiSearchOutput(BaseModel):
    results: List[Dict[str, Any]]
    totalResults: int
    hint: str


class WikiGetPageInput(BaseModel):
    """Wiki è·å–é¡µé¢çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiGetPageInput", description="Wiki è·å–é¡µé¢çš„è¾“å…¥å‚æ•°")
    pageId: Optional[str] = Field(None, description="é¡µé¢ID")
    spaceKey: Optional[str] = Field(None, description="ç©ºé—´é”®å€¼")
    title: Optional[str] = Field(None, description="é¡µé¢æ ‡é¢˜")
    expand: List[str] = Field(default_factory=lambda: ["body.storage", "version", "space"], description="æ‰©å±•å­—æ®µ")


class WikiGetPageOutput(BaseModel):
    pageId: str
    title: str
    content: str
    spaceKey: str
    version: int
    url: Optional[str] = None
    labels: List[str] = Field(default_factory=list)
    lastModified: str
    hint: str


class WikiPublishTaskInput(BaseModel):
    """Wiki å‘å¸ƒä»»åŠ¡æ–‡æ¡£çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiPublishTaskInput", description="Wiki å‘å¸ƒä»»åŠ¡æ–‡æ¡£çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    spaceKey: str = Field(..., description="ç›®æ ‡Wikiç©ºé—´")
    parentPageTitle: Optional[str] = Field(None, description="çˆ¶é¡µé¢æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰")
    includeProcessDocs: bool = Field(True, description="æ˜¯å¦åŒ…å«è¿‡ç¨‹æ–‡æ¡£")
    includeIntegrationDoc: bool = Field(True, description="æ˜¯å¦åŒ…å«é›†æˆæ–‡æ¡£")
    templateStyle: str = Field("standard", description="æ¨¡æ¿æ ·å¼ï¼šstandard/compact/detailed")
    autoLink: bool = Field(True, description="æ˜¯å¦è‡ªåŠ¨åˆ›å»ºé¡µé¢é—´é“¾æ¥")
    projectRoot: Optional[str] = Field(None, description="é¡¹ç›®æ ¹ç›®å½•")


class WikiPublishTaskOutput(BaseModel):
    taskKey: str
    mainPageId: str
    mainPageUrl: str
    publishedPages: List[Dict[str, str]]
    spaceKey: str
    hint: str


class WikiAddCommentInput(BaseModel):
    """Wiki æ·»åŠ è¯„è®ºçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiAddCommentInput", description="Wiki æ·»åŠ è¯„è®ºçš„è¾“å…¥å‚æ•°")
    pageId: str = Field(..., description="é¡µé¢ID")
    comment: str = Field(..., description="è¯„è®ºå†…å®¹ï¼Œæ”¯æŒHTMLæ ¼å¼")
    parentCommentId: Optional[str] = Field(None, description="çˆ¶è¯„è®ºIDï¼Œç”¨äºå›å¤è¯„è®º")


class WikiAddCommentOutput(BaseModel):
    commentId: Optional[str] = None
    pageId: str
    commentUrl: Optional[str] = None
    hint: str


class WikiGetCommentsInput(BaseModel):
    """Wiki è·å–è¯„è®ºçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiGetCommentsInput", description="Wiki è·å–è¯„è®ºçš„è¾“å…¥å‚æ•°")
    pageId: str = Field(..., description="é¡µé¢ID")
    limit: int = Field(10, description="è¿”å›è¯„è®ºæ•°é‡é™åˆ¶")
    includeReplies: bool = Field(True, description="æ˜¯å¦åŒ…å«å›å¤è¯„è®º")


class WikiGetCommentsOutput(BaseModel):
    pageId: str
    comments: List[Dict[str, Any]]
    totalComments: int
    hint: str


class WikiUpdateCommentInput(BaseModel):
    """Wiki æ›´æ–°è¯„è®ºçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiUpdateCommentInput", description="Wiki æ›´æ–°è¯„è®ºçš„è¾“å…¥å‚æ•°")
    commentId: str = Field(..., description="è¯„è®ºID")
    comment: str = Field(..., description="æ–°çš„è¯„è®ºå†…å®¹")


class WikiUpdateCommentOutput(BaseModel):
    commentId: str
    commentUrl: Optional[str] = None
    hint: str


class WikiDeleteCommentInput(BaseModel):
    """Wiki åˆ é™¤è¯„è®ºçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiDeleteCommentInput", description="Wiki åˆ é™¤è¯„è®ºçš„è¾“å…¥å‚æ•°")
    commentId: str = Field(..., description="è¦åˆ é™¤çš„è¯„è®ºID")


class WikiDeleteCommentOutput(BaseModel):
    commentId: str
    success: bool
    hint: str


class WikiReadUrlInput(BaseModel):
    """Wiki æ ¹æ®URLè¯»å–é¡µé¢çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="WikiReadUrlInput", description="Wiki æ ¹æ®URLè¯»å–é¡µé¢çš„è¾“å…¥å‚æ•°")
    url: str = Field(..., description="Wikié¡µé¢çš„å®Œæ•´URL")
    includeComments: bool = Field(False, description="æ˜¯å¦åŒ…å«é¡µé¢è¯„è®º")
    includeAttachments: bool = Field(False, description="æ˜¯å¦åŒ…å«é¡µé¢é™„ä»¶ä¿¡æ¯")


class WikiReadUrlOutput(BaseModel):
    pageId: str
    title: str
    content: str
    spaceKey: str
    spaceName: str
    version: int
    url: str
    labels: List[str] = Field(default_factory=list)
    lastModified: str
    author: str
    comments: List[Dict[str, Any]] = Field(default_factory=list)
    attachments: List[Dict[str, Any]] = Field(default_factory=list)
    breadcrumb: List[Dict[str, str]] = Field(default_factory=list)
    hint: str


class WikiDiagnosticInput(BaseModel):
    pageId: str
    testComment: Optional[str] = "æµ‹è¯•è¯„è®º"


class WikiDiagnosticOutput(BaseModel):
    pageId: str
    apiTests: Dict[str, Any]
    recommendations: List[str]
    hint: str


@app.tool()
def wiki_create_page(input: WikiCreatePageInput) -> WikiCreatePageOutput:
    """åœ¨ Wiki (Confluence) ä¸­åˆ›å»ºæ–°é¡µé¢ã€‚"""
    try:
        session = _get_wiki_session()
        url = _wiki_api_url("content")
        
        # æ„å»ºé¡µé¢æ•°æ®
        page_data = {
            "type": "page",
            "title": input.title,
            "space": {"key": input.spaceKey},
            "body": {
                input.contentFormat: {
                    "value": input.content,
                    "representation": input.contentFormat
                }
            }
        }
        
        # æ·»åŠ çˆ¶é¡µé¢
        if input.parentPageId:
            page_data["ancestors"] = [{"id": input.parentPageId}]
        
        # æ·»åŠ æ ‡ç­¾
        if input.labels:
            page_data["metadata"] = {
                "labels": [{"name": label} for label in input.labels]
            }
        
        resp = session.post(url, json=page_data, timeout=30)
        
        if resp.status_code >= 400:
            return WikiCreatePageOutput(
                pageId=None,
                title=input.title,
                url=None,
                spaceKey=input.spaceKey,
                version=1,
                hint=f"Failed to create page: {resp.status_code} {resp.text}"
            )
        
        result = resp.json()
        page_id = result.get("id")
        
        # æ„å»ºé¡µé¢URL
        base_url = os.getenv("WIKI_BASE_URL", "").rstrip("/")
        page_url = f"{base_url}/display/{input.spaceKey}/{input.title.replace(' ', '+')}" if page_id else None
        
        return WikiCreatePageOutput(
            pageId=page_id,
            title=result.get("title", input.title),
            url=page_url,
            spaceKey=input.spaceKey,
            version=result.get("version", {}).get("number", 1),
            hint=f"Page created successfully in space {input.spaceKey}"
        )
        
    except Exception as e:
        return WikiCreatePageOutput(
            pageId=None,
            title=input.title,
            url=None,
            spaceKey=input.spaceKey,
            version=1,
            hint=f"Error creating page: {str(e)}"
        )


@app.tool()
def wiki_update_page(input: WikiUpdatePageInput) -> WikiUpdatePageOutput:
    """æ›´æ–° Wiki (Confluence) é¡µé¢å†…å®¹ã€‚"""
    try:
        session = _get_wiki_session()
        
        # å…ˆè·å–å½“å‰é¡µé¢ä¿¡æ¯
        get_url = _wiki_api_url(f"content/{input.pageId}?expand=version,space")
        get_resp = session.get(get_url, timeout=30)
        
        if get_resp.status_code >= 400:
            return WikiUpdatePageOutput(
                pageId=input.pageId,
                title="",
                url=None,
                version=1,
                hint=f"Failed to get current page: {get_resp.status_code}"
            )
        
        current_page = get_resp.json()
        current_version = current_page.get("version", {}).get("number", 1)
        current_title = current_page.get("title", "")
        space_key = current_page.get("space", {}).get("key", "")
        
        # æ„å»ºæ›´æ–°æ•°æ®
        update_data = {
            "id": input.pageId,
            "type": "page",
            "title": input.title or current_title,
            "version": {
                "number": current_version + 1,
                "message": input.versionComment
            }
        }
        
        # æ›´æ–°å†…å®¹
        if input.content:
            update_data["body"] = {
                input.contentFormat: {
                    "value": input.content,
                    "representation": input.contentFormat
                }
            }
        
        # æ›´æ–°æ ‡ç­¾
        if input.labels is not None:
            update_data["metadata"] = {
                "labels": [{"name": label} for label in input.labels]
            }
        
        # å‘é€æ›´æ–°è¯·æ±‚
        update_url = _wiki_api_url(f"content/{input.pageId}")
        resp = session.put(update_url, json=update_data, timeout=30)
        
        if resp.status_code >= 400:
            return WikiUpdatePageOutput(
                pageId=input.pageId,
                title=current_title,
                url=None,
                version=current_version,
                hint=f"Failed to update page: {resp.status_code} {resp.text}"
            )
        
        result = resp.json()
        
        # æ„å»ºé¡µé¢URL
        base_url = os.getenv("WIKI_BASE_URL", "").rstrip("/")
        page_title = result.get("title", current_title)
        page_url = f"{base_url}/display/{space_key}/{page_title.replace(' ', '+')}"
        
        return WikiUpdatePageOutput(
            pageId=input.pageId,
            title=page_title,
            url=page_url,
            version=result.get("version", {}).get("number", current_version + 1),
            hint=f"Page updated successfully (version {current_version + 1})"
        )
        
    except Exception as e:
        return WikiUpdatePageOutput(
            pageId=input.pageId,
            title="",
            url=None,
            version=1,
            hint=f"Error updating page: {str(e)}"
        )


@app.tool()
def wiki_search_pages(input: WikiSearchInput) -> WikiSearchOutput:
    """åœ¨ Wiki (Confluence) ä¸­æœç´¢é¡µé¢ã€‚"""
    try:
        session = _get_wiki_session()
        
        # æ„å»ºæœç´¢å‚æ•°
        params = {
            "cql": f"text ~ \"{input.query}\"",
            "limit": input.limit
        }
        
        # é™åˆ¶æœç´¢ç©ºé—´
        if input.spaceKey:
            params["cql"] += f" and space = {input.spaceKey}"
        
        # æ ¹æ®æœç´¢ç±»å‹è°ƒæ•´æŸ¥è¯¢
        if input.searchType == "title":
            params["cql"] = f"title ~ \"{input.query}\""
            if input.spaceKey:
                params["cql"] += f" and space = {input.spaceKey}"
        elif input.searchType == "space":
            params["cql"] = f"space = {input.query}"
        
        # è®¾ç½®æ‰©å±•å­—æ®µ
        expand_fields = ["version", "space"]
        if input.includeContent:
            expand_fields.append("body.storage")
        params["expand"] = ",".join(expand_fields)
        
        url = _wiki_api_url("content/search")
        resp = session.get(url, params=params, timeout=30)
        
        if resp.status_code >= 400:
            return WikiSearchOutput(
                results=[],
                totalResults=0,
                hint=f"Search failed: {resp.status_code} {resp.text}"
            )
        
        data = resp.json()
        results = data.get("results", [])
        
        # å¤„ç†æœç´¢ç»“æœ
        processed_results = []
        for result in results:
            processed_result = {
                "id": result.get("id"),
                "title": result.get("title"),
                "type": result.get("type"),
                "spaceKey": result.get("space", {}).get("key"),
                "spaceName": result.get("space", {}).get("name"),
                "version": result.get("version", {}).get("number"),
                "lastModified": result.get("version", {}).get("when"),
                "url": result.get("_links", {}).get("webui")
            }
            
            # æ·»åŠ å†…å®¹ï¼ˆå¦‚æœè¯·æ±‚ï¼‰
            if input.includeContent and "body" in result:
                processed_result["content"] = result.get("body", {}).get("storage", {}).get("value", "")
            
            processed_results.append(processed_result)
        
        return WikiSearchOutput(
            results=processed_results,
            totalResults=data.get("size", len(results)),
            hint=f"Found {len(results)} results for query: {input.query}"
        )
        
    except Exception as e:
        return WikiSearchOutput(
            results=[],
            totalResults=0,
            hint=f"Search error: {str(e)}"
        )


@app.tool()
def wiki_get_page(input: WikiGetPageInput) -> WikiGetPageOutput:
    """è·å– Wiki (Confluence) é¡µé¢è¯¦æƒ…ã€‚"""
    try:
        session = _get_wiki_session()
        
        # ç¡®å®šé¡µé¢æŸ¥è¯¢æ–¹å¼
        if input.pageId:
            url = _wiki_api_url(f"content/{input.pageId}")
        elif input.spaceKey and input.title:
            # é€šè¿‡ç©ºé—´å’Œæ ‡é¢˜æœç´¢
            search_params = {
                "spaceKey": input.spaceKey,
                "title": input.title,
                "expand": ",".join(input.expand)
            }
            url = _wiki_api_url("content")
        else:
            return WikiGetPageOutput(
                pageId="",
                title="",
                content="",
                spaceKey="",
                version=0,
                url=None,
                lastModified="",
                hint="Must provide either pageId or both spaceKey and title"
            )
        
        # è®¾ç½®æ‰©å±•å‚æ•°
        params = {"expand": ",".join(input.expand)}
        if not input.pageId:
            params.update(search_params)
        
        resp = session.get(url, params=params, timeout=30)
        
        if resp.status_code >= 400:
            return WikiGetPageOutput(
                pageId="",
                title="",
                content="",
                spaceKey="",
                version=0,
                url=None,
                lastModified="",
                hint=f"Failed to get page: {resp.status_code} {resp.text}"
            )
        
        data = resp.json()
        
        # å¤„ç†æœç´¢ç»“æœï¼ˆå¦‚æœæ˜¯é€šè¿‡æ ‡é¢˜æœç´¢ï¼‰
        if not input.pageId and "results" in data:
            if not data["results"]:
                return WikiGetPageOutput(
                    pageId="",
                    title=input.title or "",
                    content="",
                    spaceKey=input.spaceKey or "",
                    version=0,
                    url=None,
                    lastModified="",
                    hint=f"Page not found: {input.title}"
                )
            data = data["results"][0]
        
        # æå–é¡µé¢ä¿¡æ¯
        page_id = data.get("id", "")
        title = data.get("title", "")
        space_key = data.get("space", {}).get("key", "")
        version = data.get("version", {}).get("number", 0)
        last_modified = data.get("version", {}).get("when", "")
        
        # æå–å†…å®¹
        content = ""
        if "body" in data and "storage" in data["body"]:
            content = data["body"]["storage"].get("value", "")
        
        # æå–æ ‡ç­¾
        labels = []
        if "metadata" in data and "labels" in data["metadata"]:
            labels = [label.get("name", "") for label in data["metadata"]["labels"].get("results", [])]
        
        # æ„å»ºé¡µé¢URL
        base_url = os.getenv("WIKI_BASE_URL", "").rstrip("/")
        page_url = f"{base_url}/display/{space_key}/{title.replace(' ', '+')}" if page_id else None
        
        return WikiGetPageOutput(
            pageId=page_id,
            title=title,
            content=content,
            spaceKey=space_key,
            version=version,
            url=page_url,
            labels=labels,
            lastModified=last_modified,
            hint=f"Page retrieved successfully: {title}"
        )
        
    except Exception as e:
        return WikiGetPageOutput(
            pageId="",
            title="",
            content="",
            spaceKey="",
            version=0,
            url=None,
            lastModified="",
            hint=f"Error getting page: {str(e)}"
        )


@app.tool()
def wiki_read_url(input: WikiReadUrlInput) -> WikiReadUrlOutput:
    """æ ¹æ®Wiki URLç›´æ¥è¯»å–é¡µé¢å†…å®¹ï¼Œæ”¯æŒå¤šç§URLæ ¼å¼ã€‚"""
    try:
        # è§£æURLè·å–é¡µé¢ä¿¡æ¯
        parsed_info = _parse_wiki_url(input.url)
        
        if not parsed_info["spaceKey"] and not parsed_info["pageId"]:
            return WikiReadUrlOutput(
                pageId="",
                title="",
                content="",
                spaceKey="",
                spaceName="",
                version=0,
                url=input.url,
                lastModified="",
                author="",
                hint="æ— æ³•ä»URLä¸­è§£æå‡ºæœ‰æ•ˆçš„ç©ºé—´é”®æˆ–é¡µé¢ID"
            )
        
        session = _get_wiki_session()
        
        # æ ¹æ®è§£æç»“æœè·å–é¡µé¢
        if parsed_info["pageId"]:
            # é€šè¿‡é¡µé¢IDè·å–
            page_result = wiki_get_page(WikiGetPageInput(
                pageId=parsed_info["pageId"],
                expand=["body.storage", "version", "space", "metadata.labels", "ancestors"]
            ))
        elif parsed_info["spaceKey"] and parsed_info["pageTitle"]:
            # é€šè¿‡ç©ºé—´å’Œæ ‡é¢˜è·å–
            page_result = wiki_get_page(WikiGetPageInput(
                spaceKey=parsed_info["spaceKey"],
                title=parsed_info["pageTitle"],
                expand=["body.storage", "version", "space", "metadata.labels", "ancestors"]
            ))
        else:
            return WikiReadUrlOutput(
                pageId="",
                title="",
                content="",
                spaceKey="",
                spaceName="",
                version=0,
                url=input.url,
                lastModified="",
                author="",
                hint="URLè§£æä¸å®Œæ•´ï¼Œæ— æ³•å®šä½é¡µé¢"
            )
        
        if not page_result.pageId:
            return WikiReadUrlOutput(
                pageId="",
                title="",
                content="",
                spaceKey=parsed_info.get("spaceKey", ""),
                spaceName="",
                version=0,
                url=input.url,
                lastModified="",
                author="",
                hint=f"é¡µé¢æœªæ‰¾åˆ°: {page_result.hint}"
            )
        
        # è·å–ç©ºé—´ä¿¡æ¯
        space_name = ""
        try:
            space_url = _wiki_api_url(f"space/{page_result.spaceKey}")
            space_resp = session.get(space_url, timeout=30)
            if space_resp.status_code == 200:
                space_data = space_resp.json()
                space_name = space_data.get("name", "")
        except:
            pass
        
        # è·å–ä½œè€…ä¿¡æ¯
        author = ""
        try:
            page_url = _wiki_api_url(f"content/{page_result.pageId}?expand=version.by")
            page_resp = session.get(page_url, timeout=30)
            if page_resp.status_code == 200:
                page_data = page_resp.json()
                author = page_data.get("version", {}).get("by", {}).get("displayName", "")
        except:
            pass
        
        # è·å–é¢åŒ…å±‘å¯¼èˆª
        breadcrumb = []
        try:
            ancestors_url = _wiki_api_url(f"content/{page_result.pageId}?expand=ancestors")
            ancestors_resp = session.get(ancestors_url, timeout=30)
            if ancestors_resp.status_code == 200:
                ancestors_data = ancestors_resp.json()
                ancestors = ancestors_data.get("ancestors", [])
                for ancestor in ancestors:
                    breadcrumb.append({
                        "id": ancestor.get("id", ""),
                        "title": ancestor.get("title", ""),
                        "type": ancestor.get("type", "")
                    })
        except:
            pass
        
        result = WikiReadUrlOutput(
            pageId=page_result.pageId,
            title=page_result.title,
            content=page_result.content,
            spaceKey=page_result.spaceKey,
            spaceName=space_name,
            version=page_result.version,
            url=input.url,
            labels=page_result.labels,
            lastModified=page_result.lastModified,
            author=author,
            breadcrumb=breadcrumb,
            hint=f"æˆåŠŸè¯»å–é¡µé¢: {page_result.title}"
        )
        
        # è·å–è¯„è®ºï¼ˆå¦‚æœéœ€è¦ï¼‰
        if input.includeComments:
            try:
                comments_result = wiki_get_comments(WikiGetCommentsInput(
                    pageId=page_result.pageId,
                    limit=50,
                    includeReplies=True
                ))
                result.comments = comments_result.comments
            except Exception as e:
                print(f"Failed to get comments: {e}")
        
        # è·å–é™„ä»¶ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if input.includeAttachments:
            try:
                attachments_url = _wiki_api_url(f"content/{page_result.pageId}/child/attachment")
                attachments_resp = session.get(attachments_url, timeout=30)
                if attachments_resp.status_code == 200:
                    attachments_data = attachments_resp.json()
                    attachments = []
                    for attachment in attachments_data.get("results", []):
                        attachments.append({
                            "id": attachment.get("id"),
                            "title": attachment.get("title"),
                            "mediaType": attachment.get("metadata", {}).get("mediaType", ""),
                            "fileSize": attachment.get("extensions", {}).get("fileSize", 0),
                            "downloadUrl": attachment.get("_links", {}).get("download", ""),
                            "version": attachment.get("version", {}).get("number", 1),
                            "createdDate": attachment.get("version", {}).get("when", "")
                        })
                    result.attachments = attachments
            except Exception as e:
                print(f"Failed to get attachments: {e}")
        
        return result
        
    except Exception as e:
        return WikiReadUrlOutput(
            pageId="",
            title="",
            content="",
            spaceKey="",
            spaceName="",
            version=0,
            url=input.url,
            lastModified="",
            author="",
            hint=f"è¯»å–é¡µé¢æ—¶å‡ºé”™: {str(e)}"
        )


@app.tool()
def wiki_add_comment(input: WikiAddCommentInput) -> WikiAddCommentOutput:
    """å‘ Wiki é¡µé¢æ·»åŠ è¯„è®ºã€‚"""
    try:
        session = _get_wiki_session()
        
        # é¦–å…ˆå°è¯•ä½¿ç”¨TinyMCE APIï¼ˆæ›´ç°ä»£çš„æ–¹å¼ï¼‰
        base_url = os.getenv("WIKI_BASE_URL", "").rstrip("/")
        context_path = os.getenv("WIKI_CONTEXT_PATH", "").strip("/")
        
        # å°è¯•å¤šç§TinyMCE APIç‰ˆæœ¬
        tinymce_urls = []
        if context_path:
            tinymce_urls = [
                f"{base_url}/{context_path}/rest/tinymce/1/content/{input.pageId}/comment",
                f"{base_url}/{context_path}/rest/tinymce/1.0/content/{input.pageId}/comment"
            ]
        else:
            tinymce_urls = [
                f"{base_url}/rest/tinymce/1/content/{input.pageId}/comment",
                f"{base_url}/rest/tinymce/1.0/content/{input.pageId}/comment"
            ]
        
        # æ„å»ºTinyMCEè¯„è®ºæ•°æ®
        tinymce_data = {
            "body": input.comment,
            "actions": True
        }
        
        # å¦‚æœæ˜¯å›å¤è¯„è®ºï¼Œæ·»åŠ çˆ¶è¯„è®ºä¿¡æ¯
        if input.parentCommentId:
            tinymce_data["parentId"] = input.parentCommentId
        
        # å°è¯•å¤šä¸ªTinyMCE APIç‰ˆæœ¬
        tinymce_success = False
        resp = None
        for tinymce_url in tinymce_urls:
            try:
                resp = session.post(tinymce_url, json=tinymce_data, timeout=30)
                if resp.status_code < 400:
                    tinymce_success = True
                    break
            except Exception as e:
                print(f"TinyMCE API {tinymce_url} failed: {e}")
                continue
        
        if tinymce_success and resp and resp.status_code < 400:
            # TinyMCE APIæˆåŠŸ
            result = resp.json()
            comment_id = result.get("id")
            comment_url = f"{base_url}/pages/viewpage.action?pageId={input.pageId}#comment-{comment_id}" if comment_id else None
            
            return WikiAddCommentOutput(
                commentId=comment_id,
                pageId=input.pageId,
                commentUrl=comment_url,
                hint=f"Comment added successfully via TinyMCE API to page {input.pageId}"
            )
        
        # å¦‚æœTinyMCE APIå¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†REST API
        print(f"TinyMCE API failed ({resp.status_code}), falling back to standard REST API")
        
        # æ„å»ºæ ‡å‡†APIè¯„è®ºæ•°æ®
        comment_data = {
            "type": "comment",
            "container": {"id": input.pageId, "type": "page"},
            "body": {
                "storage": {
                    "value": input.comment,
                    "representation": "storage"
                }
            }
        }
        
        # å¦‚æœæ˜¯å›å¤è¯„è®ºï¼Œæ·»åŠ çˆ¶è¯„è®ºä¿¡æ¯
        if input.parentCommentId:
            comment_data["ancestors"] = [{"id": input.parentCommentId}]
        
        url = _wiki_api_url("content")
        resp = session.post(url, json=comment_data, timeout=30)
        
        if resp.status_code >= 400:
            return WikiAddCommentOutput(
                commentId=None,
                pageId=input.pageId,
                commentUrl=None,
                hint=f"Failed to add comment via both APIs. TinyMCE: {tinymce_url}, REST: {url}. Last error: {resp.status_code} {resp.text}"
            )
        
        result = resp.json()
        comment_id = result.get("id")
        
        # æ„å»ºè¯„è®ºé“¾æ¥
        comment_url = f"{base_url}/pages/viewpage.action?pageId={input.pageId}#comment-{comment_id}" if comment_id else None
        
        return WikiAddCommentOutput(
            commentId=comment_id,
            pageId=input.pageId,
            commentUrl=comment_url,
            hint=f"Comment added successfully via REST API to page {input.pageId}"
        )
        
    except Exception as e:
        return WikiAddCommentOutput(
            commentId=None,
            pageId=input.pageId,
            commentUrl=None,
            hint=f"Error adding comment: {str(e)}"
        )


@app.tool()
def wiki_get_comments(input: WikiGetCommentsInput) -> WikiGetCommentsOutput:
    """è·å– Wiki é¡µé¢çš„è¯„è®ºåˆ—è¡¨ã€‚"""
    try:
        session = _get_wiki_session()
        
        # å°è¯•å¤šç§è¯„è®ºAPIè·¯å¾„
        base_url = os.getenv("WIKI_BASE_URL", "").rstrip("/")
        context_path = os.getenv("WIKI_CONTEXT_PATH", "").strip("/")
        
        # æ„å»ºå¤šä¸ªå¯èƒ½çš„è¯„è®ºAPI URL
        comment_urls = []
        if context_path:
            comment_urls = [
                f"{base_url}/{context_path}/rest/tinymce/1/content/{input.pageId}/comment",
                f"{base_url}/{context_path}/rest/tinymce/1.0/content/{input.pageId}/comment",
                f"{base_url}/{context_path}/rest/api/content/{input.pageId}/child/comment",
                f"{base_url}/{context_path}/rest/api/1.0/content/{input.pageId}/child/comment",
            ]
        else:
            comment_urls = [
                f"{base_url}/rest/tinymce/1/content/{input.pageId}/comment",
                f"{base_url}/rest/tinymce/1.0/content/{input.pageId}/comment", 
                f"{base_url}/rest/api/content/{input.pageId}/child/comment",
                f"{base_url}/rest/api/1.0/content/{input.pageId}/child/comment",
            ]
        
        # å°è¯•æ¯ä¸ªAPIç›´åˆ°æ‰¾åˆ°å¯ç”¨çš„
        successful_response = None
        successful_url = None
        
        for comment_url in comment_urls:
            try:
                params = {"limit": input.limit}
                resp = session.get(comment_url, params=params, timeout=30)
                
                if resp.status_code == 200:
                    successful_response = resp
                    successful_url = comment_url
                    break
                elif resp.status_code == 501:
                    print(f"API not implemented: {comment_url}")
                    continue
                else:
                    print(f"API failed with {resp.status_code}: {comment_url}")
                    continue
                    
            except Exception as e:
                print(f"Exception with {comment_url}: {e}")
                continue
        
        if successful_response and successful_response.status_code == 200:
            # APIæˆåŠŸ
            try:
                data = successful_response.json()
                comments_data = data.get("results", []) if isinstance(data, dict) else data
                
                processed_comments = []
                for comment in comments_data:
                    comment_info = {
                        "id": comment.get("id"),
                        "title": comment.get("title", ""),
                        "content": comment.get("body", comment.get("content", "")),
                        "author": comment.get("author", {}).get("displayName", "Unknown") if isinstance(comment.get("author"), dict) else comment.get("author", "Unknown"),
                        "authorEmail": comment.get("author", {}).get("email", "") if isinstance(comment.get("author"), dict) else "",
                        "createdDate": comment.get("createdDate", comment.get("created", "")),
                        "version": comment.get("version", 1),
                        "isReply": bool(comment.get("parentId") or comment.get("parent"))
                    }
                    
                    # å¦‚æœæ˜¯å›å¤ï¼Œæ·»åŠ çˆ¶è¯„è®ºä¿¡æ¯
                    if comment_info["isReply"]:
                        comment_info["parentCommentId"] = comment.get("parentId", comment.get("parent", {}).get("id"))
                    
                    processed_comments.append(comment_info)
                
                # å¦‚æœä¸åŒ…å«å›å¤ï¼Œè¿‡æ»¤æ‰å›å¤è¯„è®º
                if not input.includeReplies:
                    processed_comments = [c for c in processed_comments if not c["isReply"]]
                
                return WikiGetCommentsOutput(
                    pageId=input.pageId,
                    comments=processed_comments,
                    totalComments=len(processed_comments),
                    hint=f"Retrieved {len(processed_comments)} comments via {successful_url} for page {input.pageId}"
                )
            except Exception as parse_e:
                print(f"Failed to parse response: {parse_e}")
        
        # å¦‚æœæ‰€æœ‰è¯„è®ºAPIéƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
        if not successful_response:
            return WikiGetCommentsOutput(
                pageId=input.pageId,
                comments=[],
                totalComments=0,
                hint=f"All comment APIs failed (501 Not Implemented). Tried: {', '.join(comment_urls)}"
            )
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {
            "type": "comment",
            "container": input.pageId,
            "limit": input.limit,
            "expand": "body.storage,version,ancestors"
        }
        
        url = _wiki_api_url("content")
        resp = session.get(url, params=params, timeout=30)
        
        if resp.status_code >= 400:
            return WikiGetCommentsOutput(
                pageId=input.pageId,
                comments=[],
                totalComments=0,
                hint=f"Failed to get comments via all APIs. Tried: {', '.join(comment_urls)}. No successful response."
            )
        
        data = resp.json()
        comments_data = data.get("results", [])
        
        # å¤„ç†è¯„è®ºæ•°æ®
        processed_comments = []
        for comment in comments_data:
            comment_info = {
                "id": comment.get("id"),
                "title": comment.get("title", ""),
                "content": comment.get("body", {}).get("storage", {}).get("value", ""),
                "author": comment.get("version", {}).get("by", {}).get("displayName", "Unknown"),
                "authorEmail": comment.get("version", {}).get("by", {}).get("email", ""),
                "createdDate": comment.get("version", {}).get("when", ""),
                "version": comment.get("version", {}).get("number", 1),
                "isReply": bool(comment.get("ancestors", []))
            }
            
            # å¦‚æœæ˜¯å›å¤ï¼Œæ·»åŠ çˆ¶è¯„è®ºä¿¡æ¯
            if comment_info["isReply"] and comment.get("ancestors"):
                parent = comment["ancestors"][-1]  # æœ€åä¸€ä¸ªancestoræ˜¯ç›´æ¥çˆ¶çº§
                comment_info["parentCommentId"] = parent.get("id")
            
            processed_comments.append(comment_info)
        
        # å¦‚æœä¸åŒ…å«å›å¤ï¼Œè¿‡æ»¤æ‰å›å¤è¯„è®º
        if not input.includeReplies:
            processed_comments = [c for c in processed_comments if not c["isReply"]]
        
        return WikiGetCommentsOutput(
            pageId=input.pageId,
            comments=processed_comments,
            totalComments=len(processed_comments),
            hint=f"Retrieved {len(processed_comments)} comments via REST API for page {input.pageId}"
        )
        
    except Exception as e:
        return WikiGetCommentsOutput(
            pageId=input.pageId,
            comments=[],
            totalComments=0,
            hint=f"Error getting comments: {str(e)}"
        )


@app.tool()
def wiki_update_comment(input: WikiUpdateCommentInput) -> WikiUpdateCommentOutput:
    """æ›´æ–° Wiki è¯„è®ºå†…å®¹ã€‚"""
    try:
        session = _get_wiki_session()
        
        # å…ˆè·å–å½“å‰è¯„è®ºä¿¡æ¯
        get_url = _wiki_api_url(f"content/{input.commentId}?expand=version,container")
        get_resp = session.get(get_url, timeout=30)
        
        if get_resp.status_code >= 400:
            return WikiUpdateCommentOutput(
                commentId=input.commentId,
                commentUrl=None,
                hint=f"Failed to get current comment: {get_resp.status_code}"
            )
        
        current_comment = get_resp.json()
        current_version = current_comment.get("version", {}).get("number", 1)
        container_id = current_comment.get("container", {}).get("id")
        
        # æ„å»ºæ›´æ–°æ•°æ®
        update_data = {
            "id": input.commentId,
            "type": "comment",
            "version": {
                "number": current_version + 1
            },
            "body": {
                "storage": {
                    "value": input.comment,
                    "representation": "storage"
                }
            }
        }
        
        # å‘é€æ›´æ–°è¯·æ±‚
        update_url = _wiki_api_url(f"content/{input.commentId}")
        resp = session.put(update_url, json=update_data, timeout=30)
        
        if resp.status_code >= 400:
            return WikiUpdateCommentOutput(
                commentId=input.commentId,
                commentUrl=None,
                hint=f"Failed to update comment: {resp.status_code} {resp.text}"
            )
        
        # æ„å»ºè¯„è®ºé“¾æ¥
        base_url = os.getenv("WIKI_BASE_URL", "").rstrip("/")
        comment_url = f"{base_url}/pages/viewpage.action?pageId={container_id}#comment-{input.commentId}" if container_id else None
        
        return WikiUpdateCommentOutput(
            commentId=input.commentId,
            commentUrl=comment_url,
            hint=f"Comment {input.commentId} updated successfully"
        )
        
    except Exception as e:
        return WikiUpdateCommentOutput(
            commentId=input.commentId,
            commentUrl=None,
            hint=f"Error updating comment: {str(e)}"
        )


@app.tool()
def wiki_delete_comment(input: WikiDeleteCommentInput) -> WikiDeleteCommentOutput:
    """åˆ é™¤ Wiki è¯„è®ºã€‚"""
    try:
        session = _get_wiki_session()
        
        url = _wiki_api_url(f"content/{input.commentId}")
        resp = session.delete(url, timeout=30)
        
        if resp.status_code >= 400:
            return WikiDeleteCommentOutput(
                commentId=input.commentId,
                success=False,
                hint=f"Failed to delete comment: {resp.status_code} {resp.text}"
            )
        
        return WikiDeleteCommentOutput(
            commentId=input.commentId,
            success=True,
            hint=f"Comment {input.commentId} deleted successfully"
        )
        
    except Exception as e:
        return WikiDeleteCommentOutput(
            commentId=input.commentId,
            success=False,
            hint=f"Error deleting comment: {str(e)}"
        )


@app.tool()
def wiki_publish_task(input: WikiPublishTaskInput) -> WikiPublishTaskOutput:
    """å°†DevFlowä»»åŠ¡æ–‡æ¡£å‘å¸ƒåˆ°Wikiï¼Œåˆ›å»ºç»“æ„åŒ–çš„æ–‡æ¡£é¡µé¢ã€‚"""
    try:
        project_root = _resolve_project_root(input.projectRoot)
        published_pages = []
        
        # 1. è·å–ä»»åŠ¡ä¿¡æ¯
        task_metadata = _get_task_metadata(project_root, input.taskKey)
        task_title = task_metadata.get("title", input.taskKey)
        
        # 2. åˆ›å»ºä¸»é¡µé¢
        main_page_title = f"{input.taskKey} - {task_title}"
        main_page_content = _generate_wiki_task_overview(
            project_root, input.taskKey, task_metadata, input.templateStyle
        )
        
        # æŸ¥æ‰¾çˆ¶é¡µé¢IDï¼ˆå¦‚æœæŒ‡å®šï¼‰
        parent_page_id = None
        if input.parentPageTitle:
            search_result = wiki_search_pages(WikiSearchInput(
                query=input.parentPageTitle,
                spaceKey=input.spaceKey,
                searchType="title",
                limit=1
            ))
            if search_result.results:
                parent_page_id = search_result.results[0]["id"]
        
        # åˆ›å»ºä¸»é¡µé¢
        main_page_result = wiki_create_page(WikiCreatePageInput(
            spaceKey=input.spaceKey,
            title=main_page_title,
            content=main_page_content,
            parentPageId=parent_page_id,
            labels=[input.taskKey, "DevFlow", "Task"],
            contentFormat="storage"
        ))
        
        if not main_page_result.pageId:
            return WikiPublishTaskOutput(
                taskKey=input.taskKey,
                mainPageId="",
                mainPageUrl="",
                publishedPages=[],
                spaceKey=input.spaceKey,
                hint=f"Failed to create main page: {main_page_result.hint}"
            )
        
        published_pages.append({
            "title": main_page_title,
            "pageId": main_page_result.pageId,
            "url": main_page_result.url or "",
            "type": "overview"
        })
        
        # 3. å‘å¸ƒè¿‡ç¨‹æ–‡æ¡£ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if input.includeProcessDocs:
            process_dir = project_root / "Docs" / "ProcessDocuments" / f"task-{input.taskKey}"
            if process_dir.exists():
                doc_configs = [
                    ("01-Context.md", "é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡"),
                    ("02-Design.md", "è®¾è®¡æ–¹æ¡ˆ"),
                    ("03-CodePlan.md", "ä»£ç å®ç°è®¡åˆ’"),
                    ("04-TestCurls.md", "æµ‹è¯•ç”¨ä¾‹"),
                    ("05-MySQLVerificationPlan.md", "æ•°æ®åº“éªŒè¯è®¡åˆ’"),
                    ("06-Integration.md", "é›†æˆæ–‡æ¡£"),
                    ("07-JiraPublishPlan.md", "å‘å¸ƒè®¡åˆ’")
                ]
                
                for doc_file, doc_title in doc_configs:
                    doc_path = process_dir / f"{input.taskKey}_{doc_file}"
                    if doc_path.exists():
                        try:
                            # è¯»å–æ–‡æ¡£å†…å®¹
                            post = frontmatter.load(doc_path)
                            doc_content = post.content
                            
                            # è½¬æ¢ä¸ºWikiæ ¼å¼
                            wiki_content = _convert_markdown_to_confluence(doc_content)
                            
                            # åˆ›å»ºå­é¡µé¢
                            sub_page_title = f"{input.taskKey} - {doc_title}"
                            sub_page_result = wiki_create_page(WikiCreatePageInput(
                                spaceKey=input.spaceKey,
                                title=sub_page_title,
                                content=wiki_content,
                                parentPageId=main_page_result.pageId,
                                labels=[input.taskKey, "DevFlow", "ProcessDoc", doc_file.split('-')[0]],
                                contentFormat="storage"
                            ))
                            
                            if sub_page_result.pageId:
                                published_pages.append({
                                    "title": sub_page_title,
                                    "pageId": sub_page_result.pageId,
                                    "url": sub_page_result.url or "",
                                    "type": "process_doc",
                                    "docFile": doc_file
                                })
                        except Exception as e:
                            print(f"Failed to publish {doc_file}: {str(e)}")
        
        # 4. å‘å¸ƒé›†æˆæ–‡æ¡£ï¼ˆå¦‚æœå¯ç”¨ä¸”å­˜åœ¨ï¼‰
        if input.includeIntegrationDoc:
            integration_doc_path = project_root / "Docs" / "ProcessDocuments" / f"task-{input.taskKey}" / f"{input.taskKey}_06-Integration.md"
            if integration_doc_path.exists():
                try:
                    post = frontmatter.load(integration_doc_path)
                    integration_content = _convert_markdown_to_confluence(post.content)
                    
                    integration_page_result = wiki_create_page(WikiCreatePageInput(
                        spaceKey=input.spaceKey,
                        title=f"{input.taskKey} - APIé›†æˆæ–‡æ¡£",
                        content=integration_content,
                        parentPageId=main_page_result.pageId,
                        labels=[input.taskKey, "DevFlow", "Integration", "API"],
                        contentFormat="storage"
                    ))
                    
                    if integration_page_result.pageId:
                        published_pages.append({
                            "title": f"{input.taskKey} - APIé›†æˆæ–‡æ¡£",
                            "pageId": integration_page_result.pageId,
                            "url": integration_page_result.url or "",
                            "type": "integration_doc"
                        })
                except Exception as e:
                    print(f"Failed to publish integration doc: {str(e)}")
        
        # 5. æ›´æ–°ä¸»é¡µé¢ï¼Œæ·»åŠ å­é¡µé¢é“¾æ¥ï¼ˆå¦‚æœå¯ç”¨è‡ªåŠ¨é“¾æ¥ï¼‰
        if input.autoLink and len(published_pages) > 1:
            try:
                updated_main_content = _add_child_page_links(
                    main_page_content, published_pages[1:], input.spaceKey
                )
                
                wiki_update_page(WikiUpdatePageInput(
                    pageId=main_page_result.pageId,
                    content=updated_main_content,
                    versionComment="Added child page links"
                ))
            except Exception as e:
                print(f"Failed to update main page with links: {str(e)}")
        
        return WikiPublishTaskOutput(
            taskKey=input.taskKey,
            mainPageId=main_page_result.pageId,
            mainPageUrl=main_page_result.url or "",
            publishedPages=published_pages,
            spaceKey=input.spaceKey,
            hint=f"Successfully published {len(published_pages)} pages for task {input.taskKey}"
        )
        
    except Exception as e:
        return WikiPublishTaskOutput(
            taskKey=input.taskKey,
            mainPageId="",
            mainPageUrl="",
            publishedPages=[],
            spaceKey=input.spaceKey,
            hint=f"Error publishing task: {str(e)}"
        )


def _generate_wiki_task_overview(project_root: Path, task_key: str, metadata: Dict[str, Any], style: str) -> str:
    """ç”ŸæˆWikiä»»åŠ¡æ¦‚è§ˆé¡µé¢å†…å®¹"""
    title = metadata.get("title", task_key)
    owner = metadata.get("owner", "æœªæŒ‡å®š")
    reviewers = ", ".join(metadata.get("reviewers", []))
    status = _read_task_status(project_root, task_key)
    created_at = metadata.get("createdAt", "")
    updated_at = metadata.get("updatedAt", "")
    
    if style == "compact":
        content = f"""<h1>{task_key} - {title}</h1>

<table>
<tr><td><strong>ä»»åŠ¡çŠ¶æ€</strong></td><td><ac:structured-macro ac:name="status" ac:schema-version="1"><ac:parameter ac:name="colour">Blue</ac:parameter><ac:parameter ac:name="title">{status}</ac:parameter></ac:structured-macro></td></tr>
<tr><td><strong>è´Ÿè´£äºº</strong></td><td>{owner}</td></tr>
<tr><td><strong>å®¡æ ¸äºº</strong></td><td>{reviewers}</td></tr>
<tr><td><strong>åˆ›å»ºæ—¶é—´</strong></td><td>{created_at}</td></tr>
<tr><td><strong>æ›´æ–°æ—¶é—´</strong></td><td>{updated_at}</td></tr>
</table>

<h2>å­é¡µé¢</h2>
<p><em>ç›¸å…³æ–‡æ¡£é¡µé¢å°†åœ¨ä¸‹æ–¹åˆ—å‡º</em></p>
"""
    elif style == "detailed":
        # è·å–ä»»åŠ¡è¿›å±•æŠ¥å‘Š
        progress_report = _generate_task_progress_report(project_root, task_key)
        
        content = f"""<h1>{task_key} - {title}</h1>

<ac:structured-macro ac:name="info" ac:schema-version="1">
<ac:parameter ac:name="title">ä»»åŠ¡æ¦‚è§ˆ</ac:parameter>
<ac:rich-text-body>
<p>æœ¬é¡µé¢åŒ…å«ä»»åŠ¡ <strong>{task_key}</strong> çš„å®Œæ•´æ–‡æ¡£å’Œè¿›å±•ä¿¡æ¯ã€‚</p>
</ac:rich-text-body>
</ac:structured-macro>

<h2>åŸºæœ¬ä¿¡æ¯</h2>
<table>
<tr><td><strong>ä»»åŠ¡ç¼–å·</strong></td><td>{task_key}</td></tr>
<tr><td><strong>ä»»åŠ¡æ ‡é¢˜</strong></td><td>{title}</td></tr>
<tr><td><strong>å½“å‰çŠ¶æ€</strong></td><td><ac:structured-macro ac:name="status" ac:schema-version="1"><ac:parameter ac:name="colour">Blue</ac:parameter><ac:parameter ac:name="title">{status}</ac:parameter></ac:structured-macro></td></tr>
<tr><td><strong>è´Ÿè´£äºº</strong></td><td>{owner}</td></tr>
<tr><td><strong>å®¡æ ¸äºº</strong></td><td>{reviewers}</td></tr>
<tr><td><strong>åˆ›å»ºæ—¶é—´</strong></td><td>{created_at}</td></tr>
<tr><td><strong>æœ€åæ›´æ–°</strong></td><td>{updated_at}</td></tr>
</table>

<h2>æ–‡æ¡£çŠ¶æ€</h2>
<table>
<tr><th>æ–‡æ¡£ç±»å‹</th><th>çŠ¶æ€</th><th>æ›´æ–°æ—¶é—´</th></tr>
"""
        # æ·»åŠ æ–‡æ¡£çŠ¶æ€ä¿¡æ¯
        for doc in progress_report.get("processDocuments", []):
            status_macro = f'<ac:structured-macro ac:name="status" ac:schema-version="1"><ac:parameter ac:name="colour">Green</ac:parameter><ac:parameter ac:name="title">{doc["status"]}</ac:parameter></ac:structured-macro>'
            content += f'<tr><td>{doc["name"]}</td><td>{status_macro}</td><td>{doc.get("updatedAt", "N/A")}</td></tr>\n'
        
        content += """</table>

<h2>ç›¸å…³é¡µé¢</h2>
<p><em>ç›¸å…³æ–‡æ¡£é¡µé¢å°†åœ¨ä¸‹æ–¹åˆ—å‡º</em></p>

<h2>æœ€æ–°è¿›å±•</h2>
<ac:structured-macro ac:name="expand" ac:schema-version="1">
<ac:parameter ac:name="title">æŸ¥çœ‹è¯¦ç»†è¿›å±•</ac:parameter>
<ac:rich-text-body>
<p><em>æœ€æ–°çš„ä»»åŠ¡è¿›å±•ä¿¡æ¯å°†é€šè¿‡DevFlowè‡ªåŠ¨æ›´æ–°</em></p>
</ac:rich-text-body>
</ac:structured-macro>
"""
    else:  # standard
        content = f"""<h1>{task_key} - {title}</h1>

<ac:structured-macro ac:name="panel" ac:schema-version="1">
<ac:parameter ac:name="bgColor">#eae6ff</ac:parameter>
<ac:parameter ac:name="title">ä»»åŠ¡ä¿¡æ¯</ac:parameter>
<ac:rich-text-body>
<table>
<tr><td><strong>çŠ¶æ€</strong></td><td><ac:structured-macro ac:name="status" ac:schema-version="1"><ac:parameter ac:name="colour">Blue</ac:parameter><ac:parameter ac:name="title">{status}</ac:parameter></ac:structured-macro></td></tr>
<tr><td><strong>è´Ÿè´£äºº</strong></td><td>{owner}</td></tr>
<tr><td><strong>å®¡æ ¸äºº</strong></td><td>{reviewers}</td></tr>
<tr><td><strong>åˆ›å»ºæ—¶é—´</strong></td><td>{created_at}</td></tr>
<tr><td><strong>æ›´æ–°æ—¶é—´</strong></td><td>{updated_at}</td></tr>
</table>
</ac:rich-text-body>
</ac:structured-macro>

<h2>æ–‡æ¡£å¯¼èˆª</h2>
<p>æœ¬ä»»åŠ¡çš„ç›¸å…³æ–‡æ¡£é¡µé¢ï¼š</p>
<p><em>å­é¡µé¢é“¾æ¥å°†è‡ªåŠ¨ç”Ÿæˆåœ¨æ­¤å¤„</em></p>

<h2>å¿«é€Ÿé“¾æ¥</h2>
<ul>
<li><a href="/display/{metadata.get('spaceKey', 'DEV')}/DevFlow+Tasks">è¿”å›ä»»åŠ¡åˆ—è¡¨</a></li>
</ul>
"""
    
    return content


def _convert_markdown_to_confluence(markdown_content: str) -> str:
    """å°†Markdownå†…å®¹è½¬æ¢ä¸ºConfluenceå­˜å‚¨æ ¼å¼"""
    # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„è½¬æ¢å™¨ï¼Œå¤„ç†å¸¸è§çš„Markdownå…ƒç´ 
    content = markdown_content
    
    # æ ‡é¢˜è½¬æ¢
    content = re.sub(r'^# (.*?)$', r'<h1>\1</h1>', content, flags=re.MULTILINE)
    content = re.sub(r'^## (.*?)$', r'<h2>\1</h2>', content, flags=re.MULTILINE)
    content = re.sub(r'^### (.*?)$', r'<h3>\1</h3>', content, flags=re.MULTILINE)
    content = re.sub(r'^#### (.*?)$', r'<h4>\1</h4>', content, flags=re.MULTILINE)
    
    # ç²—ä½“å’Œæ–œä½“
    content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', content)
    content = re.sub(r'\*(.*?)\*', r'<em>\1</em>', content)
    
    # ä»£ç å—
    content = re.sub(r'```(\w+)?\n(.*?)\n```', 
                    r'<ac:structured-macro ac:name="code" ac:schema-version="1"><ac:parameter ac:name="language">\1</ac:parameter><ac:plain-text-body><![CDATA[\2]]></ac:plain-text-body></ac:structured-macro>', 
                    content, flags=re.DOTALL)
    
    # è¡Œå†…ä»£ç 
    content = re.sub(r'`(.*?)`', r'<code>\1</code>', content)
    
    # åˆ—è¡¨è½¬æ¢
    content = re.sub(r'^- (.*?)$', r'<li>\1</li>', content, flags=re.MULTILINE)
    content = re.sub(r'^(\d+)\. (.*?)$', r'<li>\2</li>', content, flags=re.MULTILINE)
    
    # åŒ…è£…åˆ—è¡¨é¡¹
    content = re.sub(r'(<li>.*?</li>\n?)+', r'<ul>\g<0></ul>', content, flags=re.DOTALL)
    
    # é“¾æ¥è½¬æ¢
    content = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'<a href="\2">\1</a>', content)
    
    # æ®µè½å¤„ç†
    paragraphs = content.split('\n\n')
    processed_paragraphs = []
    for para in paragraphs:
        para = para.strip()
        if para and not para.startswith('<'):
            para = f'<p>{para}</p>'
        processed_paragraphs.append(para)
    
    return '\n\n'.join(processed_paragraphs)


def _add_child_page_links(main_content: str, child_pages: List[Dict[str, str]], space_key: str) -> str:
    """åœ¨ä¸»é¡µé¢ä¸­æ·»åŠ å­é¡µé¢é“¾æ¥"""
    links_html = "<h3>ç›¸å…³æ–‡æ¡£</h3>\n<ul>\n"
    
    for page in child_pages:
        page_title = page["title"]
        page_type = page.get("type", "document")
        
        # æ ¹æ®ç±»å‹æ·»åŠ å›¾æ ‡
        icon = {
            "process_doc": "ğŸ“‹",
            "integration_doc": "ğŸ”—",
            "test_doc": "ğŸ§ª"
        }.get(page_type, "ğŸ“„")
        
        links_html += f'<li>{icon} <ac:link><ri:page ri:content-title="{page_title}" ri:space-key="{space_key}"/><ac:plain-text-link-body><![CDATA[{page_title}]]></ac:plain-text-link-body></ac:link></li>\n'
    
    links_html += "</ul>\n"
    
    # æ›¿æ¢å ä½ç¬¦æ–‡æœ¬
    if "å­é¡µé¢é“¾æ¥å°†è‡ªåŠ¨ç”Ÿæˆåœ¨æ­¤å¤„" in main_content:
        return main_content.replace("å­é¡µé¢é“¾æ¥å°†è‡ªåŠ¨ç”Ÿæˆåœ¨æ­¤å¤„", links_html)
    elif "ç›¸å…³æ–‡æ¡£é¡µé¢å°†åœ¨ä¸‹æ–¹åˆ—å‡º" in main_content:
        return main_content.replace("ç›¸å…³æ–‡æ¡£é¡µé¢å°†åœ¨ä¸‹æ–¹åˆ—å‡º", links_html)
    else:
        # åœ¨æ–‡æ¡£å¯¼èˆªéƒ¨åˆ†åæ·»åŠ 
        return main_content + "\n\n" + links_html


# ---------- Jiraåˆ†æä¸æµ‹è¯•å¯¹æ¯”å·¥å…·å‡½æ•° ----------

@app.tool()
def jira_fetch_issue_with_analysis(input: JiraFetchInput) -> JiraFetchOutput:
    """æ‹‰å–Jiraå·¥å•åŠå­ä»»åŠ¡ä¿¡æ¯ï¼Œä¸‹è½½é™„ä»¶ï¼Œä¸ºåç»­åˆ†æå‡†å¤‡æ•°æ®ã€‚
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - å®Œæ•´çš„å·¥å•ä¿¡æ¯è·å–ï¼ˆä¸»è¦å­—æ®µå’Œè‡ªå®šä¹‰å­—æ®µï¼‰
    - å­ä»»åŠ¡é€’å½’è·å–
    - é™„ä»¶æ‰¹é‡ä¸‹è½½
    - å˜æ›´å†å²è¿½è¸ªï¼ˆå¯é€‰ï¼‰
    """
    try:
        session = _get_jira_session()
        
        # 1. è·å–ä¸»å·¥å•ä¿¡æ¯
        issue_url = _jira_api_url(f"issue/{input.issueKey}")
        issue_resp = session.get(issue_url, params={"expand": "changelog"} if input.includeHistory else {})
        
        if issue_resp.status_code >= 400:
            raise Exception(f"Failed to fetch issue {input.issueKey}: {issue_resp.status_code}")
            
        issue_data = issue_resp.json()
        fields = issue_data.get("fields", {})
        
        # æ„å»ºå·¥å•ä¿¡æ¯
        issue_info = JiraIssueInfo(
            key=issue_data.get("key", input.issueKey),
            summary=fields.get("summary", ""),
            description=fields.get("description", ""),
            status=fields.get("status", {}).get("name", "Unknown"),
            issueType=fields.get("issuetype", {}).get("name", "Unknown"),
            priority=fields.get("priority", {}).get("name", "Medium"),
            assignee=fields.get("assignee", {}).get("displayName") if fields.get("assignee") else None,
            reporter=fields.get("reporter", {}).get("displayName") if fields.get("reporter") else None,
            created=fields.get("created", ""),
            updated=fields.get("updated", ""),
            customFields={k: v for k, v in fields.items() if k.startswith("customfield_")}
        )
        
        subtasks = []
        attachments = []
        downloaded_files = []
        
        # 2. è·å–å­ä»»åŠ¡
        if input.includeSubtasks:
            subtask_links = fields.get("subtasks", [])
            for subtask_link in subtask_links:
                try:
                    subtask_key = subtask_link.get("key")
                    if subtask_key:
                        subtask_resp = session.get(_jira_api_url(f"issue/{subtask_key}"))
                        if subtask_resp.status_code < 400:
                            subtask_data = subtask_resp.json()
                            subtask_fields = subtask_data.get("fields", {})
                            
                            subtasks.append(JiraSubtask(
                                key=subtask_data.get("key", subtask_key),
                                summary=subtask_fields.get("summary", ""),
                                description=subtask_fields.get("description", ""),
                                status=subtask_fields.get("status", {}).get("name", "Unknown"),
                                assignee=subtask_fields.get("assignee", {}).get("displayName") if subtask_fields.get("assignee") else None
                            ))
                except Exception:
                    continue  # è·³è¿‡è·å–å¤±è´¥çš„å­ä»»åŠ¡
        
        # 3. å¤„ç†é™„ä»¶
        if input.includeAttachments:
            attachment_list = fields.get("attachment", [])
            
            # å‡†å¤‡ä¸‹è½½ç›®å½•
            project_root = Path(os.getcwd())  # é»˜è®¤é¡¹ç›®æ ¹ç›®å½•
            if input.attachmentPath:
                download_dir = project_root / input.attachmentPath / input.issueKey
            else:
                download_dir = project_root / "downloads" / "jira_attachments" / input.issueKey
            
            for attachment_info in attachment_list:
                try:
                    attachment = JiraAttachment(
                        id=str(attachment_info.get("id", "")),
                        filename=attachment_info.get("filename", ""),
                        size=attachment_info.get("size", 0),
                        mimeType=attachment_info.get("mimeType", ""),
                        author=attachment_info.get("author", {}).get("displayName", "Unknown"),
                        created=attachment_info.get("created", ""),
                        downloadUrl=attachment_info.get("content", "")
                    )
                    
                    # ä¸‹è½½é™„ä»¶
                    local_path = _download_jira_attachment(session, attachment_info, download_dir)
                    if local_path:
                        attachment.localPath = local_path
                        downloaded_files.append(local_path)
                    
                    attachments.append(attachment)
                    
                except Exception:
                    continue  # è·³è¿‡ä¸‹è½½å¤±è´¥çš„é™„ä»¶
        
        return JiraFetchOutput(
            issueInfo=issue_info,
            subtasks=subtasks,
            attachments=attachments,
            downloadedFiles=downloaded_files
        )
        
    except Exception as e:
        # è¿”å›åŸºæœ¬ä¿¡æ¯ï¼Œå³ä½¿éƒ¨åˆ†è·å–å¤±è´¥
        return JiraFetchOutput(
            issueInfo=JiraIssueInfo(
                key=input.issueKey,
                summary="Failed to fetch",
                description=f"Error: {str(e)}",
                status="Unknown",
                issueType="Unknown",
                priority="Medium",
                created="",
                updated=""
            ),
            subtasks=[],
            attachments=[],
            downloadedFiles=[]
        )

@app.tool()  
def analyze_requirements_vs_tests(input: TestAnalysisInput) -> TestAnalysisOutput:
    """åˆ†æJiraéœ€æ±‚ä¸ç°æœ‰æµ‹è¯•ç”¨ä¾‹çš„è¦†ç›–åº¦ï¼Œç”Ÿæˆæµ‹è¯•gapå’Œæ¨èã€‚
    
    åˆ†æç»´åº¦ï¼š
    - éœ€æ±‚è§£æï¼šä»Jiraæè¿°å’Œå­ä»»åŠ¡ä¸­æå–ç»“æ„åŒ–éœ€æ±‚
    - æµ‹è¯•åŒ¹é…ï¼šå°†éœ€æ±‚ä¸ç°æœ‰æµ‹è¯•ç”¨ä¾‹è¿›è¡ŒåŒ¹é…
    - è¦†ç›–åº¦è®¡ç®—ï¼šè®¡ç®—æ¯ä¸ªéœ€æ±‚çš„æµ‹è¯•è¦†ç›–ç¨‹åº¦
    - ç¼ºå¤±è¯†åˆ«ï¼šè¯†åˆ«æµ‹è¯•è¦†ç›–ä¸è¶³çš„éœ€æ±‚ç‚¹
    - æ™ºèƒ½æ¨èï¼šåŸºäºéœ€æ±‚ç±»å‹æ¨èåˆé€‚çš„æµ‹è¯•ç”¨ä¾‹
    """
    project_root = _resolve_project_root(input.projectRoot)
    
    # 1. é¦–å…ˆè·å–Jiraä¿¡æ¯
    jira_fetch_input = JiraFetchInput(
        issueKey=input.jiraIssueKey,
        includeSubtasks=True,
        includeAttachments=input.includeAttachments,
        attachmentPath="analysis_temp"
    )
    
    jira_data = jira_fetch_issue_with_analysis(jira_fetch_input)
    
    # 2. è§£æéœ€æ±‚
    requirements = []
    
    # ä»ä¸»å·¥å•æè¿°è§£æéœ€æ±‚
    main_requirements = _parse_requirements_from_text(jira_data.issueInfo.description, "main_issue")
    requirements.extend(main_requirements)
    
    # ä»å­ä»»åŠ¡è§£æéœ€æ±‚
    for i, subtask in enumerate(jira_data.subtasks):
        subtask_requirements = _parse_requirements_from_text(
            f"{subtask.summary}\n{subtask.description}", 
            f"subtask_{i+1}"
        )
        requirements.extend(subtask_requirements)
    
    # ä»é™„ä»¶è§£æéœ€æ±‚ï¼ˆå¦‚æœæ˜¯æ–‡æœ¬æ–‡ä»¶ï¼‰
    if input.includeAttachments:
        for attachment in jira_data.attachments:
            if attachment.localPath and attachment.mimeType.startswith("text/"):
                try:
                    attachment_path = Path(attachment.localPath)
                    if attachment_path.exists():
                        attachment_content = attachment_path.read_text(encoding="utf-8")
                        attachment_requirements = _parse_requirements_from_text(
                            attachment_content, 
                            f"attachment_{attachment.filename}"
                        )
                        requirements.extend(attachment_requirements)
                except Exception:
                    continue
    
    # 3. è·å–ç°æœ‰æµ‹è¯•ç”¨ä¾‹
    test_cases = []
    
    # ä»DevFlowä»»åŠ¡æ–‡æ¡£ä¸­è·å–æµ‹è¯•ç”¨ä¾‹
    process_dir = project_root / "Docs" / "ProcessDocuments" / f"task-{input.taskKey}"
    if process_dir.exists():
        # æŸ¥æ‰¾æµ‹è¯•ç›¸å…³æ–‡æ¡£
        test_files = [
            process_dir / f"{input.taskKey}_04-TestCurls.md",
            process_dir / f"{input.taskKey}_05-MySQLVerificationPlan.md",
            process_dir / f"{input.taskKey}_06-Integration.md",
        ]
        
        for test_file in test_files:
            if test_file.exists():
                file_test_cases = _extract_test_cases_from_file(test_file)
                test_cases.extend(file_test_cases)
    
    # 4. è®¡ç®—è¦†ç›–åº¦
    test_matches = _calculate_coverage(requirements, test_cases)
    
    # 5. ç”Ÿæˆæ¨è
    recommended_tests = _generate_test_recommendations(requirements, test_matches)
    
    # 6. è®¡ç®—æ•´ä½“è¦†ç›–åº¦
    if test_matches:
        overall_coverage = sum(match.coverage for match in test_matches) / len(test_matches)
    else:
        overall_coverage = 0.0
    
    # 7. è¯†åˆ«ç¼ºå¤±æµ‹è¯•
    missing_tests = []
    for match in test_matches:
        if match.coverage < 0.3:  # è¦†ç›–åº¦ä½äº30%çš„éœ€æ±‚
            req = next((r for r in requirements if r.id == match.requirementId), None)
            if req:
                missing_tests.append(f"{req.id}: {req.title}")
    
    # 8. ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report_dir = project_root / "Docs" / "ProcessDocuments" / f"task-{input.taskKey}"
    report_dir.mkdir(parents=True, exist_ok=True)
    report_path = report_dir / f"{input.taskKey}_TestAnalysisReport.md"
    
    report_content = f"""---
status: DRAFT
generatedAt: {_timestamp()}
jiraIssue: {input.jiraIssueKey}
analysisType: {input.analysisType}
---

# æµ‹è¯•è¦†ç›–åº¦åˆ†ææŠ¥å‘Š - {input.taskKey}

## å·¥å•ä¿¡æ¯
- **Jiraå·¥å•**: {input.jiraIssueKey}
- **æ ‡é¢˜**: {jira_data.issueInfo.summary}
- **çŠ¶æ€**: {jira_data.issueInfo.status}
- **ç±»å‹**: {jira_data.issueInfo.issueType}

## éœ€æ±‚åˆ†æ
**æ€»éœ€æ±‚æ•°**: {len(requirements)}

{chr(10).join(f"- **{req.id}** ({req.category}): {req.title}" for req in requirements)}

## æµ‹è¯•è¦†ç›–åº¦
**æ•´ä½“è¦†ç›–åº¦**: {overall_coverage:.1%}

### è¯¦ç»†è¦†ç›–æƒ…å†µ
{chr(10).join(f"- **{match.requirementId}**: {match.coverage:.1%} è¦†ç›– ({len(match.testCases)} ä¸ªç›¸å…³æµ‹è¯•)" for match in test_matches)}

## ç¼ºå¤±åˆ†æ
**ç¼ºå¤±æµ‹è¯•æ•°**: {len(missing_tests)}

{chr(10).join(f"- {missing}" for missing in missing_tests)}

## æ¨èæµ‹è¯•ç”¨ä¾‹
{chr(10).join(f"- {rec}" for rec in recommended_tests)}

## é™„ä»¶ä¿¡æ¯
{chr(10).join(f"- **{att.filename}** ({att.mimeType}) - {att.size} bytes" for att in jira_data.attachments)}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {_timestamp()}*
"""
    
    report_path.write_text(report_content, encoding="utf-8")
    
    return TestAnalysisOutput(
        taskKey=input.taskKey,
        jiraIssueKey=input.jiraIssueKey,
        requirements=requirements,
        testMatches=test_matches,
        overallCoverage=overall_coverage,
        missingTests=missing_tests,
        recommendedTests=recommended_tests,
        analysisReport=str(report_path)
    )

@app.tool()
def sync_jira_requirements(input: RequirementSyncInput) -> RequirementSyncOutput:
    """å°†Jiraéœ€æ±‚åŒæ­¥åˆ°DevFlowä»»åŠ¡ï¼Œå¯é€‰æ‹©è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚
    
    åŒæ­¥åŠŸèƒ½ï¼š
    - åˆ›å»ºæˆ–æ›´æ–°DevFlowä»»åŠ¡æ–‡æ¡£
    - åŒæ­¥éœ€æ±‚æè¿°å’ŒéªŒæ”¶æ ‡å‡†
    - æ›´æ–°å­ä»»åŠ¡çŠ¶æ€æ˜ å°„
    - å¯é€‰çš„è‡ªåŠ¨æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
    - å»ºç«‹éœ€æ±‚è¿½æº¯é“¾æ¥
    """
    project_root = _resolve_project_root(input.projectRoot)
    
    # 1. è·å–Jiraæ•°æ®
    jira_fetch_input = JiraFetchInput(
        issueKey=input.jiraIssueKey,
        includeSubtasks=True,
        includeAttachments=True
    )
    
    jira_data = jira_fetch_issue_with_analysis(jira_fetch_input)
    
    # 2. ç¡®å®šç›®æ ‡ä»»åŠ¡Key
    task_key = input.targetTaskKey
    if not task_key:
        # è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡Key
        task_key = f"JIRA-{input.jiraIssueKey.replace('-', '')}"
    
    created_files = []
    updated_files = []
    generated_tests = []
    
    # 3. åˆ›å»ºæˆ–æ›´æ–°ä¸»ä»»åŠ¡æ–‡æ¡£
    if input.syncMode in ["create", "update", "merge"]:
        task_input = PrepareDocsInput(
            taskKey=task_key,
            title=f"JiraåŒæ­¥: {jira_data.issueInfo.summary}",
            owner="system",
            reviewers=["qa", "dev"],
            force=(input.syncMode == "create")
        )
        
        task_result = task_prepare_docs(task_input)
        if task_result:
            created_files.append(task_result.mainDocPath)
    
    # 4. æ›´æ–°ä»»åŠ¡å†…å®¹
    main_doc_path = project_root / "Docs" / ".tasks" / f"{task_key}.md"
    if main_doc_path.exists():
        try:
            post = frontmatter.load(main_doc_path)
            metadata = dict(post.metadata or {})
            
            # æ·»åŠ Jiraå…³è”ä¿¡æ¯
            metadata["jiraIssue"] = input.jiraIssueKey
            metadata["jiraStatus"] = jira_data.issueInfo.status
            metadata["syncedAt"] = _timestamp()
            
            # æ›´æ–°å†…å®¹
            content_lines = [
                f"# {jira_data.issueInfo.summary}",
                "",
                "## éœ€æ±‚æ¥æº",
                f"- **Jiraå·¥å•**: {input.jiraIssueKey}",
                f"- **çŠ¶æ€**: {jira_data.issueInfo.status}",
                f"- **ç±»å‹**: {jira_data.issueInfo.issueType}",
                f"- **ä¼˜å…ˆçº§**: {jira_data.issueInfo.priority}",
                "",
                "## éœ€æ±‚æè¿°",
                jira_data.issueInfo.description or "æ— è¯¦ç»†æè¿°",
                "",
                "## å­ä»»åŠ¡",
            ]
            
            for subtask in jira_data.subtasks:
                content_lines.append(f"- **{subtask.key}**: {subtask.summary} ({subtask.status})")
            
            if jira_data.attachments:
                content_lines.extend([
                    "",
                    "## é™„ä»¶",
                ])
                for att in jira_data.attachments:
                    content_lines.append(f"- **{att.filename}** ({att.mimeType})")
            
            post.content = "\n".join(content_lines)
            post.metadata = metadata
            
            content_str = frontmatter.dumps(post)
            main_doc_path.write_text(content_str, encoding="utf-8")
            updated_files.append(str(main_doc_path))
            
        except Exception:
            pass
    
    # 5. è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if input.autoGenerateTests:
        analysis_input = TestAnalysisInput(
            taskKey=task_key,
            jiraIssueKey=input.jiraIssueKey,
            analysisType="recommendation",
            includeAttachments=True,
            projectRoot=input.projectRoot
        )
        
        analysis_result = analyze_requirements_vs_tests(analysis_input)
        
        # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ–‡æ¡£
        if analysis_result.recommendedTests:
            test_doc_path = project_root / "Docs" / "ProcessDocuments" / f"task-{task_key}" / f"{task_key}_RecommendedTests.md"
            test_doc_path.parent.mkdir(parents=True, exist_ok=True)
            
            test_content = f"""---
status: DRAFT
generatedAt: {_timestamp()}
source: jira_sync
---

# æ¨èæµ‹è¯•ç”¨ä¾‹ - {task_key}

## åŸºäºéœ€æ±‚åˆ†æçš„æµ‹è¯•ç”¨ä¾‹æ¨è

{chr(10).join(f"### æµ‹è¯•ç”¨ä¾‹ {i+1}: {test}" for i, test in enumerate(analysis_result.recommendedTests))}

## éœ€æ±‚è¦†ç›–åº¦åˆ†æ
- **æ•´ä½“è¦†ç›–åº¦**: {analysis_result.overallCoverage:.1%}
- **éœ€æ±‚æ€»æ•°**: {len(analysis_result.requirements)}
- **ç¼ºå¤±æµ‹è¯•**: {len(analysis_result.missingTests)}

è¯¦ç»†åˆ†ææŠ¥å‘Š: [æŸ¥çœ‹æŠ¥å‘Š]({analysis_result.analysisReport})
"""
            
            test_doc_path.write_text(test_content, encoding="utf-8")
            generated_tests.append(str(test_doc_path))
    
    # 6. ç”ŸæˆåŒæ­¥æŠ¥å‘Š
    sync_report_path = project_root / "Docs" / "ProcessDocuments" / f"task-{task_key}" / f"{task_key}_SyncReport.md"
    sync_report_path.parent.mkdir(parents=True, exist_ok=True)
    
    sync_report_content = f"""---
status: COMPLETED
syncedAt: {_timestamp()}
---

# JiraåŒæ­¥æŠ¥å‘Š - {task_key}

## åŒæ­¥ä¿¡æ¯
- **æºJiraå·¥å•**: {input.jiraIssueKey}
- **ç›®æ ‡ä»»åŠ¡**: {task_key}  
- **åŒæ­¥æ¨¡å¼**: {input.syncMode}
- **è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•**: {'æ˜¯' if input.autoGenerateTests else 'å¦'}

## åŒæ­¥ç»“æœ
- **åˆ›å»ºæ–‡ä»¶**: {len(created_files)} ä¸ª
- **æ›´æ–°æ–‡ä»¶**: {len(updated_files)} ä¸ª
- **ç”Ÿæˆæµ‹è¯•**: {len(generated_tests)} ä¸ª

### è¯¦ç»†æ–‡ä»¶æ¸…å•
**åˆ›å»ºçš„æ–‡ä»¶**:
{chr(10).join(f"- {f}" for f in created_files)}

**æ›´æ–°çš„æ–‡ä»¶**:
{chr(10).join(f"- {f}" for f in updated_files)}

**ç”Ÿæˆçš„æµ‹è¯•**:
{chr(10).join(f"- {f}" for f in generated_tests)}

## Jiraå·¥å•å¿«ç…§
- **æ ‡é¢˜**: {jira_data.issueInfo.summary}
- **çŠ¶æ€**: {jira_data.issueInfo.status}
- **å­ä»»åŠ¡æ•°**: {len(jira_data.subtasks)}
- **é™„ä»¶æ•°**: {len(jira_data.attachments)}

---
*åŒæ­¥å®Œæˆæ—¶é—´: {_timestamp()}*
"""
    
    sync_report_path.write_text(sync_report_content, encoding="utf-8")
    
    return RequirementSyncOutput(
        taskKey=task_key,
        jiraIssueKey=input.jiraIssueKey,
        createdFiles=created_files,
        updatedFiles=updated_files,
        generatedTests=generated_tests,
        syncReport=str(sync_report_path)
    )

# ---------- çŠ¶æ€ç®¡ç†å·¥å…·å‡½æ•° ----------

@app.tool()
def status_query(input: StatusQueryInput) -> StatusQueryOutput:
    """æŸ¥è¯¢ä»»åŠ¡çš„çŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…æ‹¬å½“å‰çŠ¶æ€ã€å…è®¸çš„è½¬æ¢ã€å†å²è®°å½•å’Œç»Ÿè®¡ä¿¡æ¯ã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    task_metadata = _get_task_metadata(project_root, input.taskKey)
    current_status = _read_task_status(project_root, input.taskKey)
    
    # è·å–å…è®¸çš„çŠ¶æ€è½¬æ¢
    allowed_transitions = _STATUS_TRANSITIONS.get(current_status, [])
    
    # è·å–å†å²è®°å½•
    history = None
    if input.includeHistory:
        history = task_metadata.get("reviews", [])
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        history = sorted(history, key=lambda x: x.get("time", ""), reverse=True)
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = None
    if input.includeStats:
        stats = task_metadata.get("statusStats", {})
        # æ·»åŠ ä¸€äº›æ´¾ç”Ÿç»Ÿè®¡
        if history:
            stats["historyCount"] = len(history)
            stats["averageTimeInStatus"] = {}  # å¯ä»¥åç»­è®¡ç®—
    
    return StatusQueryOutput(
        taskKey=input.taskKey,
        currentStatus=current_status,
        allowedTransitions=allowed_transitions,
        history=history,
        stats=stats
    )

@app.tool()
def status_batch_operation(input: StatusBatchInput) -> StatusBatchOutput:
    """æ‰¹é‡æ‰§è¡ŒçŠ¶æ€è½¬æ¢æ“ä½œã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    successful = []
    failed = []
    
    for i, op in enumerate(input.operations):
        try:
            # éªŒè¯æ“ä½œå‚æ•°
            task_key = op.get("taskKey")
            new_status = op.get("newStatus") 
            by = op.get("by")
            notes = op.get("notes", "")
            
            if not all([task_key, new_status, by]):
                raise ValueError("ç¼ºå°‘å¿…è¦å‚æ•°: taskKey, newStatus, by")
            
            # æ‰§è¡ŒçŠ¶æ€è½¬æ¢
            status_input = ReviewStatusInput(
                taskKey=task_key,
                newStatus=new_status,
                by=by,
                notes=notes,
                projectRoot=input.projectRoot
            )
            
            result = review_set_status(status_input)
            successful.append({
                "operation": i,
                "taskKey": task_key,
                "from": result.oldStatus,
                "to": result.newStatus,
                "by": by
            })
            
        except Exception as e:
            failed.append({
                "operation": i,
                "taskKey": op.get("taskKey", "unknown"),
                "error": str(e),
                "operation_data": op
            })
            
            if not input.continueOnError:
                break
    
    summary = {
        "total": len(input.operations),
        "successful": len(successful),
        "failed": len(failed)
    }
    
    return StatusBatchOutput(
        successful=successful,
        failed=failed,
        summary=summary
    )

@app.tool()
def status_report(input: StatusReportInput) -> StatusReportOutput:
    """ç”ŸæˆçŠ¶æ€æŠ¥å‘Šï¼ŒåŒ…æ‹¬æ‰€æœ‰ä»»åŠ¡çš„çŠ¶æ€ç»Ÿè®¡å’Œæ´»åŠ¨æ‘˜è¦ã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    tasks_dir = project_root / "Docs" / ".tasks"
    
    if not tasks_dir.exists():
        return StatusReportOutput(
            totalTasks=0,
            statusBreakdown={},
            recentActivity=[],
            blockedTasks=[],
            summary={"message": "æ²¡æœ‰æ‰¾åˆ°ä»»åŠ¡ç›®å½•"}
        )
    
    # æ‰«ææ‰€æœ‰ä»»åŠ¡æ–‡ä»¶
    task_files = list(tasks_dir.glob("*.md"))
    total_tasks = 0
    status_breakdown = {}
    recent_activity = []
    blocked_tasks = []
    
    for task_file in task_files:
        try:
            task_key = task_file.stem
            
            # è¯»å–ä»»åŠ¡å…ƒæ•°æ®
            post = frontmatter.load(task_file)
            metadata = post.metadata or {}
            current_status = metadata.get("status", "DRAFT")
            
            # åº”ç”¨è¿‡æ»¤å™¨
            if input.statusFilter and current_status not in input.statusFilter:
                continue
                
            if input.userFilter:
                owner = metadata.get("owner", "")
                reviewers = metadata.get("reviewers", [])
                if input.userFilter not in [owner] + list(reviewers):
                    continue
            
            total_tasks += 1
            status_breakdown[current_status] = status_breakdown.get(current_status, 0) + 1
            
            # æ”¶é›†æœ€è¿‘æ´»åŠ¨
            reviews = metadata.get("reviews", [])
            if reviews:
                latest_review = max(reviews, key=lambda x: x.get("time", ""))
                recent_activity.append({
                    "taskKey": task_key,
                    "action": f"{latest_review.get('from', 'UNKNOWN')} -> {latest_review.get('to', 'UNKNOWN')}",
                    "by": latest_review.get("by", "unknown"),
                    "time": latest_review.get("time", ""),
                    "notes": latest_review.get("notes", "")
                })
            
            # è¯†åˆ«é˜»å¡çš„ä»»åŠ¡
            if current_status == "CHANGES_REQUESTED":
                blocked_tasks.append({
                    "taskKey": task_key,
                    "status": current_status,
                    "owner": metadata.get("owner", "unknown"),
                    "lastUpdate": metadata.get("updatedAt", "unknown")
                })
                
        except Exception as e:
            # è·³è¿‡æ— æ³•è§£æçš„æ–‡ä»¶
            continue
    
    # æŒ‰æ—¶é—´æ’åºæœ€è¿‘æ´»åŠ¨
    recent_activity.sort(key=lambda x: x.get("time", ""), reverse=True)
    recent_activity = recent_activity[:20]  # åªå–æœ€è¿‘20æ¡
    
    summary = {
        "totalFiles": len(task_files),
        "validTasks": total_tasks,
        "mostCommonStatus": max(status_breakdown.items(), key=lambda x: x[1])[0] if status_breakdown else "N/A",
        "blockedCount": len(blocked_tasks),
        "recentActivityCount": len(recent_activity)
    }
    
    return StatusReportOutput(
        totalTasks=total_tasks,
        statusBreakdown=status_breakdown,
        recentActivity=recent_activity,
        blockedTasks=blocked_tasks,
        summary=summary
    )


@app.tool()
def wiki_diagnostic(input: WikiDiagnosticInput) -> WikiDiagnosticOutput:
    """è¯Šæ–­Wiki APIè¿æ¥å’Œé¡µé¢è®¿é—®é—®é¢˜ï¼Œæµ‹è¯•ä¸åŒçš„APIè·¯å¾„ã€‚"""
    try:
        session = _get_wiki_session()
        base_url = os.getenv("WIKI_BASE_URL", "").rstrip("/")
        context_path = os.getenv("WIKI_CONTEXT_PATH", "").strip("/")
        
        api_tests = {}
        recommendations = []
        
        # æµ‹è¯•ä¸åŒçš„APIè·¯å¾„ï¼ŒåŸºäºæ‚¨æä¾›çš„APIç»“æ„
        test_paths = [
            f"{base_url}/rest/api/content/{input.pageId}",
            f"{base_url}/rest/api/1.0/content/{input.pageId}",
            f"{base_url}/rest/api/2.0/content/{input.pageId}",
            f"{base_url}/rest/tinymce/1/content/{input.pageId}",
            f"{base_url}/rest/tinymce/1.0/content/{input.pageId}",
            f"{base_url}/rest/prototype/1/content/{input.pageId}",
        ]
        
        if context_path:
            test_paths.extend([
                f"{base_url}/{context_path}/rest/api/content/{input.pageId}",
                f"{base_url}/{context_path}/rest/api/1/content/{input.pageId}",
                f"{base_url}/{context_path}/rest/tinymce/1/content/{input.pageId}",
            ])
        
        # æµ‹è¯•æ¯ä¸ªAPIè·¯å¾„
        for path in test_paths:
            try:
                params = {"expand": "body.storage,version,space"}
                resp = session.get(path, params=params, timeout=10)
                
                api_tests[path] = {
                    "status_code": resp.status_code,
                    "success": resp.status_code < 400,
                    "response_size": len(resp.text),
                    "content_type": resp.headers.get("content-type", ""),
                    "error": None if resp.status_code < 400 else resp.text[:200]
                }
                
                # å¦‚æœæˆåŠŸï¼Œè®°å½•é¡µé¢ä¿¡æ¯
                if resp.status_code < 400:
                    try:
                        data = resp.json()
                        api_tests[path]["page_title"] = data.get("title", "")
                        api_tests[path]["page_type"] = data.get("type", "")
                        api_tests[path]["space_key"] = data.get("space", {}).get("key", "")
                    except:
                        pass
                        
            except Exception as e:
                api_tests[path] = {
                    "status_code": 0,
                    "success": False,
                    "error": str(e)[:200]
                }
        
        # åˆ†æç»“æœå¹¶ç»™å‡ºå»ºè®®
        successful_apis = [path for path, result in api_tests.items() if result.get("success")]
        
        if successful_apis:
            recommendations.append(f"âœ… å‘ç°å¯ç”¨çš„APIè·¯å¾„: {successful_apis[0]}")
            
            # ç¡®å®šæ­£ç¡®çš„APIç‰ˆæœ¬
            if "/rest/api/content/" in successful_apis[0]:
                recommendations.append("ğŸ”§ å»ºè®®è®¾ç½® WIKI_API_VERSION=''ï¼ˆç©ºå­—ç¬¦ä¸²ï¼‰")
            elif "/rest/api/1/" in successful_apis[0]:
                recommendations.append("ğŸ”§ å»ºè®®è®¾ç½® WIKI_API_VERSION='1'")
            elif "/rest/tinymce/" in successful_apis[0]:
                recommendations.append("ğŸ”§ ç³»ç»Ÿä¸»è¦ä½¿ç”¨TinyMCE APIï¼ŒREST APIä½œä¸ºå¤‡ç”¨")
                
        else:
            recommendations.append("âŒ æ‰€æœ‰APIè·¯å¾„éƒ½å¤±è´¥äº†")
            recommendations.append("ğŸ” è¯·æ£€æŸ¥:")
            recommendations.append("  - WIKI_BASE_URLæ˜¯å¦æ­£ç¡®")
            recommendations.append("  - é¡µé¢IDæ˜¯å¦å­˜åœ¨")
            recommendations.append("  - ç”¨æˆ·æƒé™æ˜¯å¦è¶³å¤Ÿ")
            recommendations.append("  - ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        
        # æµ‹è¯•å¤šç§è¯„è®ºAPI
        comment_test_urls = [
            f"{base_url}/rest/tinymce/1/content/{input.pageId}/comment",
            f"{base_url}/rest/tinymce/1.0/content/{input.pageId}/comment", 
            f"{base_url}/rest/api/content/{input.pageId}/child/comment",
            f"{base_url}/rest/api/1.0/content/{input.pageId}/child/comment",
        ]
        
        if context_path:
            comment_test_urls.extend([
                f"{base_url}/{context_path}/rest/tinymce/1/content/{input.pageId}/comment",
                f"{base_url}/{context_path}/rest/tinymce/1.0/content/{input.pageId}/comment",
                f"{base_url}/{context_path}/rest/api/content/{input.pageId}/child/comment",
                f"{base_url}/{context_path}/rest/api/1.0/content/{input.pageId}/child/comment",
            ])
        
        # æµ‹è¯•æ¯ä¸ªè¯„è®ºAPI
        working_comment_apis = []
        for comment_url in comment_test_urls:
            try:
                resp = session.get(comment_url, timeout=10)
                api_tests[f"comment_api_{len(api_tests)}"] = {
                    "url": comment_url,
                    "status_code": resp.status_code,
                    "success": resp.status_code < 400,
                    "note": "è¯„è®ºAPIæµ‹è¯•"
                }
                
                if resp.status_code < 400:
                    working_comment_apis.append(comment_url)
                elif resp.status_code == 501:
                    api_tests[f"comment_api_{len(api_tests)-1}"]["note"] += " (501 Not Implemented)"
                    
            except Exception as e:
                api_tests[f"comment_api_{len(api_tests)}"] = {
                    "url": comment_url,
                    "error": str(e)[:200],
                    "success": False,
                    "note": "è¯„è®ºAPIæµ‹è¯•å¼‚å¸¸"
                }
        
        # è¯„è®ºAPIå»ºè®®
        if working_comment_apis:
            recommendations.append(f"âœ… æ‰¾åˆ°å¯ç”¨çš„è¯„è®ºAPI: {working_comment_apis[0]}")
        else:
            recommendations.append("âŒ æ‰€æœ‰è¯„è®ºAPIéƒ½è¿”å›501é”™è¯¯")
            recommendations.append("ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
            recommendations.append("  - æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰è¯„è®ºæƒé™")
            recommendations.append("  - ç¡®è®¤é¡µé¢æ˜¯å¦å…è®¸è¯„è®º")
            recommendations.append("  - å°è¯•ä¸åŒçš„APIç‰ˆæœ¬æˆ–ç«¯ç‚¹")
            recommendations.append("  - è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æœåŠ¡å™¨é…ç½®")
        
        return WikiDiagnosticOutput(
            pageId=input.pageId,
            apiTests=api_tests,
            recommendations=recommendations,
            hint=f"æµ‹è¯•äº†{len(test_paths)}ä¸ªAPIè·¯å¾„ï¼Œæ‰¾åˆ°{len(successful_apis)}ä¸ªå¯ç”¨è·¯å¾„"
        )
        
    except Exception as e:
        return WikiDiagnosticOutput(
            pageId=input.pageId,
            apiTests={},
            recommendations=[f"è¯Šæ–­è¿‡ç¨‹å‡ºé”™: {str(e)}"],
            hint=f"Wikiè¯Šæ–­å¤±è´¥: {str(e)}"
        )

if __name__ == "__main__":
    # ä»¥ stdio æ–¹å¼å¯åŠ¨ MCPï¼ˆFastMCP ä¼šå¤„ç†åè®®ç»†èŠ‚ï¼‰
    app.run()
