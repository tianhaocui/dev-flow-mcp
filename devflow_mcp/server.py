from __future__ import annotations
from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Dict, Any, Optional, Union, Literal
from pathlib import Path
import os
import json
import pymysql
import requests
from requests import Session
import yaml
from datetime import datetime
import frontmatter
import re
import subprocess

# æ–‡æ¡£æ ¹ç›®å½•å®šä½ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ DOCS_PROJECT_ROOTï¼Œå…¶æ¬¡ä½¿ç”¨è¿›ç¨‹å¯åŠ¨æ—¶çš„å·¥ä½œç›®å½•
# è¿™æ ·å¯å°†è¾“å‡ºå†™å…¥â€œè°ƒç”¨æ–¹é¡¹ç›®â€çš„ Docs ç›®å½•ï¼Œè€Œä¸æ˜¯ MCP è‡ªèº«ä»“åº“
PROJECT_ROOT = Path(os.getenv("DOCS_PROJECT_ROOT") or os.getcwd()).resolve()
DOCS_ROOT = PROJECT_ROOT / "Docs"
TASKS_DIR = DOCS_ROOT / ".tasks"
PROCESS_DIR = DOCS_ROOT / "ProcessDocuments"

# å†…ç½®å®ç°ï¼Œæ— éœ€å¤–éƒ¨MCPè·¯å¾„

app = FastMCP("devflow-mcp")

# ---------- Models (Inputs/Outputs) ----------
class PrepareDocsInput(BaseModel):
    """å‡†å¤‡ä»»åŠ¡ä¸»æ–‡æ¡£ä¸è¿‡ç¨‹æ–‡æ¡£çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="PrepareDocsInput", description="å‡†å¤‡ä»»åŠ¡ä¸»æ–‡æ¡£ä¸è¿‡ç¨‹æ–‡æ¡£çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†ï¼Œä¾‹å¦‚ PROJ-123")
    title: str = Field(..., description="ä»»åŠ¡æ ‡é¢˜")
    owner: str = Field(..., description="è´£ä»»äºº")
    reviewers: List[str] = Field(default_factory=list, description="å®¡æ ¸äººåˆ—è¡¨")
    force: bool = Field(False, description="è‹¥å·²å­˜åœ¨æ–‡æ¡£ï¼Œæ˜¯å¦å¼ºåˆ¶è¦†ç›–éª¨æ¶ï¼ˆè°¨æ…ï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ DOCS_PROJECT_ROOT æˆ–å½“å‰å·¥ä½œç›®å½•")

class PrepareDocsOutput(BaseModel):
    taskKey: str
    mainDocPath: str
    mainDocPathRelative: Optional[str] = None
    processDir: str
    processDirRelative: Optional[str] = None
    status: str

class CodeGenInput(BaseModel):
    """ä»£ç ç”Ÿæˆè®¡åˆ’çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="CodeGenInput", description="ä»£ç ç”Ÿæˆè®¡åˆ’çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    requirements: str = Field(..., description="éœ€æ±‚/ç›®æ ‡çš„æ–‡å­—è¯´æ˜")
    constraints: List[str] = Field(default_factory=list, description="å®ç°çº¦æŸï¼ˆè·¯å¾„/è§„èŒƒ/å®‰å…¨ç­‰ï¼‰")
    targetModules: List[str] = Field(default_factory=list, description="ç›®æ ‡æ¨¡å—åˆ—è¡¨ï¼Œä¾‹å¦‚ devflow_mcp")
    acceptanceCriteria: List[str] = Field(default_factory=list, description="éªŒæ”¶æ ‡å‡†åˆ—è¡¨")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class CodeGenOutput(BaseModel):
    codePlanDoc: str
    codePlanDocRelative: Optional[str] = None
    statusHint: str

class CurlGenInput(BaseModel):
    """curl æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="CurlGenInput", description="curl æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆçš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    baseUrl: Optional[str] = Field(None, description="æ¥å£åŸºç¡€åœ°å€ï¼Œä¾‹å¦‚ https://api.example.comï¼›è‹¥ä» OpenAPI servers æ¨æ–­å¯çœç•¥")
    endpoints: List[Dict[str, Any]] = Field(default_factory=list, description="è¦ç”Ÿæˆçš„æ¥å£æ¸…å•ï¼ˆmethod/path/headers/payloadï¼‰ï¼Œè‹¥ç•™ç©ºå°†å°è¯•ä» OpenAPI æ¨æ–­")
    envVars: Dict[str, str] = Field(default_factory=dict, description="env å˜é‡ç¤ºä¾‹ï¼Œå¦‚ API_TOKEN")
    openapiUrl: Optional[str] = Field(None, description="OpenAPI æ–‡æ¡£çš„ URLï¼ˆjson/yamlï¼‰")
    openapiPath: Optional[str] = Field(None, description="OpenAPI æ–‡æ¡£çš„æœ¬åœ°è·¯å¾„ï¼ˆjson/yamlï¼‰")
    maxEndpoints: int = Field(20, description="ä» OpenAPI æå–çš„æœ€å¤§æ¥å£æ•°é‡ä¸Šé™")
    authMode: Literal['none', 'authorization_bearer', 'header_token', 'query_token'] = Field('none', description="é‰´æƒæ–¹å¼ï¼šæ— /Authorization Bearer/è‡ªå®šä¹‰è¯·æ±‚å¤´/Query å‚æ•°")
    tokenEnvVar: str = Field('API_TOKEN', description="ç”¨äº curl çš„ä»¤ç‰Œç¯å¢ƒå˜é‡åï¼Œä¾‹å¦‚ API_TOKENï¼Œå°†ä»¥ $API_TOKEN å¼•ç”¨")
    headerName: str = Field('accessToken', description="å½“ authMode=header_token æ—¶ä½¿ç”¨çš„è¯·æ±‚å¤´åç§°ï¼ˆé»˜è®¤ accessTokenï¼‰")
    queryParamName: str = Field('accessToken', description="å½“ authMode=query_token æ—¶ä½¿ç”¨çš„æŸ¥è¯¢å‚æ•°åï¼ˆé»˜è®¤ accessTokenï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class CurlGenOutput(BaseModel):
    curlDoc: str
    curlDocRelative: Optional[str] = None
    snippets: List[str]

class MySQLPlanInput(BaseModel):
    """MySQL éªŒè¯è®¡åˆ’çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="MySQLPlanInput", description="MySQL éªŒè¯è®¡åˆ’çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    tables: List[str] = Field(default_factory=list, description="æ¶‰åŠçš„è¡¨ï¼ˆå¯é€‰ï¼‰")
    preconditions: List[str] = Field(default_factory=list, description="å‰ç½® SQL è¯­å¥åˆ—è¡¨ï¼Œå¦‚å»ºè¡¨/å‡†å¤‡æ•°æ®")
    assertions: List[Dict[str, Any]] = Field(default_factory=list, description="æ–­è¨€ SQL ä¸æœŸæœ›æè¿°")
    cleanup: List[str] = Field(default_factory=list, description="æ¸…ç† SQL è¯­å¥åˆ—è¡¨")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class MySQLStatementResult(BaseModel):
    sql: str
    success: bool
    rowsAffected: Optional[int] = None
    rows: Optional[List[Dict[str, Any]]] = None
    error: Optional[str] = None

class MySQLPlanOutput(BaseModel):
    verificationPlanDoc: str
    verificationPlanDocRelative: Optional[str] = None
    sqlPlan: Dict[str, Any]
    executionResults: Optional[List[MySQLStatementResult]] = None
    executed: bool = False

class IntegrationDocInput(BaseModel):
    """å¯¹æ¥æ–‡æ¡£ç”Ÿæˆçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="IntegrationDocInput", description="å¯¹æ¥æ–‡æ¡£ç”Ÿæˆçš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    audience: str = Field(..., description="ç›®æ ‡è¯»è€…ï¼šinternal|external")
    systems: List[str] = Field(default_factory=list, description="æ¶‰åŠç³»ç»Ÿåˆ—è¡¨")
    interfaces: List[Dict[str, Any]] = Field(default_factory=list, description="æ¥å£å®šä¹‰åˆ—è¡¨ï¼ˆname/method/path/schemasï¼‰")
    notes: Optional[str] = Field(None, description="è¡¥å……è¯´æ˜ï¼ˆå¯é€‰ï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class IntegrationDocOutput(BaseModel):
    integrationDoc: str
    integrationDocRelative: Optional[str] = None
    toc: List[str]

class JiraPublishInput(BaseModel):
    """ç”Ÿæˆ Jira æäº¤è®¡åˆ’çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraPublishInput", description="ç”Ÿæˆ Jira æäº¤è®¡åˆ’çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    projectKey: Optional[str] = Field(None, description="Jira é¡¹ç›® Keyï¼ˆå¯é€‰ï¼Œä¸ºç©ºæ—¶è‡ªåŠ¨ä»Gitåˆ†æ”¯è§£æï¼‰")
    issueType: str = Field(..., description="å·¥å•ç±»å‹ï¼Œå¦‚ Task/Story/Documentation")
    summary: str = Field(..., description="å·¥å•æ ‡é¢˜")
    description: str = Field(..., description="å·¥å•æè¿°")
    labels: List[str] = Field(default_factory=list, description="æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")
    attachments: List[str] = Field(default_factory=list, description="è¦ä¸Šä¼ çš„é™„ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")
    links: List[Dict[str, str]] = Field(default_factory=list, description="è¦å…³è”çš„å·¥å•åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•ï¼Œç”¨äºè§£æé™„ä»¶ç›¸å¯¹è·¯å¾„")
    autoDetectFromBranch: bool = Field(True, description="æ˜¯å¦è‡ªåŠ¨ä»Gitåˆ†æ”¯æ£€æµ‹é¡¹ç›®ä¿¡æ¯ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")

class JiraCreateIssueOutput(BaseModel):
    issueKey: Optional[str] = None
    url: Optional[str] = None
    hint: str

class JiraAttachFilesOutput(BaseModel):
    attached: List[str]
    failed: List[Dict[str, Any]]
    hint: str

class JiraPublishOutput(BaseModel):
    jiraPlanDoc: str
    jiraPlanDocRelative: Optional[str] = None
    jiraPayload: Dict[str, Any]
    createdIssue: Optional[JiraCreateIssueOutput] = None
    attachmentResults: Optional[JiraAttachFilesOutput] = None
    executed: bool = False

class ReviewStatusInput(BaseModel):
    """æ–‡æ¡£çŠ¶æ€æµè½¬çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="ReviewStatusInput", description="æ–‡æ¡£çŠ¶æ€æµè½¬çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    newStatus: str = Field(..., description="ç›®æ ‡çŠ¶æ€ï¼šPENDING_REVIEW/APPROVED/CHANGES_REQUESTED/PUBLISHED")
    by: str = Field(..., description="æ“ä½œè€…")
    notes: Optional[str] = Field(None, description="å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ DOCS_PROJECT_ROOT æˆ–å½“å‰å·¥ä½œç›®å½•")

class ReviewStatusOutput(BaseModel):
    taskKey: str
    oldStatus: str
    newStatus: str

class ReviewChecklistInput(BaseModel):
    """ä¸€è‡´æ€§æ£€æŸ¥çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="ReviewChecklistInput", description="ä¸€è‡´æ€§æ£€æŸ¥çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    checks: List[str] = Field(..., description="éœ€è¦æ‰§è¡Œçš„æ£€æŸ¥é¡¹æ ‡è¯†åˆ—è¡¨")

class ReviewChecklistOutput(BaseModel):
    passed: bool
    failedItems: List[Dict[str, str]]

# æ–°å¢ï¼šçŠ¶æ€ç®¡ç†ç›¸å…³æ¨¡å‹
class StatusQueryInput(BaseModel):
    """æŸ¥è¯¢çŠ¶æ€ä¿¡æ¯çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="StatusQueryInput", description="æŸ¥è¯¢çŠ¶æ€ä¿¡æ¯çš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    includeHistory: bool = Field(True, description="æ˜¯å¦åŒ…å«å†å²è®°å½•")
    includeStats: bool = Field(True, description="æ˜¯å¦åŒ…å«ç»Ÿè®¡ä¿¡æ¯")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class StatusQueryOutput(BaseModel):
    taskKey: str
    currentStatus: str
    allowedTransitions: List[str]
    history: Optional[List[Dict[str, Any]]] = None
    stats: Optional[Dict[str, Any]] = None

class StatusBatchInput(BaseModel):
    """æ‰¹é‡çŠ¶æ€æ“ä½œçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="StatusBatchInput", description="æ‰¹é‡çŠ¶æ€æ“ä½œçš„è¾“å…¥å‚æ•°") 
    operations: List[Dict[str, Any]] = Field(..., description="æ‰¹é‡æ“ä½œåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«taskKeyã€newStatusã€byã€notesç­‰")
    continueOnError: bool = Field(False, description="é‡åˆ°é”™è¯¯æ—¶æ˜¯å¦ç»§ç»­æ‰§è¡Œ")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class StatusBatchOutput(BaseModel):
    successful: List[Dict[str, Any]]
    failed: List[Dict[str, Any]]
    summary: Dict[str, int]

class StatusReportInput(BaseModel):
    """çŠ¶æ€æŠ¥å‘Šçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="StatusReportInput", description="çŠ¶æ€æŠ¥å‘Šçš„è¾“å…¥å‚æ•°")
    includeAll: bool = Field(True, description="æ˜¯å¦åŒ…å«æ‰€æœ‰ä»»åŠ¡")
    statusFilter: Optional[List[str]] = Field(None, description="çŠ¶æ€è¿‡æ»¤å™¨")
    userFilter: Optional[str] = Field(None, description="ç”¨æˆ·è¿‡æ»¤å™¨")
    projectRoot: Optional[str] = Field(None, description="ï¼ˆå¯é€‰ï¼‰é¡¹ç›®æ ¹ç›®å½•")

class StatusReportOutput(BaseModel):
    totalTasks: int
    statusBreakdown: Dict[str, int]
    recentActivity: List[Dict[str, Any]]
    blockedTasks: List[Dict[str, Any]]
    summary: Dict[str, Any]

# ---------- Jiraåˆ†æä¸æµ‹è¯•å¯¹æ¯”ç›¸å…³æ¨¡å‹ ----------

class JiraFetchInput(BaseModel):
    """Jiraå·¥å•è·å–çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraFetchInput", description="Jiraå·¥å•è·å–çš„è¾“å…¥å‚æ•°")
    issueKey: str = Field(..., description="Jiraå·¥å•Keyï¼Œå¦‚ PROJ-123")
    includeSubtasks: bool = Field(True, description="æ˜¯å¦åŒ…å«å­ä»»åŠ¡")
    includeAttachments: bool = Field(True, description="æ˜¯å¦ä¸‹è½½é™„ä»¶")
    includeHistory: bool = Field(False, description="æ˜¯å¦åŒ…å«å˜æ›´å†å²")
    attachmentPath: Optional[str] = Field(None, description="é™„ä»¶ä¸‹è½½è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰")
    
class JiraIssueInfo(BaseModel):
    """Jiraå·¥å•ä¿¡æ¯"""
    key: str
    summary: str
    description: str
    status: str
    issueType: str
    priority: str
    assignee: Optional[str] = None
    reporter: Optional[str] = None
    created: str
    updated: str
    customFields: Dict[str, Any] = Field(default_factory=dict)
    
class JiraSubtask(BaseModel):
    """Jiraå­ä»»åŠ¡ä¿¡æ¯"""
    key: str
    summary: str
    description: str
    status: str
    assignee: Optional[str] = None
    
class JiraAttachment(BaseModel):
    """Jiraé™„ä»¶ä¿¡æ¯"""
    id: str
    filename: str
    size: int
    mimeType: str
    author: str
    created: str
    downloadUrl: str
    localPath: Optional[str] = None  # ä¸‹è½½åçš„æœ¬åœ°è·¯å¾„
    
class JiraFetchOutput(BaseModel):
    issueInfo: JiraIssueInfo
    subtasks: List[JiraSubtask] = Field(default_factory=list)
    attachments: List[JiraAttachment] = Field(default_factory=list)
    downloadedFiles: List[str] = Field(default_factory=list)
    
class TestAnalysisInput(BaseModel):
    """æµ‹è¯•åˆ†æçš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="TestAnalysisInput", description="æµ‹è¯•åˆ†æçš„è¾“å…¥å‚æ•°")
    taskKey: str = Field(..., description="DevFlowä»»åŠ¡Key")
    jiraIssueKey: str = Field(..., description="å…³è”çš„Jiraå·¥å•Key")
    analysisType: str = Field("coverage", description="åˆ†æç±»å‹ï¼šcoverage/gap/recommendation")
    includeAttachments: bool = Field(True, description="æ˜¯å¦åˆ†æé™„ä»¶å†…å®¹")
    projectRoot: Optional[str] = Field(None, description="é¡¹ç›®æ ¹ç›®å½•")
    
class RequirementItem(BaseModel):
    """éœ€æ±‚æ¡ç›®"""
    id: str
    title: str
    description: str
    priority: str = "Medium"
    category: str = "åŠŸèƒ½æ€§"
    source: str  # æ¥æºï¼šdescription/subtask/attachment
    
class TestCaseMatch(BaseModel):
    """æµ‹è¯•ç”¨ä¾‹åŒ¹é…ä¿¡æ¯"""
    requirementId: str
    testCases: List[str] = Field(default_factory=list)
    coverage: float  # 0-1ä¹‹é—´çš„è¦†ç›–åº¦
    gaps: List[str] = Field(default_factory=list)
    
class TestAnalysisOutput(BaseModel):
    taskKey: str
    jiraIssueKey: str
    requirements: List[RequirementItem]
    testMatches: List[TestCaseMatch] 
    overallCoverage: float
    missingTests: List[str]
    recommendedTests: List[str]
    analysisReport: str  # è¯¦ç»†çš„åˆ†ææŠ¥å‘Šè·¯å¾„
    
class RequirementSyncInput(BaseModel):
    """éœ€æ±‚åŒæ­¥çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="RequirementSyncInput", description="éœ€æ±‚åŒæ­¥çš„è¾“å…¥å‚æ•°")
    jiraIssueKey: str = Field(..., description="Jiraå·¥å•Key")
    targetTaskKey: Optional[str] = Field(None, description="ç›®æ ‡DevFlowä»»åŠ¡Keyï¼Œä¸ºç©ºåˆ™è‡ªåŠ¨åˆ›å»º")
    syncMode: str = Field("update", description="åŒæ­¥æ¨¡å¼ï¼šcreate/update/merge")
    autoGenerateTests: bool = Field(False, description="æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
    projectRoot: Optional[str] = Field(None, description="é¡¹ç›®æ ¹ç›®å½•")
    
class RequirementSyncOutput(BaseModel):
    taskKey: str
    jiraIssueKey: str
    createdFiles: List[str]
    updatedFiles: List[str]
    generatedTests: List[str]
    syncReport: str

# ---------- Git Utils ----------

def _get_current_git_branch() -> str:
    """è·å–å½“å‰Gitåˆ†æ”¯åç§°"""
    try:
        result = subprocess.run(
            ["git", "branch", "--show-current"], 
            capture_output=True, 
            text=True, 
            check=True
        )
        return result.stdout.strip()
    except (subprocess.CalledProcessError, FileNotFoundError):
        return "main"  # é»˜è®¤åˆ†æ”¯

def _extract_ticket_from_branch(branch_name: str) -> Optional[str]:
    """ä»åˆ†æ”¯åç§°ä¸­æå–ticketå·ç """
    if not branch_name:
        return None
        
    # å¸¸è§çš„åˆ†æ”¯å‘½åæ¨¡å¼
    patterns = [
        r'^feature/([A-Z]+-\d+)',     # feature/DTS-7442
        r'^bugfix/([A-Z]+-\d+)',      # bugfix/DTS-7442
        r'^hotfix/([A-Z]+-\d+)',      # hotfix/DTS-7442
        r'^([A-Z]+-\d+)-.*',          # DTS-7442-some-description
        r'^([A-Z]+-\d+)$',            # DTS-7442
        r'([A-Z]+-\d+)',              # ä»»æ„ä½ç½®çš„ DTS-7442 æ ¼å¼
    ]
    
    for pattern in patterns:
        match = re.search(pattern, branch_name, re.IGNORECASE)
        if match:
            return match.group(1).upper()
    
    return None

def _get_project_key_from_ticket(ticket_key: str) -> Optional[str]:
    """ä»ticketå·ç ä¸­æå–é¡¹ç›®key"""
    if not ticket_key:
        return None
    
    # æå–é¡¹ç›®å‰ç¼€ï¼Œä¾‹å¦‚ DTS-7442 -> DTS
    match = re.match(r'^([A-Z]+)-\d+', ticket_key)
    if match:
        return match.group(1)
    
    return None

def _auto_detect_jira_context() -> Dict[str, Optional[str]]:
    """è‡ªåŠ¨æ£€æµ‹å½“å‰ä¸Šä¸‹æ–‡çš„Jiraç›¸å…³ä¿¡æ¯"""
    branch_name = _get_current_git_branch()
    ticket_key = _extract_ticket_from_branch(branch_name)
    project_key = _get_project_key_from_ticket(ticket_key) if ticket_key else None
    
    return {
        "branch_name": branch_name,
        "ticket_key": ticket_key,
        "project_key": project_key
    }

# ---------- Utils ----------

def _ensure_dirs_for(project_root: Optional[Path], task_key: Optional[str] = None) -> Dict[str, Path]:
    base = (project_root or PROJECT_ROOT)
    docs_root = base / "Docs"
    tasks_dir = docs_root / ".tasks"
    process_dir = docs_root / "ProcessDocuments"
    if task_key:
        process_dir = process_dir / f"task-{task_key}"
    tasks_dir.mkdir(parents=True, exist_ok=True)
    process_dir.mkdir(parents=True, exist_ok=True)
    return {"docs_root": docs_root, "tasks_dir": tasks_dir, "process_dir": process_dir}


def _timestamp() -> str:
    return datetime.utcnow().isoformat()


def _resolve_project_root(explicit: Optional[str]) -> Path:
    if explicit:
        return Path(explicit).resolve()
    env = os.getenv("DOCS_PROJECT_ROOT")
    if env:
        return Path(env).resolve()
    return Path(os.getcwd()).resolve()


def _relpath(path: Path, root: Path) -> str:
    try:
        return str(path.resolve().relative_to(root.resolve()))
    except Exception:
        return str(path)


def _read_task_status(project_root: Path, task_key: str) -> str:
    main_doc = (project_root / "Docs" / ".tasks" / f"{task_key}.md")
    if not main_doc.exists():
        return "DRAFT"
    try:
        post = frontmatter.load(main_doc)
        status = str(post.metadata.get("status", "DRAFT")).strip().upper()
        return status or "DRAFT"
    except Exception:
        return "DRAFT"


# çŠ¶æ€å®šä¹‰å’Œè½¬æ¢è§„åˆ™
_STATUS_ORDER = {"DRAFT": 1, "PENDING_REVIEW": 2, "CHANGES_REQUESTED": 2, "APPROVED": 3, "PUBLISHED": 4}

# åˆæ³•çš„çŠ¶æ€è½¬æ¢è·¯å¾„
_STATUS_TRANSITIONS = {
    "DRAFT": ["PENDING_REVIEW"],
    "PENDING_REVIEW": ["APPROVED", "CHANGES_REQUESTED"],
    "CHANGES_REQUESTED": ["PENDING_REVIEW", "DRAFT"], 
    "APPROVED": ["PUBLISHED", "CHANGES_REQUESTED"],
    "PUBLISHED": []  # ç»ˆæ€ï¼Œä¸å…è®¸è½¬æ¢
}

def _validate_status_transition(from_status: str, to_status: str) -> bool:
    """éªŒè¯çŠ¶æ€è½¬æ¢æ˜¯å¦åˆæ³•"""
    if from_status not in _STATUS_TRANSITIONS:
        return False
    return to_status in _STATUS_TRANSITIONS[from_status]

def _require_min_status(project_root: Path, task_key: str, min_status: str) -> None:
    current = _read_task_status(project_root, task_key)
    if _STATUS_ORDER.get(current, 0) < _STATUS_ORDER.get(min_status, 0):
        raise ValueError(f"Action not allowed: require >= {min_status}, current={current}")

class StatusValidationError(Exception):
    """çŠ¶æ€éªŒè¯é”™è¯¯"""
    pass

def _get_task_metadata(project_root: Path, task_key: str) -> Dict[str, Any]:
    """è·å–ä»»åŠ¡çš„å…ƒæ•°æ®"""
    main_doc = (project_root / "Docs" / ".tasks" / f"{task_key}.md")
    if not main_doc.exists():
        return {}
    try:
        post = frontmatter.load(main_doc)
        return post.metadata or {}
    except Exception:
        return {}

# ---------- Jiraä¸æµ‹è¯•åˆ†æè¾…åŠ©å‡½æ•° ----------

def _download_jira_attachment(session: Session, attachment_info: Dict[str, Any], download_dir: Path) -> Optional[str]:
    """ä¸‹è½½Jiraé™„ä»¶åˆ°æŒ‡å®šç›®å½•"""
    try:
        download_url = attachment_info.get("content", "")
        filename = attachment_info.get("filename", f"attachment_{attachment_info.get('id', 'unknown')}")
        
        if not download_url:
            return None
            
        response = session.get(download_url, stream=True, timeout=60)
        if response.status_code >= 400:
            return None
            
        download_dir.mkdir(parents=True, exist_ok=True)
        file_path = download_dir / filename
        
        with open(file_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    
        return str(file_path)
        
    except Exception:
        return None

def _parse_requirements_from_text(text: str, source: str = "description") -> List[RequirementItem]:
    """ä»æ–‡æœ¬ä¸­è§£æéœ€æ±‚æ¡ç›®"""
    requirements = []
    
    if not text or not text.strip():
        return requirements
    
    # ç®€å•çš„éœ€æ±‚è¯†åˆ«ç®—æ³•
    lines = text.split('\n')
    current_req = None
    req_id = 1
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # è¯†åˆ«éœ€æ±‚æ ‡è¯†ï¼ˆå¦‚ï¼šéœ€æ±‚1ã€Featureã€åŠŸèƒ½ç­‰ï¼‰
        req_patterns = [
            r'^(\d+[\.\)]\s*)',  # 1. æˆ– 1) å¼€å¤´
            r'^([éœ€æ±‚åŠŸèƒ½ç‰¹æ€§]\d*[\.\:ï¼š]\s*)',  # éœ€æ±‚1. æˆ– åŠŸèƒ½:
            r'^(.*åº”è¯¥|.*å¿…é¡»|.*éœ€è¦)',  # éœ€æ±‚æ€§è¯­è¨€
            r'^(User Story|Feature|éœ€æ±‚)[\s\:ï¼š]',  # æ˜ç¡®æ ‡è¯†
        ]
        
        is_requirement = False
        for pattern in req_patterns:
            if re.search(pattern, line):
                is_requirement = True
                break
        
        if is_requirement or len(line) > 20:  # é•¿å¥å­å¯èƒ½æ˜¯éœ€æ±‚æè¿°
            # ç¡®å®šä¼˜å…ˆçº§
            priority = "Medium"
            if "é‡è¦" in line or "å…³é”®" in line or "é«˜ä¼˜å…ˆçº§" in line:
                priority = "High"
            elif "å¯é€‰" in line or "ä½ä¼˜å…ˆçº§" in line:
                priority = "Low"
            
            # ç¡®å®šç±»åˆ«
            category = "åŠŸèƒ½æ€§"
            if "æ€§èƒ½" in line or "å“åº”æ—¶é—´" in line:
                category = "æ€§èƒ½"
            elif "å®‰å…¨" in line or "æƒé™" in line:
                category = "å®‰å…¨æ€§"
            elif "ç•Œé¢" in line or "UI" in line or "ç”¨æˆ·ä½“éªŒ" in line:
                category = "ç•Œé¢"
            
            requirements.append(RequirementItem(
                id=f"REQ-{source}-{req_id:03d}",
                title=line[:50] + ("..." if len(line) > 50 else ""),
                description=line,
                priority=priority,
                category=category,
                source=source
            ))
            req_id += 1
    
    return requirements

def _extract_test_cases_from_file(file_path: Path) -> List[str]:
    """ä»æµ‹è¯•æ–‡ä»¶ä¸­æå–æµ‹è¯•ç”¨ä¾‹"""
    test_cases = []
    
    if not file_path.exists():
        return test_cases
        
    try:
        content = file_path.read_text(encoding="utf-8")
        
        # æŸ¥æ‰¾curlå‘½ä»¤
        curl_pattern = r'curl\s+.*'
        curl_matches = re.findall(curl_pattern, content, re.MULTILINE)
        test_cases.extend([f"APIæµ‹è¯•: {match[:80]}..." for match in curl_matches])
        
        # æŸ¥æ‰¾æµ‹è¯•æè¿°
        test_patterns = [
            r'###?\s*æµ‹è¯•ç”¨ä¾‹\s*\d*[\:\s]+(.*)',
            r'###?\s*Test Case\s*\d*[\:\s]+(.*)',
            r'###?\s*ç”¨ä¾‹\s*\d*[\:\s]+(.*)',
            r'-\s*æµ‹è¯•[ï¼š:]\s*(.*)',
        ]
        
        for pattern in test_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            test_cases.extend(matches)
    
    except Exception:
        pass
        
    return test_cases

def _calculate_coverage(requirements: List[RequirementItem], test_cases: List[str]) -> List[TestCaseMatch]:
    """è®¡ç®—éœ€æ±‚è¦†ç›–åº¦"""
    matches = []
    
    for req in requirements:
        matched_tests = []
        coverage = 0.0
        gaps = []
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ç®—æ³•
        req_keywords = set(re.findall(r'\w+', req.description.lower()))
        
        for test_case in test_cases:
            test_keywords = set(re.findall(r'\w+', test_case.lower()))
            
            # è®¡ç®—å…³é”®è¯é‡å åº¦
            overlap = len(req_keywords.intersection(test_keywords))
            if overlap > 0:
                matched_tests.append(test_case)
                coverage += min(overlap / len(req_keywords), 1.0)
        
        coverage = min(coverage, 1.0)
        
        if coverage < 0.5:
            gaps.append("ç¼ºå°‘è¶³å¤Ÿçš„æµ‹è¯•ç”¨ä¾‹è¦†ç›–")
        if coverage == 0:
            gaps.append("å®Œå…¨æ²¡æœ‰ç›¸å…³æµ‹è¯•ç”¨ä¾‹")
            
        matches.append(TestCaseMatch(
            requirementId=req.id,
            testCases=matched_tests,
            coverage=coverage,
            gaps=gaps
        ))
    
    return matches

def _generate_test_recommendations(requirements: List[RequirementItem], test_matches: List[TestCaseMatch]) -> List[str]:
    """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ¨è"""
    recommendations = []
    
    for req, match in zip(requirements, test_matches):
        if match.coverage < 0.8:  # è¦†ç›–åº¦ä½äº80%
            # åŸºäºéœ€æ±‚ç±»åˆ«ç”Ÿæˆæ¨è
            if req.category == "åŠŸèƒ½æ€§":
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ åŠŸèƒ½æµ‹è¯•ï¼šéªŒè¯{req.title}")
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ è¾¹ç•Œæµ‹è¯•ï¼šå¼‚å¸¸è¾“å…¥å¤„ç†")
            elif req.category == "æ€§èƒ½":
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ æ€§èƒ½æµ‹è¯•ï¼šå“åº”æ—¶é—´éªŒè¯")
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ è´Ÿè½½æµ‹è¯•ï¼šå¹¶å‘å¤„ç†èƒ½åŠ›")
            elif req.category == "å®‰å…¨æ€§":
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ å®‰å…¨æµ‹è¯•ï¼šæƒé™éªŒè¯")
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ å®‰å…¨æµ‹è¯•ï¼šè¾“å…¥éªŒè¯")
            elif req.category == "ç•Œé¢":
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ UIæµ‹è¯•ï¼šç•Œé¢å…ƒç´ éªŒè¯")
                recommendations.append(f"ä¸ºéœ€æ±‚ {req.id} æ·»åŠ UXæµ‹è¯•ï¼šç”¨æˆ·äº¤äº’æµç¨‹")
    
    return recommendations[:10]  # é™åˆ¶æ¨èæ•°é‡


# ---------- Tool Stubs (no-op implementations) ----------

@app.tool()
def task_prepare_docs(input: PrepareDocsInput) -> PrepareDocsOutput:
    """å‡†å¤‡ä»»åŠ¡ä¸»æ–‡æ¡£ä¸åˆ†æ­¥éª¤æ–‡æ¡£çš„éª¨æ¶ï¼Œç›´æ¥ç”Ÿæˆæ–‡æ¡£æ–‡ä»¶ã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    main_doc = dirs["tasks_dir"] / f"{input.taskKey}.md"
    process_dir = dirs["process_dir"]
    
    # åˆ›å»ºä¸»ä»»åŠ¡æ–‡æ¡£
    if not main_doc.exists() or input.force:
        main_content = f"""---
status: DRAFT
taskKey: {input.taskKey}
title: {input.title}
owner: {input.owner}
reviewers: {input.reviewers}
updatedAt: {_timestamp()}
---

# ä»»åŠ¡æ¦‚è¿°
{input.title}

# è´£ä»»äºº
- è´Ÿè´£äººï¼š{input.owner}
- å®¡æ ¸äººï¼š{", ".join(input.reviewers)}

# çŠ¶æ€æœº
DRAFT â†’ PENDING_REVIEW â†’ (APPROVED | CHANGES_REQUESTED) â†’ PUBLISHED

# è¿‡ç¨‹æ–‡æ¡£
- ä¸Šä¸‹æ–‡ï¼š01-Context.md
- è®¾è®¡ï¼š02-Design.md  
- ä»£ç è®¡åˆ’ï¼š03-CodePlan.md
- æµ‹è¯•ç”¨ä¾‹ï¼š04-TestCurls.md
- MySQLéªŒè¯ï¼š05-MySQLVerificationPlan.md
- é›†æˆæ–‡æ¡£ï¼š06-Integration.md
- Jiraå‘å¸ƒï¼š07-JiraPublishPlan.md
"""
        main_doc.write_text(main_content, encoding="utf-8")
    
    # åˆ›å»ºè¿‡ç¨‹æ–‡æ¡£éª¨æ¶
    process_docs = [
        ("01-Context.md", "èƒŒæ™¯ä¸ç›®æ ‡"),
        ("02-Design.md", "è®¾è®¡æ–¹æ¡ˆ"),
        ("03-CodePlan.md", "ä»£ç ç”Ÿæˆè®¡åˆ’"),
        ("04-TestCurls.md", "æµ‹è¯•ç”¨ä¾‹"),
        ("05-MySQLVerificationPlan.md", "MySQLéªŒè¯è®¡åˆ’"),
        ("06-Integration.md", "é›†æˆæ–‡æ¡£"),
        ("07-JiraPublishPlan.md", "Jiraå‘å¸ƒè®¡åˆ’")
    ]
    
    for doc_name, doc_title in process_docs:
        doc_path = process_dir / f"{input.taskKey}_{doc_name}"
        if not doc_path.exists() or input.force:
            doc_content = f"""---
status: DRAFT
updatedAt: {_timestamp()}
---

# {doc_title}

å¾…è¡¥å……å†…å®¹...
"""
            doc_path.write_text(doc_content, encoding="utf-8")
    
    return PrepareDocsOutput(
        taskKey=input.taskKey,
        mainDocPath=str(main_doc),
        mainDocPathRelative=_relpath(main_doc, project_root),
        processDir=str(process_dir),
        processDirRelative=_relpath(process_dir, project_root),
        status="DRAFT",
    )


@app.tool()
def task_request_code_generation(input: CodeGenInput) -> CodeGenOutput:
    """ç”Ÿæˆé¢å‘ AI çš„ä»£ç ç¼–å†™è®¡åˆ’æ–‡æ¡£ï¼ŒåŒ…å«è¯¦ç»†çš„å®ç°æŒ‡å¯¼ã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    code_doc = dirs["process_dir"] / f"{input.taskKey}_03-CodePlan.md"
    
    # ç”Ÿæˆè¯¦ç»†çš„ä»£ç è®¡åˆ’æ–‡æ¡£
    code_content = f"""---
status: DRAFT
updatedAt: {_timestamp()}
---

# ä»£ç ç”Ÿæˆè®¡åˆ’ï¼ˆé¢å‘ AIï¼‰

## éœ€æ±‚æè¿°
{input.requirements}

## ç›®æ ‡æ¨¡å—
{chr(10).join(f"- {module}" for module in input.targetModules)}

## å®ç°çº¦æŸ
{chr(10).join(f"- {constraint}" for constraint in input.constraints)}

## éªŒæ”¶æ ‡å‡†
{chr(10).join(f"- {criteria}" for criteria in input.acceptanceCriteria)}

## å¼€å‘æŒ‡å¯¼

### æ¶æ„è¦æ±‚
- è¯­è¨€ï¼šPython 3.10+
- æ¡†æ¶ï¼šFastMCP
- æ¨¡å—ç»“æ„ï¼šéµå¾ªç°æœ‰ devflow_mcp åŒ…ç»“æ„

### å®ç°æ­¥éª¤
1. **æ¨¡å‹å®šä¹‰**ï¼šå®šä¹‰è¾“å…¥è¾“å‡º Pydantic æ¨¡å‹
2. **å·¥å…·å‡½æ•°**ï¼šå®ç°æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
3. **æ–‡æ¡£ç”Ÿæˆ**ï¼šç”Ÿæˆå®é™…æ–‡æ¡£å†…å®¹ï¼Œéä»…è·¯å¾„
4. **çŠ¶æ€ç®¡ç†**ï¼šå®ç°çŠ¶æ€æµè½¬å’Œæƒé™æ§åˆ¶
5. **é”™è¯¯å¤„ç†**ï¼šæ·»åŠ å®Œå–„çš„å¼‚å¸¸å¤„ç†

### è´¨é‡è¦æ±‚
- æ‰€æœ‰å‡½æ•°å¿…é¡»æœ‰å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
- è¾“å…¥å‚æ•°å¿…é¡»è¿›è¡ŒéªŒè¯
- é”™è¯¯ä¿¡æ¯å¿…é¡»ç”¨æˆ·å‹å¥½
- æ”¯æŒç›¸å¯¹å’Œç»å¯¹è·¯å¾„

## AI æ‰§è¡Œæ¸…å•
- [ ] è¡¥å…¨å·¥å…·å®ç°é€»è¾‘
- [ ] ç”Ÿæˆå®é™…æ–‡æ¡£å†…å®¹
- [ ] æ·»åŠ è¾“å…¥éªŒè¯
- [ ] å®Œå–„é”™è¯¯å¤„ç†
- [ ] æ›´æ–°çŠ¶æ€ä¸º PENDING_REVIEW
"""
    
    code_doc.write_text(code_content, encoding="utf-8")
    
    return CodeGenOutput(
        codePlanDoc=str(code_doc),
        codePlanDocRelative=_relpath(code_doc, project_root),
        statusHint="Document created, ready for PENDING_REVIEW",
    )


@app.tool()
def test_generate_curl_calls(input: CurlGenInput) -> CurlGenOutput:
    """ç”Ÿæˆå¯æ‰§è¡Œçš„ curl æµ‹è¯•æ–‡æ¡£è·¯å¾„ä¸ç‰‡æ®µåˆ—è¡¨ï¼Œè¦†ç›–æ­£/åç”¨ä¾‹ï¼ˆè¿”å›è®¡åˆ’ï¼‰ã€‚
    
    âš ï¸ å‰ç½®æ¡ä»¶ï¼šä»»åŠ¡çŠ¶æ€å¿…é¡» >= APPROVEDã€‚
    ğŸ‘¤ AI æé†’ï¼šè°ƒç”¨å‰è¯·å…ˆç¡®è®¤ä»»åŠ¡çš„çŠ¶æ€æ˜¯å¦å·²é€šè¿‡äººå·¥å®¡æ ¸(APPROVED)ã€‚
    å¦‚å½“å‰çŠ¶æ€ä¸º DRAFT/PENDING_REVIEWï¼Œè¯·å…ˆä¸ç”¨æˆ·ç¡®è®¤æ˜¯å¦éœ€è¦ï¼š
    1. ä½¿ç”¨ review_set_status å°†çŠ¶æ€æ”¹ä¸º APPROVEDï¼Œæˆ–
    2. ç”¨æˆ·æ‰‹åŠ¨å®¡æ ¸é€šè¿‡åå†è°ƒç”¨æ­¤å·¥å…·
    
    æ”¯æŒä¸¤ç§æ¥æºï¼š
    - ç›´æ¥ä¼ å…¥ endpointsï¼ˆmethod/path/...ï¼‰
    - é€šè¿‡ openapiUrl/openapiPath è§£æ OpenAPIï¼Œè‡ªåŠ¨æå– endpoints
    """
    project_root = _resolve_project_root(input.projectRoot)
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    doc_path = dirs["process_dir"] / f"{input.taskKey}_04-TestCurls.md"

    def _load_openapi() -> Optional[Dict[str, Any]]:
        spec_text: Optional[str] = None
        if input.openapiUrl:
            resp = requests.get(input.openapiUrl, timeout=30)
            if resp.status_code >= 400:
                raise ValueError(f"OpenAPI url fetch failed: {resp.status_code}")
            spec_text = resp.text
        elif input.openapiPath:
            p = Path(input.openapiPath)
            if not p.is_absolute():
                p = (PROJECT_ROOT / p).resolve()
            if not p.is_file():
                raise ValueError(f"OpenAPI file not found: {p}")
            spec_text = p.read_text(encoding="utf-8")
        if not spec_text:
            return None
        try:
            return json.loads(spec_text)
        except Exception:
            return yaml.safe_load(spec_text)

    def _extract_endpoints_from_openapi(spec: Dict[str, Any]) -> tuple[List[Dict[str, Any]], Optional[str]]:
        endpoints: List[Dict[str, Any]] = []
        derived_base: Optional[str] = None
        # derive baseUrl from servers (OpenAPI v3)
        servers = spec.get("servers")
        if isinstance(servers, list) and servers:
            srv = servers[0]
            if isinstance(srv, dict):
                derived_base = srv.get("url")
        # paths
        paths = spec.get("paths", {})
        for path, ops in paths.items():
            if not isinstance(ops, dict):
                continue
            for method in ["get", "post", "put", "delete", "patch", "head", "options"]:
                if method in ops:
                    op = ops[method]
                    desc = op.get("summary") or op.get("operationId") or ""
                    endpoints.append({
                        "method": method.upper(),
                        "path": path,
                        "description": desc,
                    })
                    if len(endpoints) >= max(1, input.maxEndpoints):
                        return endpoints, derived_base
        return endpoints, derived_base

    # é—¨ç¦ï¼šåªæœ‰åœ¨ APPROVED ä¹‹åæ‰å…è®¸ç”Ÿæˆ curl
    _require_min_status(project_root, input.taskKey, "APPROVED")

    endpoints = list(input.endpoints or [])
    derived_base = None
    if not endpoints:
        spec = _load_openapi()
        if spec:
            endpoints, derived_base = _extract_endpoints_from_openapi(spec)
    if not endpoints:
        raise ValueError("éœ€è¦æä¾› endpoints æˆ– openapiUrl/openapiPath ä»¥ç”Ÿæˆ curl ç”¨ä¾‹")

    base_url = input.baseUrl or derived_base or ""
    snippets: List[str] = []
    default_auth_mode = input.authMode or 'none'
    default_header_name = input.headerName or 'accessToken'
    default_query_name = input.queryParamName or 'accessToken'
    token_shell = f"${input.tokenEnvVar}" if input.tokenEnvVar else "$API_TOKEN"
    for ep in endpoints:
        method = (ep.get("method") or "GET").upper()
        path = ep.get("path") or "/"
        headers = ep.get("headers") or {}
        payload = ep.get("samplePayload")
        # è®¡ç®—é‰´æƒç­–ç•¥ï¼ˆç«¯ç‚¹å¯è¦†ç›–å…¨å±€ï¼‰
        auth_mode = (ep.get("authMode") or default_auth_mode) if isinstance(ep, dict) else default_auth_mode
        header_name = ep.get("headerName") if isinstance(ep, dict) else None
        query_name = ep.get("queryParamName") if isinstance(ep, dict) else None
        eff_header_name = header_name or default_header_name
        eff_query_name = query_name or default_query_name
        parts = ["curl -sS -X", method]
        # æ³¨å…¥é‰´æƒ
        if auth_mode == 'authorization_bearer':
            headers = {**headers, "Authorization": f"Bearer {token_shell}"}
        elif auth_mode == 'header_token':
            headers = {**headers, eff_header_name: token_shell}
        # å†™å…¥å¤´éƒ¨
        for k, v in headers.items():
            parts += ["-H", f"\"{k}: {v}\""]
        # æ„é€  URL å¹¶æ³¨å…¥ query tokenï¼ˆå¦‚éœ€è¦ï¼‰
        url = (base_url.rstrip("/") + path) if base_url else path
        if auth_mode == 'query_token':
            sep = '&' if ('?' in url) else '?'
            url = f"{url}{sep}{eff_query_name}={token_shell}"
        if payload is not None:
            parts += ["-H", "\"Content-Type: application/json\"", "--data", json.dumps(payload)]
        parts += [f"\"{url}\""]
        snippets.append(" ".join(parts))

    # å°†ç”Ÿæˆçš„ curl ç”¨ä¾‹å†™å…¥æ–‡æ¡£æ–‡ä»¶
    try:
        doc_path.parent.mkdir(parents=True, exist_ok=True)
        lines: List[str] = []
        lines.append("---")
        lines.append("status: DRAFT")
        lines.append(f"generatedAt: {_timestamp()}")
        if base_url:
            lines.append(f"baseUrl: {base_url}")
        lines.append("---\n")
        lines.append("## è¿è¡Œå‰")
        lines.append(f"- å¯¼å‡ºä»¤ç‰Œ: export {input.tokenEnvVar or 'API_TOKEN'}=\"<token>\"\n")
        lines.append("## ç”¨ä¾‹")
        for idx, snip in enumerate(snippets, start=1):
            lines.append(f"\n### ç”¨ä¾‹ {idx}")
            lines.append("```bash")
            lines.append(snip)
            lines.append("```")
        content = "\n".join(lines) + "\n"
        doc_path.write_text(content, encoding="utf-8")
    except Exception:
        # å†™å…¥å¤±è´¥ä¸é˜»å¡è¿”å›
        pass

    return CurlGenOutput(curlDoc=str(doc_path), curlDocRelative=_relpath(doc_path, project_root), snippets=snippets)


@app.tool()
def verify_plan_with_mysql_mcp(input: MySQLPlanInput) -> MySQLPlanOutput:
    """ç”Ÿæˆå¹¶æ‰§è¡Œ MySQL éªŒè¯è®¡åˆ’ï¼ˆå‰ç½®/æ–­è¨€/æ¸…ç†ï¼‰ï¼Œç›´æ¥è¿”å›æ‰§è¡Œç»“æœã€‚
    
    âš ï¸ å‰ç½®æ¡ä»¶ï¼šä»»åŠ¡çŠ¶æ€å¿…é¡» >= APPROVEDã€‚
    ğŸ‘¤ AI æé†’ï¼šè°ƒç”¨å‰è¯·å…ˆç¡®è®¤ä»»åŠ¡çš„çŠ¶æ€æ˜¯å¦å·²é€šè¿‡äººå·¥å®¡æ ¸(APPROVED)ã€‚
    å¦‚å½“å‰çŠ¶æ€ä¸æ»¡è¶³ï¼Œè¯·ä¸»åŠ¨ä¸ç”¨æˆ·ç¡®è®¤æ˜¯å¦éœ€è¦å…ˆè¿›è¡ŒçŠ¶æ€æµè½¬ã€‚
    """
    project_root = _resolve_project_root(input.projectRoot)
    # é—¨ç¦ï¼šè¦æ±‚ APPROVED
    _require_min_status(project_root, input.taskKey, "APPROVED")
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    doc_path = dirs["process_dir"] / f"{input.taskKey}_05-MySQLVerificationPlan.md"
    
    plan = {
        "preconditions": input.preconditions,
        "assertions": input.assertions,
        "cleanup": input.cleanup,
        "execution_order": ["preconditions", "assertions", "cleanup"],
    }
    
    # æ‰§è¡ŒMySQLéªŒè¯è®¡åˆ’
    execution_results = []
    executed = False
    
    try:
        # æŒ‰é¡ºåºæ‰§è¡Œï¼šå‰ç½®æ¡ä»¶ -> æ–­è¨€ -> æ¸…ç†
        all_statements = []
        
        # 1. æ‰§è¡Œå‰ç½®æ¡ä»¶
        if input.preconditions:
            all_statements.extend(input.preconditions)
        
        # 2. æ‰§è¡Œæ–­è¨€ï¼ˆè½¬æ¢ä¸ºSQLæŸ¥è¯¢ï¼‰
        if input.assertions:
            for assertion in input.assertions:
                if isinstance(assertion, dict) and 'sql' in assertion:
                    all_statements.append(assertion['sql'])
                elif isinstance(assertion, str):
                    all_statements.append(assertion)
        
        # 3. æ‰§è¡Œæ¸…ç†è¯­å¥
        if input.cleanup:
            all_statements.extend(input.cleanup)
        
        if all_statements:
            # ç›´æ¥ä½¿ç”¨å†…ç½®çš„MySQLæ‰§è¡ŒåŠŸèƒ½
            mysql_result = mysql_execute_statements(MySQLExecuteInput(
                taskKey=input.taskKey,
                statements=all_statements,
                continueOnError=True
            ))
            execution_results = mysql_result.results
            executed = True
            
    except Exception as e:
        # å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­ç”Ÿæˆæ–‡æ¡£
        execution_results = [MySQLStatementResult(
            sql="EXECUTION_ERROR",
            success=False,
            error=str(e)
        )]
    
    # ç”ŸæˆéªŒè¯è®¡åˆ’æ–‡æ¡£
    doc_content = f"""---
status: {"EXECUTED" if executed else "DRAFT"}
updatedAt: {_timestamp()}
executed: {executed}
---

# MySQL éªŒè¯è®¡åˆ’

## éªŒè¯ç›®æ ‡
éªŒè¯ä»»åŠ¡ {input.taskKey} çš„æ•°æ®åº“ç›¸å…³åŠŸèƒ½

## æ¶‰åŠè¡¨
{chr(10).join(f"- {table}" for table in input.tables)}

## æ‰§è¡Œè®¡åˆ’

### 1. å‰ç½®æ¡ä»¶
```sql
{chr(10).join(input.preconditions)}
```

### 2. æ–­è¨€æ£€æŸ¥
{chr(10).join(f"- {assertion.get('description', str(assertion)) if isinstance(assertion, dict) else assertion}" for assertion in input.assertions)}

### 3. æ¸…ç†æ“ä½œ
```sql
{chr(10).join(input.cleanup)}
```

## æ‰§è¡Œç»“æœ
{'âœ… å·²æ‰§è¡Œ' if executed else 'âŒ æœªæ‰§è¡Œ'}

{chr(10).join(f"**{i+1}.** {result.sql} - {'âœ… æˆåŠŸ' if result.success else 'âŒ å¤±è´¥: ' + (result.error or '')}" for i, result in enumerate(execution_results)) if execution_results else 'æ— æ‰§è¡Œè®°å½•'}
"""
    
    doc_path.write_text(doc_content, encoding="utf-8")
    
    return MySQLPlanOutput(
        verificationPlanDoc=str(doc_path),
        verificationPlanDocRelative=_relpath(doc_path, project_root),
        sqlPlan=plan,
        executionResults=execution_results,
        executed=executed
    )


@app.tool()
def docs_generate_integration(input: IntegrationDocInput) -> IntegrationDocOutput:
    """ç”Ÿæˆå®Œæ•´çš„é›†æˆå¯¹æ¥æ–‡æ¡£ï¼ŒåŒ…å«æ¦‚è§ˆã€é‰´æƒã€æ¥å£ã€Schemaã€é”™è¯¯ç å’Œæ ·ä¾‹ã€‚
    
    âš ï¸ å‰ç½®æ¡ä»¶ï¼šä»»åŠ¡çŠ¶æ€å¿…é¡» >= APPROVEDã€‚
    ğŸ‘¤ AI æé†’ï¼šè°ƒç”¨å‰è¯·å…ˆç¡®è®¤ä»»åŠ¡çš„çŠ¶æ€æ˜¯å¦å·²é€šè¿‡äººå·¥å®¡æ ¸(APPROVED)ã€‚
    å¦‚å½“å‰çŠ¶æ€ä¸æ»¡è¶³ï¼Œè¯·ä¸»åŠ¨ä¸ç”¨æˆ·ç¡®è®¤æ˜¯å¦éœ€è¦å…ˆè¿›è¡ŒçŠ¶æ€æµè½¬ã€‚
    """
    project_root = _resolve_project_root(input.projectRoot)
    # é—¨ç¦ï¼šè¦æ±‚ APPROVED
    _require_min_status(project_root, input.taskKey, "APPROVED")
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    doc_path = dirs["process_dir"] / f"{input.taskKey}_06-Integration.md"
    
    # ç”Ÿæˆå®Œæ•´çš„é›†æˆæ–‡æ¡£å†…å®¹
    doc_content = f"""---
status: DRAFT
updatedAt: {_timestamp()}
audience: {input.audience}
---

# é›†æˆå¯¹æ¥æ–‡æ¡£ - {input.taskKey}

## 1. æ¦‚è§ˆ (Overview)

### ç³»ç»Ÿç®€ä»‹
ä»»åŠ¡ {input.taskKey} çš„ç³»ç»Ÿé›†æˆæ–‡æ¡£ï¼Œé¢å‘ {input.audience} ç”¨æˆ·ã€‚

### æ¶‰åŠç³»ç»Ÿ
{chr(10).join(f"- {system}" for system in input.systems)}

## 2. é‰´æƒ (Authentication)

### é‰´æƒæ–¹å¼
- **ç±»å‹**: Bearer Token / API Key
- **è¯·æ±‚å¤´**: `Authorization: Bearer <token>`
- **è·å–æ–¹å¼**: è”ç³»ç³»ç»Ÿç®¡ç†å‘˜

### ç¤ºä¾‹
```bash
curl -H "Authorization: Bearer your-api-token" \\
     https://api.example.com/endpoint
```

## 3. æ¥å£ (Endpoints)

{chr(10).join(f'''### {interface.get("name", "Unknown")}
**æ–¹æ³•**: {interface.get("method", "GET")}  
**è·¯å¾„**: {interface.get("path", "/")}  
**æè¿°**: {interface.get("description", "æš‚æ— æè¿°")}

**è¯·æ±‚ç¤ºä¾‹**:
```json
{{"example": "request"}}
```

**å“åº”ç¤ºä¾‹**:
```json
{{"status": "success", "data": {{}}}}
```
''' for interface in input.interfaces)}

## 4. æ•°æ®ç»“æ„ (Schemas)

### é€šç”¨å“åº”æ ¼å¼
```json
{{
  "status": "success|error",
  "message": "æ“ä½œç»“æœæè¿°",
  "data": {{}},
  "timestamp": "2024-01-01T00:00:00Z"
}}
```

### ä¸šåŠ¡æ•°æ®ç»“æ„
```json
{{
  "id": "string",
  "name": "string", 
  "status": "active|inactive",
  "createdAt": "2024-01-01T00:00:00Z",
  "updatedAt": "2024-01-01T00:00:00Z"
}}
```

## 5. é”™è¯¯ç  (Error Codes)

| é”™è¯¯ç  | æè¿° | è§£å†³æ–¹æ¡ˆ |
|--------|------|----------|
| 400 | è¯·æ±‚å‚æ•°é”™è¯¯ | æ£€æŸ¥è¯·æ±‚å‚æ•°æ ¼å¼å’Œå¿…å¡«å­—æ®µ |
| 401 | æœªæˆæƒ | æ£€æŸ¥ API Token æ˜¯å¦æ­£ç¡® |
| 403 | ç¦æ­¢è®¿é—® | æ£€æŸ¥è´¦å·æƒé™ |
| 404 | èµ„æºä¸å­˜åœ¨ | æ£€æŸ¥è¯·æ±‚çš„èµ„æºIDæ˜¯å¦æ­£ç¡® |
| 500 | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ | è”ç³»æŠ€æœ¯æ”¯æŒ |

## 6. é›†æˆæ ·ä¾‹ (Samples)

### Python ç¤ºä¾‹
```python
import requests

def call_api(endpoint, data=None):
    headers = {{
        'Authorization': 'Bearer your-api-token',
        'Content-Type': 'application/json'
    }}
    
    response = requests.post(
        f'https://api.example.com{{endpoint}}',
        headers=headers,
        json=data
    )
    
    return response.json()

# ä½¿ç”¨ç¤ºä¾‹
result = call_api('/api/v1/resource', {{'name': 'test'}})
print(result)
```

### curl ç¤ºä¾‹
```bash
# GET è¯·æ±‚
curl -H "Authorization: Bearer your-api-token" \\
     https://api.example.com/api/v1/resource

# POST è¯·æ±‚  
curl -X POST \\
     -H "Authorization: Bearer your-api-token" \\
     -H "Content-Type: application/json" \\
     -d '{{"name": "test"}}' \\
     https://api.example.com/api/v1/resource
```

## 7. æŠ€æœ¯æ”¯æŒ

### è”ç³»æ–¹å¼
- **æŠ€æœ¯æ”¯æŒ**: tech-support@example.com
- **æ–‡æ¡£é—®é¢˜**: docs@example.com
- **ç´§æ€¥è”ç³»**: emergency@example.com

### æ›´æ–°æ—¥å¿—
- {_timestamp()[:10]}: åˆå§‹ç‰ˆæœ¬åˆ›å»º

## 8. è¡¥å……è¯´æ˜
{input.notes or "æš‚æ— è¡¥å……è¯´æ˜"}
"""
    
    doc_path.write_text(doc_content, encoding="utf-8")
    toc = ["Overview", "Authentication", "Endpoints", "Schemas", "Error Codes", "Samples", "Support", "Notes"]
    
    return IntegrationDocOutput(
        integrationDoc=str(doc_path), 
        integrationDocRelative=_relpath(doc_path, project_root), 
        toc=toc
    )


@app.tool()
def jira_publish_integration_doc(input: JiraPublishInput) -> JiraPublishOutput:
    """ç›´æ¥åˆ›å»º Jira å·¥å•å¹¶ä¸Šä¼ é™„ä»¶ï¼Œè¿”å›å®Œæ•´çš„æ‰§è¡Œç»“æœã€‚
    
    âš ï¸ å‰ç½®æ¡ä»¶ï¼šä»»åŠ¡çŠ¶æ€å¿…é¡» >= APPROVED ä¸”ç›¸å…³æ–‡æ¡£å·²ç”Ÿæˆã€‚
    ğŸ‘¤ AI æé†’ï¼šè°ƒç”¨å‰è¯·å…ˆç¡®è®¤ï¼š
    1. ä»»åŠ¡çš„çŠ¶æ€æ˜¯å¦å·²é€šè¿‡äººå·¥å®¡æ ¸(APPROVED)
    2. å¯¹æ¥æ–‡æ¡£ç­‰é™„ä»¶æ˜¯å¦å·²ç”Ÿæˆå®Œæˆ
    å¦‚æ¡ä»¶ä¸æ»¡è¶³ï¼Œè¯·ä¸»åŠ¨ä¸ç”¨æˆ·ç¡®è®¤åç»­æ­¥éª¤ã€‚
    
    ğŸ”„ è‡ªåŠ¨æ£€æµ‹ï¼šæ”¯æŒä»å½“å‰Gitåˆ†æ”¯è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Keyå’Œç›¸å…³ticketä¿¡æ¯
    """
    project_root = _resolve_project_root(input.projectRoot)
    # é—¨ç¦ï¼šè¦æ±‚æ‰€æœ‰æ£€æŸ¥é€šè¿‡ä¸”çŠ¶æ€ APPROVED
    _require_min_status(project_root, input.taskKey, "APPROVED")
    dirs = _ensure_dirs_for(project_root, input.taskKey)
    doc_path = dirs["process_dir"] / f"{input.taskKey}_07-JiraPublishPlan.md"
    
    # è‡ªåŠ¨æ£€æµ‹Gitåˆ†æ”¯ä¿¡æ¯
    git_context = _auto_detect_jira_context()
    detected_project_key = input.projectKey
    
    if input.autoDetectFromBranch and not detected_project_key:
        detected_project_key = git_context.get("project_key")
        if not detected_project_key:
            raise ValueError(f"æ— æ³•ä»å½“å‰åˆ†æ”¯ '{git_context.get('branch_name', 'unknown')}' è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Keyï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š projectKey å‚æ•°")
    
    if not detected_project_key:
        raise ValueError("å¿…é¡»æŒ‡å®š projectKey æˆ–å¯ç”¨ autoDetectFromBranch è‡ªåŠ¨æ£€æµ‹")
    
    payload = {
        "fields": {
            "project": {"key": detected_project_key},
            "issuetype": {"name": input.issueType},
            "summary": input.summary,
            "description": input.description,
            "labels": input.labels,
        },
        "attachments": input.attachments,
        "links": input.links,
        "git_context": git_context,  # è®°å½•æ£€æµ‹åˆ°çš„Gitä¸Šä¸‹æ–‡
    }
    
    # ç›´æ¥æ‰§è¡ŒJiraå·¥å•åˆ›å»º
    created_issue = None
    attachment_results = None
    executed = False
    
    try:
        # 1. åˆ›å»ºJiraå·¥å•
        created_issue = jira_create_issue(JiraCreateIssueInput(
            projectKey=detected_project_key,
            issueType=input.issueType,
            summary=input.summary,
            description=input.description,
            labels=input.labels,
            fields={}
        ))
        
        if created_issue and created_issue.issueKey:
            executed = True
            
            # 2. ä¸Šä¼ é™„ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
            if input.attachments:
                attachment_results = jira_attach_files(JiraAttachFilesInput(
                    issueKey=created_issue.issueKey,
                    filePaths=input.attachments
                ))
            
            # 3. å…³è”å·¥å•ï¼ˆå¦‚æœæœ‰ï¼‰
            if input.links:
                for link in input.links:
                    if isinstance(link, dict) and 'issueKey' in link and 'linkType' in link:
                        jira_link_issues(JiraLinkIssuesInput(
                            inwardIssue=created_issue.issueKey,
                            outwardIssue=link['issueKey'],
                            linkType=link.get('linkType', 'relates to')
                        ))
                        
    except Exception as e:
        # å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­ç”Ÿæˆæ–‡æ¡£
        executed = False
        created_issue = JiraCreateIssueOutput(
            issueKey=None,
            url=None,
            hint=f"Failed to create issue: {str(e)}"
        )
    
    # ç”Ÿæˆæ‰§è¡Œè®¡åˆ’æ–‡æ¡£
    doc_content = f"""---
status: {"PUBLISHED" if executed else "DRAFT"}
updatedAt: {_timestamp()}
executed: {executed}
---

# Jira å‘å¸ƒè®¡åˆ’ - {input.taskKey}

## æ‰§è¡ŒçŠ¶æ€
{'âœ… å·²æ‰§è¡Œ' if executed else 'âŒ æ‰§è¡Œå¤±è´¥'}

## å·¥å•ä¿¡æ¯
- **é¡¹ç›®**: {detected_project_key}
- **ç±»å‹**: {input.issueType}  
- **æ ‡é¢˜**: {input.summary}
- **åˆ›å»ºç»“æœ**: {'æˆåŠŸ - ' + (created_issue.issueKey or 'N/A') if created_issue and created_issue.issueKey else 'å¤±è´¥'}
- **å·¥å•é“¾æ¥**: {created_issue.url if created_issue and created_issue.url else 'æ— '}

## Gitä¸Šä¸‹æ–‡ä¿¡æ¯
- **å½“å‰åˆ†æ”¯**: {git_context.get('branch_name', 'unknown')}
- **æ£€æµ‹åˆ°çš„Ticket**: {git_context.get('ticket_key', 'æ— ')}
- **è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Key**: {git_context.get('project_key', 'æ— ')}
- **æ£€æµ‹æ¨¡å¼**: {'å¯ç”¨' if input.autoDetectFromBranch else 'ç¦ç”¨'}

## é™„ä»¶ä¸Šä¼ 
{f'- æˆåŠŸ: {len(attachment_results.attached if attachment_results else [])} ä¸ªæ–‡ä»¶' if attachment_results else '- æ— é™„ä»¶'}
{f'- å¤±è´¥: {len(attachment_results.failed if attachment_results else [])} ä¸ªæ–‡ä»¶' if attachment_results else ''}

## åŸå§‹ Payload
```json
{json.dumps(payload, indent=2, ensure_ascii=False)}
```

## æ‰§è¡Œæ—¥å¿—
- å·¥å•åˆ›å»º: {'âœ…' if created_issue and created_issue.issueKey else 'âŒ'}
- é™„ä»¶ä¸Šä¼ : {'âœ…' if attachment_results and not attachment_results.failed else 'âŒ' if attachment_results else 'N/A'}
- å·¥å•å…³è”: {'âœ…' if input.links else 'N/A'}

## åç»­æ­¥éª¤
{f'1. è®¿é—®å·¥å•: {created_issue.url}' if created_issue and created_issue.url else '1. å·¥å•åˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®'}
2. é€šçŸ¥ç›¸å…³äººå‘˜
3. è·Ÿè¸ªå·¥å•è¿›åº¦
"""
    
    doc_path.write_text(doc_content, encoding="utf-8")
    
    return JiraPublishOutput(
        jiraPlanDoc=str(doc_path),
        jiraPlanDocRelative=_relpath(doc_path, project_root),
        jiraPayload=payload,
        createdIssue=created_issue,
        attachmentResults=attachment_results,
        executed=executed
    )


@app.tool()
def review_set_status(input: ReviewStatusInput) -> ReviewStatusOutput:
    """åˆ‡æ¢ä¸»ä»»åŠ¡æ–‡æ¡£çŠ¶æ€ï¼ŒåŒ…å«çŠ¶æ€è½¬æ¢è·¯å¾„éªŒè¯å’Œå†å²è®°å½•ã€‚
    
    âš ï¸ çŠ¶æ€éªŒè¯ï¼š
    1. éªŒè¯çŠ¶æ€è½¬æ¢è·¯å¾„æ˜¯å¦åˆæ³•
    2. è®°å½•çŠ¶æ€å˜æ›´å†å²å’ŒåŸå› 
    3. æ”¯æŒäº‹åŠ¡æ€§çŠ¶æ€æ›´æ–°
    
    ğŸ‘¤ AI æé†’ï¼šçŠ¶æ€æµè½¬é€šå¸¸éœ€è¦äººå·¥å®¡æ ¸å†³ç­–ã€‚å»ºè®®è°ƒç”¨å‰ï¼š
    1. å‘ç”¨æˆ·è¯´æ˜å½“å‰çŠ¶æ€å’Œæ‹Ÿå˜æ›´çš„ç›®æ ‡çŠ¶æ€
    2. ç¡®è®¤å˜æ›´åŸå› å’Œåç»­å½±å“
    3. è·å¾—ç”¨æˆ·æ˜ç¡®åŒæ„åå†æ‰§è¡ŒçŠ¶æ€åˆ‡æ¢
    """
    project_root = _resolve_project_root(input.projectRoot)
    dirs = _ensure_dirs_for(project_root, None)
    main_doc = dirs["tasks_dir"] / f"{input.taskKey}.md"

    # è·å–å½“å‰çŠ¶æ€
    old_status = _read_task_status(project_root, input.taskKey)
    
    # 1. éªŒè¯çŠ¶æ€è½¬æ¢æ˜¯å¦åˆæ³•
    if not _validate_status_transition(old_status, input.newStatus):
        valid_transitions = _STATUS_TRANSITIONS.get(old_status, [])
        raise StatusValidationError(
            f"éæ³•çŠ¶æ€è½¬æ¢: {old_status} -> {input.newStatus}. "
            f"å…è®¸çš„è½¬æ¢: {valid_transitions}"
        )

    # 2. éªŒè¯å¿…éœ€çš„åŸå› è¯´æ˜ï¼ˆå¯¹æŸäº›å…³é”®è½¬æ¢ï¼‰
    critical_transitions = [
        ("PENDING_REVIEW", "CHANGES_REQUESTED"),
        ("APPROVED", "CHANGES_REQUESTED"), 
        ("APPROVED", "PUBLISHED")
    ]
    if (old_status, input.newStatus) in critical_transitions and not input.notes:
        raise StatusValidationError(
            f"å…³é”®çŠ¶æ€è½¬æ¢ {old_status} -> {input.newStatus} å¿…é¡»æä¾›åŸå› è¯´æ˜"
        )

    # è¯»å–æˆ–åˆ›å»º Front Matter
    if main_doc.exists():
        post = frontmatter.load(main_doc)
    else:
        post = frontmatter.Post("")

    metadata = dict(post.metadata or {})
    
    # 3. æ›´æ–°çŠ¶æ€å’Œæ—¶é—´æˆ³
    metadata["status"] = input.newStatus
    metadata["updatedAt"] = _timestamp()
    
    # 4. è®°å½•çŠ¶æ€å˜æ›´å†å²
    reviews = list(metadata.get("reviews", []))
    review_entry = {
        "by": input.by,
        "from": old_status,
        "to": input.newStatus,
        "notes": input.notes or "",
        "time": _timestamp(),
        "valid": True  # æ ‡è®°ä¸ºç»è¿‡éªŒè¯çš„è½¬æ¢
    }
    reviews.append(review_entry)
    metadata["reviews"] = reviews
    
    # 5. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    stats = metadata.get("statusStats", {})
    stats[input.newStatus] = stats.get(input.newStatus, 0) + 1
    stats["totalTransitions"] = stats.get("totalTransitions", 0) + 1
    metadata["statusStats"] = stats
    
    post.metadata = metadata

    # 6. è½ç›˜ä¿å­˜ï¼ˆåŒ…å«äº‹åŠ¡æ€§æ£€æŸ¥ï¼‰
    try:
        main_doc.parent.mkdir(parents=True, exist_ok=True)
        content_str = frontmatter.dumps(post)
        main_doc.write_text(content_str, encoding="utf-8")
        
        # éªŒè¯å†™å…¥æˆåŠŸ
        if _read_task_status(project_root, input.taskKey) != input.newStatus:
            raise StatusValidationError("çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œæ–‡ä»¶å†™å…¥å¼‚å¸¸")
            
    except Exception as e:
        raise StatusValidationError(f"çŠ¶æ€æ›´æ–°å¤±è´¥: {str(e)}")

    return ReviewStatusOutput(taskKey=input.taskKey, oldStatus=old_status, newStatus=input.newStatus)


@app.tool()
def review_validate_checklist(input: ReviewChecklistInput) -> ReviewChecklistOutput:
    """æ‰§è¡Œä¸€è‡´æ€§æ ¡éªŒï¼ˆæ–‡æ¡£å­˜åœ¨æ€§ã€çŠ¶æ€é—¨ç¦ã€é…ç½®å®Œæ•´æ€§ç­‰ï¼‰ï¼Œè¿”å›é€šè¿‡ä¸å¤±è´¥é¡¹ã€‚"""
    failed: List[Dict[str, str]] = []
    project_root = PROJECT_ROOT
    
    # å¯ç”¨çš„æ£€æŸ¥é¡¹
    available_checks = {
        "task_doc_exists": "æ£€æŸ¥ä¸»ä»»åŠ¡æ–‡æ¡£æ˜¯å¦å­˜åœ¨",
        "process_docs_exist": "æ£€æŸ¥è¿‡ç¨‹æ–‡æ¡£æ˜¯å¦å­˜åœ¨", 
        "status_valid": "æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æ˜¯å¦æœ‰æ•ˆ",
        "front_matter_valid": "æ£€æŸ¥ Front Matter æ ¼å¼",
        "mysql_config": "æ£€æŸ¥ MySQL é…ç½®",
        "jira_config": "æ£€æŸ¥ Jira é…ç½®",
        "file_permissions": "æ£€æŸ¥æ–‡ä»¶æƒé™",
        "directory_structure": "æ£€æŸ¥ç›®å½•ç»“æ„"
    }
    
    for check_id in input.checks:
        if check_id not in available_checks:
            failed.append({
                "check": check_id,
                "reason": f"æœªçŸ¥çš„æ£€æŸ¥é¡¹: {check_id}"
            })
            continue
            
        try:
            if check_id == "task_doc_exists":
                main_doc = project_root / "Docs" / ".tasks" / f"{input.taskKey}.md"
                if not main_doc.exists():
                    failed.append({
                        "check": check_id,
                        "reason": f"ä¸»ä»»åŠ¡æ–‡æ¡£ä¸å­˜åœ¨: {main_doc}"
                    })
                    
            elif check_id == "process_docs_exist":
                process_dir = project_root / "Docs" / "ProcessDocuments" / f"task-{input.taskKey}"
                if not process_dir.exists():
                    failed.append({
                        "check": check_id,
                        "reason": f"è¿‡ç¨‹æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {process_dir}"
                    })
                else:
                    required_docs = [
                        "01-Context.md", "02-Design.md", "03-CodePlan.md",
                        "04-TestCurls.md", "05-MySQLVerificationPlan.md", 
                        "06-Integration.md", "07-JiraPublishPlan.md"
                    ]
                    for doc in required_docs:
                        doc_path = process_dir / f"{input.taskKey}_{doc}"
                        if not doc_path.exists():
                            failed.append({
                                "check": check_id,
                                "reason": f"ç¼ºå¤±è¿‡ç¨‹æ–‡æ¡£: {doc_path.name}"
                            })
                            
            elif check_id == "status_valid":
                try:
                    current_status = _read_task_status(project_root, input.taskKey)
                    valid_statuses = ["DRAFT", "PENDING_REVIEW", "APPROVED", "CHANGES_REQUESTED", "PUBLISHED"]
                    if current_status not in valid_statuses:
                        failed.append({
                            "check": check_id,
                            "reason": f"æ— æ•ˆçŠ¶æ€: {current_status}"
                        })
                except Exception as e:
                    failed.append({
                        "check": check_id,
                        "reason": f"æ— æ³•è¯»å–çŠ¶æ€: {str(e)}"
                    })
                    
            elif check_id == "front_matter_valid":
                main_doc = project_root / "Docs" / ".tasks" / f"{input.taskKey}.md"
                if main_doc.exists():
                    try:
                        post = frontmatter.load(main_doc)
                        required_fields = ["status", "taskKey", "title", "owner"]
                        for field in required_fields:
                            if field not in post.metadata:
                                failed.append({
                                    "check": check_id,
                                    "reason": f"ç¼ºå¤± Front Matter å­—æ®µ: {field}"
                                })
                    except Exception as e:
                        failed.append({
                            "check": check_id,
                            "reason": f"Front Matter æ ¼å¼é”™è¯¯: {str(e)}"
                        })
                        
            elif check_id == "mysql_config":
                required_env = ["MYSQL_HOST", "MYSQL_USER", "MYSQL_PASSWORD", "MYSQL_DB"]
                missing_env = [env for env in required_env if not os.getenv(env)]
                if missing_env:
                    failed.append({
                        "check": check_id,
                        "reason": f"ç¼ºå¤± MySQL ç¯å¢ƒå˜é‡: {', '.join(missing_env)}"
                    })
                    
            elif check_id == "jira_config":
                base_url = os.getenv("JIRA_BASE_URL")
                user = os.getenv("JIRA_USER")
                password = os.getenv("JIRA_USER_PASSWORD")
                bearer = os.getenv("JIRA_BEARER_TOKEN")
                token = os.getenv("JIRA_API_TOKEN")
                
                if not base_url:
                    failed.append({
                        "check": check_id,
                        "reason": "ç¼ºå¤± JIRA_BASE_URL ç¯å¢ƒå˜é‡"
                    })
                    
                if not (user and password) and not bearer and not (user and token):
                    failed.append({
                        "check": check_id,
                        "reason": "ç¼ºå¤± Jira è®¤è¯é…ç½®ï¼ˆéœ€è¦ç”¨æˆ·åå¯†ç ã€Bearer Token æˆ– API Tokenï¼‰"
                    })
                    
            elif check_id == "directory_structure":
                required_dirs = [
                    project_root / "Docs",
                    project_root / "Docs" / ".tasks",
                    project_root / "Docs" / "ProcessDocuments"
                ]
                for dir_path in required_dirs:
                    if not dir_path.exists():
                        failed.append({
                            "check": check_id,
                            "reason": f"ç›®å½•ä¸å­˜åœ¨: {dir_path}"
                        })
                        
            elif check_id == "file_permissions":
                docs_dir = project_root / "Docs"
                if docs_dir.exists() and not os.access(docs_dir, os.W_OK):
                    failed.append({
                        "check": check_id,
                        "reason": f"æ²¡æœ‰å†™æƒé™: {docs_dir}"
                    })
                    
        except Exception as e:
            failed.append({
                "check": check_id,
                "reason": f"æ£€æŸ¥æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            })
    
    return ReviewChecklistOutput(passed=len(failed) == 0, failedItems=failed)


# ---------- External MCP Features (Integrated Implementations) ----------

# MySQL MCP parity: execute SQL statements sequentially
class MySQLExecuteInput(BaseModel):
    """ç›´æ¥æ‰§è¡Œ SQL è¯­å¥çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="MySQLExecuteInput", description="ç›´æ¥æ‰§è¡Œ SQL è¯­å¥çš„è¾“å…¥å‚æ•°")
    taskKey: Optional[str] = Field(None, description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†ï¼ˆå¯é€‰ï¼Œç”¨äºå®¡è®¡ï¼‰")
    statements: List[str] = Field(..., description="è¦é¡ºåºæ‰§è¡Œçš„ SQL åˆ—è¡¨")
    continueOnError: bool = Field(False, description="é‡åˆ°é”™è¯¯æ˜¯å¦ç»§ç»­æ‰§è¡Œåç»­è¯­å¥")


class MySQLExecuteOutput(BaseModel):
    results: List[MySQLStatementResult]
    hint: str


def _get_mysql_connection():
    host = os.getenv("MYSQL_HOST")
    user = os.getenv("MYSQL_USER")
    password = os.getenv("MYSQL_PASSWORD")
    database = os.getenv("MYSQL_DB")
    port = int(os.getenv("MYSQL_PORT", "3306"))
    charset = os.getenv("MYSQL_CHARSET", "utf8mb4")
    if not all([host, user, password, database]):
        missing = [n for n, v in [("MYSQL_HOST", host), ("MYSQL_USER", user), ("MYSQL_PASSWORD", password), ("MYSQL_DB", database)] if not v]
        raise ValueError(f"Missing MySQL env vars: {', '.join(missing)}")
    return pymysql.connect(host=host, port=port, user=user, password=password, database=database, charset=charset, cursorclass=pymysql.cursors.DictCursor, autocommit=True)


@app.tool()
def mysql_execute_statements(input: MySQLExecuteInput) -> MySQLExecuteOutput:
    """æ‰§è¡Œä¸€ç»„ SQL è¯­å¥ã€‚
    éœ€è¦ç¯å¢ƒå˜é‡ï¼šMYSQL_HOST, MYSQL_PORT(å¯é€‰), MYSQL_USER, MYSQL_PASSWORD, MYSQL_DB, MYSQL_CHARSET(å¯é€‰)
    """
    results: List[MySQLStatementResult] = []
    try:
        connection = _get_mysql_connection()
    except Exception as exc:  # pragma: no cover
        for sql in input.statements:
            results.append(MySQLStatementResult(sql=sql, success=False, error=f"ConnectionError: {exc}"))
        return MySQLExecuteOutput(results=results, hint="Ensure MySQL env vars are set and reachable")

    try:
        with connection.cursor() as cursor:
            for sql in input.statements:
                try:
                    is_select = sql.strip().lower().startswith("select")
                    cursor.execute(sql)
                    if is_select:
                        rows = cursor.fetchall()
                        results.append(MySQLStatementResult(sql=sql, success=True, rows=rows, rowsAffected=None))
                    else:
                        rows_affected = cursor.rowcount
                        results.append(MySQLStatementResult(sql=sql, success=True, rows=None, rowsAffected=rows_affected))
                except Exception as stmt_exc:  # pragma: no cover
                    results.append(MySQLStatementResult(sql=sql, success=False, error=str(stmt_exc)))
                    if not input.continueOnError:
                        break
    finally:
        try:
            connection.close()
        except Exception:
            pass

    return MySQLExecuteOutput(results=results, hint="Executed using direct MySQL connection from devflow-mcp")


# Jira MCP parity: create issue, attach files, link issues
class JiraCreateIssueInput(BaseModel):
    """åœ¨ Jira ä¸­åˆ›å»ºå·¥å•çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraCreateIssueInput", description="åœ¨ Jira ä¸­åˆ›å»ºå·¥å•çš„è¾“å…¥å‚æ•°")
    projectKey: Optional[str] = Field(None, description="Jira é¡¹ç›® Keyï¼ˆå¯é€‰ï¼Œä¸ºç©ºæ—¶è‡ªåŠ¨ä»Gitåˆ†æ”¯è§£æï¼‰")
    issueType: str = Field(..., description="å·¥å•ç±»å‹ï¼Œå¦‚ Task/Story/Documentation")
    summary: str = Field(..., description="å·¥å•æ ‡é¢˜")
    description: str = Field(..., description="å·¥å•æè¿°")
    labels: List[str] = Field(default_factory=list, description="æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")
    fields: Dict[str, Any] = Field(default_factory=dict, description="é¢å¤–è‡ªå®šä¹‰å­—æ®µï¼ˆå¯é€‰ï¼‰")
    autoDetectFromBranch: bool = Field(True, description="æ˜¯å¦è‡ªåŠ¨ä»Gitåˆ†æ”¯æ£€æµ‹é¡¹ç›®ä¿¡æ¯ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")


def _get_jira_session() -> Session:
    base_url = os.getenv("JIRA_BASE_URL")
    user = os.getenv("JIRA_USER")
    password = os.getenv("JIRA_USER_PASSWORD")
    token = os.getenv("JIRA_API_TOKEN")  # å…¼å®¹æ—§é…ç½®
    bearer = os.getenv("JIRA_BEARER_TOKEN")
    if not base_url:
        raise ValueError("Missing env: JIRA_BASE_URL")
    session = requests.Session()
    session.headers.update({"Accept": "application/json"})
    # ä¼˜å…ˆé¡ºåºï¼šç”¨æˆ·+å¯†ç  > Bearer > ç”¨æˆ·+API Tokenï¼ˆå…¼å®¹ï¼‰
    if user and password:
        session.auth = (user, password)
    elif bearer:
        session.headers.update({"Authorization": f"Bearer {bearer}"})
    elif user and token:
        session.auth = (user, token)
    else:
        raise ValueError("Missing Jira auth: set JIRA_USER + JIRA_USER_PASSWORD (preferred), or JIRA_BEARER_TOKEN, or JIRA_USER + JIRA_API_TOKEN")
    return session


def _jira_api_url(path: str) -> str:
    base_url = os.getenv("JIRA_BASE_URL", "").rstrip("/")
    # æ”¯æŒ context pathï¼Œä¾‹å¦‚ /jiraï¼Œå‚è€ƒ Jira Server 7.x REST ç»“æ„
    context_path = os.getenv("JIRA_CONTEXT_PATH", "").strip()
    if context_path and not context_path.startswith("/"):
        context_path = "/" + context_path
    # Jira Server 7.x é»˜è®¤ä½¿ç”¨ REST v2ã€‚å¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ã€‚
    api_version = os.getenv("JIRA_API_VERSION", "2")
    return f"{base_url}{context_path}/rest/api/{api_version}/{path.lstrip('/')}"


@app.tool()
def jira_create_issue(input: JiraCreateIssueInput) -> JiraCreateIssueOutput:
    """åœ¨ Jira ä¸­åˆ›å»ºå·¥å•ï¼ˆREST v3ï¼Œæ”¯æŒè‡ªå®šä¹‰å­—æ®µï¼‰ã€‚è®¤è¯ä¼˜å…ˆ JIRA_USER/JIRA_USER_PASSWORDã€‚æ”¯æŒä»Gitåˆ†æ”¯è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Keyã€‚"""
    try:
        # è‡ªåŠ¨æ£€æµ‹Gitåˆ†æ”¯ä¿¡æ¯
        detected_project_key = input.projectKey
        if input.autoDetectFromBranch and not detected_project_key:
            git_context = _auto_detect_jira_context()
            detected_project_key = git_context.get("project_key")
            if not detected_project_key:
                return JiraCreateIssueOutput(
                    issueKey=None, 
                    url=None, 
                    hint=f"æ— æ³•ä»å½“å‰åˆ†æ”¯ '{git_context.get('branch_name', 'unknown')}' è‡ªåŠ¨æ£€æµ‹é¡¹ç›®Keyï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š projectKey å‚æ•°"
                )
        
        if not detected_project_key:
            return JiraCreateIssueOutput(
                issueKey=None, 
                url=None, 
                hint="å¿…é¡»æŒ‡å®š projectKey æˆ–å¯ç”¨ autoDetectFromBranch è‡ªåŠ¨æ£€æµ‹"
            )
        
        session = _get_jira_session()
        payload = {"fields": {"project": {"key": detected_project_key}, "issuetype": {"name": input.issueType}, "summary": input.summary, "description": input.description, "labels": input.labels}}
        # åˆå¹¶è‡ªå®šä¹‰å­—æ®µ
        payload["fields"].update(input.fields or {})
        url = _jira_api_url("issue")
        resp = session.post(url, json=payload, timeout=30)
        if resp.status_code >= 400:
            return JiraCreateIssueOutput(issueKey=None, url=None, hint=f"Jira create failed: {resp.status_code} {resp.text}")
        data = resp.json()
        issue_key = data.get("key")
        browse_base = os.getenv("JIRA_BROWSE_BASE", os.getenv("JIRA_BASE_URL", "").rstrip("/"))
        issue_url = f"{browse_base}/browse/{issue_key}" if issue_key else None
        return JiraCreateIssueOutput(issueKey=issue_key, url=issue_url, hint=f"Created via Jira REST API (project: {detected_project_key})")
    except Exception as exc:  # pragma: no cover
        return JiraCreateIssueOutput(issueKey=None, url=None, hint=f"Jira error: {exc}")


class JiraAttachFilesInput(BaseModel):
    """Jira ä¸Šä¼ é™„ä»¶çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraAttachFilesInput", description="Jira ä¸Šä¼ é™„ä»¶çš„è¾“å…¥å‚æ•°")
    issueKey: str = Field(..., description="ç›®æ ‡å·¥å• Key")
    filePaths: List[str] = Field(..., description="è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨")


@app.tool()
def jira_attach_files(input: JiraAttachFilesInput) -> JiraAttachFilesOutput:
    """å‘æŒ‡å®šå·¥å•ä¸Šä¼ é™„ä»¶ï¼ˆéœ€ X-Atlassian-Token:no-checkï¼‰ã€‚æ”¯æŒå¤šæ–‡ä»¶æ‰¹é‡ä¸Šä¼ ï¼Œå¹¶è¿”å›å¤±è´¥åŸå› ã€‚"""
    try:
        session = _get_jira_session()
        url = _jira_api_url(f"issue/{input.issueKey}/attachments")
        session.headers.update({"X-Atlassian-Token": "no-check"})
        attached: List[str] = []
        failed: List[Dict[str, Any]] = []
        for original_path in input.filePaths:
            p = Path(original_path)
            if not p.is_absolute():
                p = (PROJECT_ROOT / p).resolve()
            if not p.is_file():
                failed.append({"path": str(p), "reason": "file not found"})
                continue
            try:
                with open(p, "rb") as f:
                    files = {"file": (p.name, f)}
                    resp = session.post(url, files=files, timeout=60)
                if resp.status_code < 400:
                    attached.append(str(p))
                else:
                    failed.append({
                        "path": str(p),
                        "status": resp.status_code,
                        "reason": resp.text[:500]
                    })
            except Exception as file_exc:  # pragma: no cover
                failed.append({"path": str(p), "reason": str(file_exc)})
        hint = f"Uploaded {len(attached)} file(s), failed {len(failed)} via Jira REST API"
        return JiraAttachFilesOutput(attached=attached, failed=failed, hint=hint)
    except Exception as exc:  # pragma: no cover
        return JiraAttachFilesOutput(attached=[], failed=[{"error": str(exc)}], hint=f"Jira attach error")


class JiraLinkIssuesInput(BaseModel):
    """Jira å…³è”å·¥å•çš„è¾“å…¥å‚æ•°"""
    model_config = ConfigDict(title="JiraLinkIssuesInput", description="Jira å…³è”å·¥å•çš„è¾“å…¥å‚æ•°")
    inwardIssue: str = Field(..., description="å…³è”æ–¹å‘çš„å†…å‘å·¥å• Key")
    outwardIssue: str = Field(..., description="å…³è”æ–¹å‘çš„å¤–å‘å·¥å• Key")
    linkType: str = Field("relates to", description="å…³è”ç±»å‹ï¼šRelates/Blocks/Duplicate ç­‰")


class JiraLinkIssuesOutput(BaseModel):
    ok: bool
    hint: str


@app.tool()
def jira_link_issues(input: JiraLinkIssuesInput) -> JiraLinkIssuesOutput:
    """å…³è”ä¸¤ä¸ªå·¥å•ï¼ˆlinkType: Relates/Blocks/Duplicate ç­‰ï¼‰ã€‚"""
    try:
        session = _get_jira_session()
        url = _jira_api_url("issueLink")
        payload = {"type": {"name": input.linkType}, "inwardIssue": {"key": input.inwardIssue}, "outwardIssue": {"key": input.outwardIssue}}
        resp = session.post(url, json=payload, timeout=30)
        if resp.status_code >= 400:
            return JiraLinkIssuesOutput(ok=False, hint=f"Jira link failed: {resp.status_code} {resp.text}")
        return JiraLinkIssuesOutput(ok=True, hint="Linked via Jira REST API")
    except Exception as exc:  # pragma: no cover
        return JiraLinkIssuesOutput(ok=False, hint=f"Jira link error: {exc}")

# ---------- Jiraåˆ†æä¸æµ‹è¯•å¯¹æ¯”å·¥å…·å‡½æ•° ----------

@app.tool()
def jira_fetch_issue_with_analysis(input: JiraFetchInput) -> JiraFetchOutput:
    """æ‹‰å–Jiraå·¥å•åŠå­ä»»åŠ¡ä¿¡æ¯ï¼Œä¸‹è½½é™„ä»¶ï¼Œä¸ºåç»­åˆ†æå‡†å¤‡æ•°æ®ã€‚
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - å®Œæ•´çš„å·¥å•ä¿¡æ¯è·å–ï¼ˆä¸»è¦å­—æ®µå’Œè‡ªå®šä¹‰å­—æ®µï¼‰
    - å­ä»»åŠ¡é€’å½’è·å–
    - é™„ä»¶æ‰¹é‡ä¸‹è½½
    - å˜æ›´å†å²è¿½è¸ªï¼ˆå¯é€‰ï¼‰
    """
    try:
        session = _get_jira_session()
        
        # 1. è·å–ä¸»å·¥å•ä¿¡æ¯
        issue_url = _jira_api_url(f"issue/{input.issueKey}")
        issue_resp = session.get(issue_url, params={"expand": "changelog"} if input.includeHistory else {})
        
        if issue_resp.status_code >= 400:
            raise Exception(f"Failed to fetch issue {input.issueKey}: {issue_resp.status_code}")
            
        issue_data = issue_resp.json()
        fields = issue_data.get("fields", {})
        
        # æ„å»ºå·¥å•ä¿¡æ¯
        issue_info = JiraIssueInfo(
            key=issue_data.get("key", input.issueKey),
            summary=fields.get("summary", ""),
            description=fields.get("description", ""),
            status=fields.get("status", {}).get("name", "Unknown"),
            issueType=fields.get("issuetype", {}).get("name", "Unknown"),
            priority=fields.get("priority", {}).get("name", "Medium"),
            assignee=fields.get("assignee", {}).get("displayName") if fields.get("assignee") else None,
            reporter=fields.get("reporter", {}).get("displayName") if fields.get("reporter") else None,
            created=fields.get("created", ""),
            updated=fields.get("updated", ""),
            customFields={k: v for k, v in fields.items() if k.startswith("customfield_")}
        )
        
        subtasks = []
        attachments = []
        downloaded_files = []
        
        # 2. è·å–å­ä»»åŠ¡
        if input.includeSubtasks:
            subtask_links = fields.get("subtasks", [])
            for subtask_link in subtask_links:
                try:
                    subtask_key = subtask_link.get("key")
                    if subtask_key:
                        subtask_resp = session.get(_jira_api_url(f"issue/{subtask_key}"))
                        if subtask_resp.status_code < 400:
                            subtask_data = subtask_resp.json()
                            subtask_fields = subtask_data.get("fields", {})
                            
                            subtasks.append(JiraSubtask(
                                key=subtask_data.get("key", subtask_key),
                                summary=subtask_fields.get("summary", ""),
                                description=subtask_fields.get("description", ""),
                                status=subtask_fields.get("status", {}).get("name", "Unknown"),
                                assignee=subtask_fields.get("assignee", {}).get("displayName") if subtask_fields.get("assignee") else None
                            ))
                except Exception:
                    continue  # è·³è¿‡è·å–å¤±è´¥çš„å­ä»»åŠ¡
        
        # 3. å¤„ç†é™„ä»¶
        if input.includeAttachments:
            attachment_list = fields.get("attachment", [])
            
            # å‡†å¤‡ä¸‹è½½ç›®å½•
            project_root = Path(os.getcwd())  # é»˜è®¤é¡¹ç›®æ ¹ç›®å½•
            if input.attachmentPath:
                download_dir = project_root / input.attachmentPath / input.issueKey
            else:
                download_dir = project_root / "downloads" / "jira_attachments" / input.issueKey
            
            for attachment_info in attachment_list:
                try:
                    attachment = JiraAttachment(
                        id=str(attachment_info.get("id", "")),
                        filename=attachment_info.get("filename", ""),
                        size=attachment_info.get("size", 0),
                        mimeType=attachment_info.get("mimeType", ""),
                        author=attachment_info.get("author", {}).get("displayName", "Unknown"),
                        created=attachment_info.get("created", ""),
                        downloadUrl=attachment_info.get("content", "")
                    )
                    
                    # ä¸‹è½½é™„ä»¶
                    local_path = _download_jira_attachment(session, attachment_info, download_dir)
                    if local_path:
                        attachment.localPath = local_path
                        downloaded_files.append(local_path)
                    
                    attachments.append(attachment)
                    
                except Exception:
                    continue  # è·³è¿‡ä¸‹è½½å¤±è´¥çš„é™„ä»¶
        
        return JiraFetchOutput(
            issueInfo=issue_info,
            subtasks=subtasks,
            attachments=attachments,
            downloadedFiles=downloaded_files
        )
        
    except Exception as e:
        # è¿”å›åŸºæœ¬ä¿¡æ¯ï¼Œå³ä½¿éƒ¨åˆ†è·å–å¤±è´¥
        return JiraFetchOutput(
            issueInfo=JiraIssueInfo(
                key=input.issueKey,
                summary="Failed to fetch",
                description=f"Error: {str(e)}",
                status="Unknown",
                issueType="Unknown",
                priority="Medium",
                created="",
                updated=""
            ),
            subtasks=[],
            attachments=[],
            downloadedFiles=[]
        )

@app.tool()  
def analyze_requirements_vs_tests(input: TestAnalysisInput) -> TestAnalysisOutput:
    """åˆ†æJiraéœ€æ±‚ä¸ç°æœ‰æµ‹è¯•ç”¨ä¾‹çš„è¦†ç›–åº¦ï¼Œç”Ÿæˆæµ‹è¯•gapå’Œæ¨èã€‚
    
    åˆ†æç»´åº¦ï¼š
    - éœ€æ±‚è§£æï¼šä»Jiraæè¿°å’Œå­ä»»åŠ¡ä¸­æå–ç»“æ„åŒ–éœ€æ±‚
    - æµ‹è¯•åŒ¹é…ï¼šå°†éœ€æ±‚ä¸ç°æœ‰æµ‹è¯•ç”¨ä¾‹è¿›è¡ŒåŒ¹é…
    - è¦†ç›–åº¦è®¡ç®—ï¼šè®¡ç®—æ¯ä¸ªéœ€æ±‚çš„æµ‹è¯•è¦†ç›–ç¨‹åº¦
    - ç¼ºå¤±è¯†åˆ«ï¼šè¯†åˆ«æµ‹è¯•è¦†ç›–ä¸è¶³çš„éœ€æ±‚ç‚¹
    - æ™ºèƒ½æ¨èï¼šåŸºäºéœ€æ±‚ç±»å‹æ¨èåˆé€‚çš„æµ‹è¯•ç”¨ä¾‹
    """
    project_root = _resolve_project_root(input.projectRoot)
    
    # 1. é¦–å…ˆè·å–Jiraä¿¡æ¯
    jira_fetch_input = JiraFetchInput(
        issueKey=input.jiraIssueKey,
        includeSubtasks=True,
        includeAttachments=input.includeAttachments,
        attachmentPath="analysis_temp"
    )
    
    jira_data = jira_fetch_issue_with_analysis(jira_fetch_input)
    
    # 2. è§£æéœ€æ±‚
    requirements = []
    
    # ä»ä¸»å·¥å•æè¿°è§£æéœ€æ±‚
    main_requirements = _parse_requirements_from_text(jira_data.issueInfo.description, "main_issue")
    requirements.extend(main_requirements)
    
    # ä»å­ä»»åŠ¡è§£æéœ€æ±‚
    for i, subtask in enumerate(jira_data.subtasks):
        subtask_requirements = _parse_requirements_from_text(
            f"{subtask.summary}\n{subtask.description}", 
            f"subtask_{i+1}"
        )
        requirements.extend(subtask_requirements)
    
    # ä»é™„ä»¶è§£æéœ€æ±‚ï¼ˆå¦‚æœæ˜¯æ–‡æœ¬æ–‡ä»¶ï¼‰
    if input.includeAttachments:
        for attachment in jira_data.attachments:
            if attachment.localPath and attachment.mimeType.startswith("text/"):
                try:
                    attachment_path = Path(attachment.localPath)
                    if attachment_path.exists():
                        attachment_content = attachment_path.read_text(encoding="utf-8")
                        attachment_requirements = _parse_requirements_from_text(
                            attachment_content, 
                            f"attachment_{attachment.filename}"
                        )
                        requirements.extend(attachment_requirements)
                except Exception:
                    continue
    
    # 3. è·å–ç°æœ‰æµ‹è¯•ç”¨ä¾‹
    test_cases = []
    
    # ä»DevFlowä»»åŠ¡æ–‡æ¡£ä¸­è·å–æµ‹è¯•ç”¨ä¾‹
    process_dir = project_root / "Docs" / "ProcessDocuments" / f"task-{input.taskKey}"
    if process_dir.exists():
        # æŸ¥æ‰¾æµ‹è¯•ç›¸å…³æ–‡æ¡£
        test_files = [
            process_dir / f"{input.taskKey}_04-TestCurls.md",
            process_dir / f"{input.taskKey}_05-MySQLVerificationPlan.md",
            process_dir / f"{input.taskKey}_06-Integration.md",
        ]
        
        for test_file in test_files:
            if test_file.exists():
                file_test_cases = _extract_test_cases_from_file(test_file)
                test_cases.extend(file_test_cases)
    
    # 4. è®¡ç®—è¦†ç›–åº¦
    test_matches = _calculate_coverage(requirements, test_cases)
    
    # 5. ç”Ÿæˆæ¨è
    recommended_tests = _generate_test_recommendations(requirements, test_matches)
    
    # 6. è®¡ç®—æ•´ä½“è¦†ç›–åº¦
    if test_matches:
        overall_coverage = sum(match.coverage for match in test_matches) / len(test_matches)
    else:
        overall_coverage = 0.0
    
    # 7. è¯†åˆ«ç¼ºå¤±æµ‹è¯•
    missing_tests = []
    for match in test_matches:
        if match.coverage < 0.3:  # è¦†ç›–åº¦ä½äº30%çš„éœ€æ±‚
            req = next((r for r in requirements if r.id == match.requirementId), None)
            if req:
                missing_tests.append(f"{req.id}: {req.title}")
    
    # 8. ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report_dir = project_root / "Docs" / "ProcessDocuments" / f"task-{input.taskKey}"
    report_dir.mkdir(parents=True, exist_ok=True)
    report_path = report_dir / f"{input.taskKey}_TestAnalysisReport.md"
    
    report_content = f"""---
status: DRAFT
generatedAt: {_timestamp()}
jiraIssue: {input.jiraIssueKey}
analysisType: {input.analysisType}
---

# æµ‹è¯•è¦†ç›–åº¦åˆ†ææŠ¥å‘Š - {input.taskKey}

## å·¥å•ä¿¡æ¯
- **Jiraå·¥å•**: {input.jiraIssueKey}
- **æ ‡é¢˜**: {jira_data.issueInfo.summary}
- **çŠ¶æ€**: {jira_data.issueInfo.status}
- **ç±»å‹**: {jira_data.issueInfo.issueType}

## éœ€æ±‚åˆ†æ
**æ€»éœ€æ±‚æ•°**: {len(requirements)}

{chr(10).join(f"- **{req.id}** ({req.category}): {req.title}" for req in requirements)}

## æµ‹è¯•è¦†ç›–åº¦
**æ•´ä½“è¦†ç›–åº¦**: {overall_coverage:.1%}

### è¯¦ç»†è¦†ç›–æƒ…å†µ
{chr(10).join(f"- **{match.requirementId}**: {match.coverage:.1%} è¦†ç›– ({len(match.testCases)} ä¸ªç›¸å…³æµ‹è¯•)" for match in test_matches)}

## ç¼ºå¤±åˆ†æ
**ç¼ºå¤±æµ‹è¯•æ•°**: {len(missing_tests)}

{chr(10).join(f"- {missing}" for missing in missing_tests)}

## æ¨èæµ‹è¯•ç”¨ä¾‹
{chr(10).join(f"- {rec}" for rec in recommended_tests)}

## é™„ä»¶ä¿¡æ¯
{chr(10).join(f"- **{att.filename}** ({att.mimeType}) - {att.size} bytes" for att in jira_data.attachments)}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {_timestamp()}*
"""
    
    report_path.write_text(report_content, encoding="utf-8")
    
    return TestAnalysisOutput(
        taskKey=input.taskKey,
        jiraIssueKey=input.jiraIssueKey,
        requirements=requirements,
        testMatches=test_matches,
        overallCoverage=overall_coverage,
        missingTests=missing_tests,
        recommendedTests=recommended_tests,
        analysisReport=str(report_path)
    )

@app.tool()
def sync_jira_requirements(input: RequirementSyncInput) -> RequirementSyncOutput:
    """å°†Jiraéœ€æ±‚åŒæ­¥åˆ°DevFlowä»»åŠ¡ï¼Œå¯é€‰æ‹©è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚
    
    åŒæ­¥åŠŸèƒ½ï¼š
    - åˆ›å»ºæˆ–æ›´æ–°DevFlowä»»åŠ¡æ–‡æ¡£
    - åŒæ­¥éœ€æ±‚æè¿°å’ŒéªŒæ”¶æ ‡å‡†
    - æ›´æ–°å­ä»»åŠ¡çŠ¶æ€æ˜ å°„
    - å¯é€‰çš„è‡ªåŠ¨æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
    - å»ºç«‹éœ€æ±‚è¿½æº¯é“¾æ¥
    """
    project_root = _resolve_project_root(input.projectRoot)
    
    # 1. è·å–Jiraæ•°æ®
    jira_fetch_input = JiraFetchInput(
        issueKey=input.jiraIssueKey,
        includeSubtasks=True,
        includeAttachments=True
    )
    
    jira_data = jira_fetch_issue_with_analysis(jira_fetch_input)
    
    # 2. ç¡®å®šç›®æ ‡ä»»åŠ¡Key
    task_key = input.targetTaskKey
    if not task_key:
        # è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡Key
        task_key = f"JIRA-{input.jiraIssueKey.replace('-', '')}"
    
    created_files = []
    updated_files = []
    generated_tests = []
    
    # 3. åˆ›å»ºæˆ–æ›´æ–°ä¸»ä»»åŠ¡æ–‡æ¡£
    if input.syncMode in ["create", "update", "merge"]:
        task_input = PrepareDocsInput(
            taskKey=task_key,
            title=f"JiraåŒæ­¥: {jira_data.issueInfo.summary}",
            owner="system",
            reviewers=["qa", "dev"],
            force=(input.syncMode == "create")
        )
        
        task_result = task_prepare_docs(task_input)
        if task_result:
            created_files.append(task_result.mainDocPath)
    
    # 4. æ›´æ–°ä»»åŠ¡å†…å®¹
    main_doc_path = project_root / "Docs" / ".tasks" / f"{task_key}.md"
    if main_doc_path.exists():
        try:
            post = frontmatter.load(main_doc_path)
            metadata = dict(post.metadata or {})
            
            # æ·»åŠ Jiraå…³è”ä¿¡æ¯
            metadata["jiraIssue"] = input.jiraIssueKey
            metadata["jiraStatus"] = jira_data.issueInfo.status
            metadata["syncedAt"] = _timestamp()
            
            # æ›´æ–°å†…å®¹
            content_lines = [
                f"# {jira_data.issueInfo.summary}",
                "",
                "## éœ€æ±‚æ¥æº",
                f"- **Jiraå·¥å•**: {input.jiraIssueKey}",
                f"- **çŠ¶æ€**: {jira_data.issueInfo.status}",
                f"- **ç±»å‹**: {jira_data.issueInfo.issueType}",
                f"- **ä¼˜å…ˆçº§**: {jira_data.issueInfo.priority}",
                "",
                "## éœ€æ±‚æè¿°",
                jira_data.issueInfo.description or "æ— è¯¦ç»†æè¿°",
                "",
                "## å­ä»»åŠ¡",
            ]
            
            for subtask in jira_data.subtasks:
                content_lines.append(f"- **{subtask.key}**: {subtask.summary} ({subtask.status})")
            
            if jira_data.attachments:
                content_lines.extend([
                    "",
                    "## é™„ä»¶",
                ])
                for att in jira_data.attachments:
                    content_lines.append(f"- **{att.filename}** ({att.mimeType})")
            
            post.content = "\n".join(content_lines)
            post.metadata = metadata
            
            content_str = frontmatter.dumps(post)
            main_doc_path.write_text(content_str, encoding="utf-8")
            updated_files.append(str(main_doc_path))
            
        except Exception:
            pass
    
    # 5. è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if input.autoGenerateTests:
        analysis_input = TestAnalysisInput(
            taskKey=task_key,
            jiraIssueKey=input.jiraIssueKey,
            analysisType="recommendation",
            includeAttachments=True,
            projectRoot=input.projectRoot
        )
        
        analysis_result = analyze_requirements_vs_tests(analysis_input)
        
        # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ–‡æ¡£
        if analysis_result.recommendedTests:
            test_doc_path = project_root / "Docs" / "ProcessDocuments" / f"task-{task_key}" / f"{task_key}_RecommendedTests.md"
            test_doc_path.parent.mkdir(parents=True, exist_ok=True)
            
            test_content = f"""---
status: DRAFT
generatedAt: {_timestamp()}
source: jira_sync
---

# æ¨èæµ‹è¯•ç”¨ä¾‹ - {task_key}

## åŸºäºéœ€æ±‚åˆ†æçš„æµ‹è¯•ç”¨ä¾‹æ¨è

{chr(10).join(f"### æµ‹è¯•ç”¨ä¾‹ {i+1}: {test}" for i, test in enumerate(analysis_result.recommendedTests))}

## éœ€æ±‚è¦†ç›–åº¦åˆ†æ
- **æ•´ä½“è¦†ç›–åº¦**: {analysis_result.overallCoverage:.1%}
- **éœ€æ±‚æ€»æ•°**: {len(analysis_result.requirements)}
- **ç¼ºå¤±æµ‹è¯•**: {len(analysis_result.missingTests)}

è¯¦ç»†åˆ†ææŠ¥å‘Š: [æŸ¥çœ‹æŠ¥å‘Š]({analysis_result.analysisReport})
"""
            
            test_doc_path.write_text(test_content, encoding="utf-8")
            generated_tests.append(str(test_doc_path))
    
    # 6. ç”ŸæˆåŒæ­¥æŠ¥å‘Š
    sync_report_path = project_root / "Docs" / "ProcessDocuments" / f"task-{task_key}" / f"{task_key}_SyncReport.md"
    sync_report_path.parent.mkdir(parents=True, exist_ok=True)
    
    sync_report_content = f"""---
status: COMPLETED
syncedAt: {_timestamp()}
---

# JiraåŒæ­¥æŠ¥å‘Š - {task_key}

## åŒæ­¥ä¿¡æ¯
- **æºJiraå·¥å•**: {input.jiraIssueKey}
- **ç›®æ ‡ä»»åŠ¡**: {task_key}  
- **åŒæ­¥æ¨¡å¼**: {input.syncMode}
- **è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•**: {'æ˜¯' if input.autoGenerateTests else 'å¦'}

## åŒæ­¥ç»“æœ
- **åˆ›å»ºæ–‡ä»¶**: {len(created_files)} ä¸ª
- **æ›´æ–°æ–‡ä»¶**: {len(updated_files)} ä¸ª
- **ç”Ÿæˆæµ‹è¯•**: {len(generated_tests)} ä¸ª

### è¯¦ç»†æ–‡ä»¶æ¸…å•
**åˆ›å»ºçš„æ–‡ä»¶**:
{chr(10).join(f"- {f}" for f in created_files)}

**æ›´æ–°çš„æ–‡ä»¶**:
{chr(10).join(f"- {f}" for f in updated_files)}

**ç”Ÿæˆçš„æµ‹è¯•**:
{chr(10).join(f"- {f}" for f in generated_tests)}

## Jiraå·¥å•å¿«ç…§
- **æ ‡é¢˜**: {jira_data.issueInfo.summary}
- **çŠ¶æ€**: {jira_data.issueInfo.status}
- **å­ä»»åŠ¡æ•°**: {len(jira_data.subtasks)}
- **é™„ä»¶æ•°**: {len(jira_data.attachments)}

---
*åŒæ­¥å®Œæˆæ—¶é—´: {_timestamp()}*
"""
    
    sync_report_path.write_text(sync_report_content, encoding="utf-8")
    
    return RequirementSyncOutput(
        taskKey=task_key,
        jiraIssueKey=input.jiraIssueKey,
        createdFiles=created_files,
        updatedFiles=updated_files,
        generatedTests=generated_tests,
        syncReport=str(sync_report_path)
    )

# ---------- çŠ¶æ€ç®¡ç†å·¥å…·å‡½æ•° ----------

@app.tool()
def status_query(input: StatusQueryInput) -> StatusQueryOutput:
    """æŸ¥è¯¢ä»»åŠ¡çš„çŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…æ‹¬å½“å‰çŠ¶æ€ã€å…è®¸çš„è½¬æ¢ã€å†å²è®°å½•å’Œç»Ÿè®¡ä¿¡æ¯ã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    task_metadata = _get_task_metadata(project_root, input.taskKey)
    current_status = _read_task_status(project_root, input.taskKey)
    
    # è·å–å…è®¸çš„çŠ¶æ€è½¬æ¢
    allowed_transitions = _STATUS_TRANSITIONS.get(current_status, [])
    
    # è·å–å†å²è®°å½•
    history = None
    if input.includeHistory:
        history = task_metadata.get("reviews", [])
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        history = sorted(history, key=lambda x: x.get("time", ""), reverse=True)
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = None
    if input.includeStats:
        stats = task_metadata.get("statusStats", {})
        # æ·»åŠ ä¸€äº›æ´¾ç”Ÿç»Ÿè®¡
        if history:
            stats["historyCount"] = len(history)
            stats["averageTimeInStatus"] = {}  # å¯ä»¥åç»­è®¡ç®—
    
    return StatusQueryOutput(
        taskKey=input.taskKey,
        currentStatus=current_status,
        allowedTransitions=allowed_transitions,
        history=history,
        stats=stats
    )

@app.tool()
def status_batch_operation(input: StatusBatchInput) -> StatusBatchOutput:
    """æ‰¹é‡æ‰§è¡ŒçŠ¶æ€è½¬æ¢æ“ä½œã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    successful = []
    failed = []
    
    for i, op in enumerate(input.operations):
        try:
            # éªŒè¯æ“ä½œå‚æ•°
            task_key = op.get("taskKey")
            new_status = op.get("newStatus") 
            by = op.get("by")
            notes = op.get("notes", "")
            
            if not all([task_key, new_status, by]):
                raise ValueError("ç¼ºå°‘å¿…è¦å‚æ•°: taskKey, newStatus, by")
            
            # æ‰§è¡ŒçŠ¶æ€è½¬æ¢
            status_input = ReviewStatusInput(
                taskKey=task_key,
                newStatus=new_status,
                by=by,
                notes=notes,
                projectRoot=input.projectRoot
            )
            
            result = review_set_status(status_input)
            successful.append({
                "operation": i,
                "taskKey": task_key,
                "from": result.oldStatus,
                "to": result.newStatus,
                "by": by
            })
            
        except Exception as e:
            failed.append({
                "operation": i,
                "taskKey": op.get("taskKey", "unknown"),
                "error": str(e),
                "operation_data": op
            })
            
            if not input.continueOnError:
                break
    
    summary = {
        "total": len(input.operations),
        "successful": len(successful),
        "failed": len(failed)
    }
    
    return StatusBatchOutput(
        successful=successful,
        failed=failed,
        summary=summary
    )

@app.tool()
def status_report(input: StatusReportInput) -> StatusReportOutput:
    """ç”ŸæˆçŠ¶æ€æŠ¥å‘Šï¼ŒåŒ…æ‹¬æ‰€æœ‰ä»»åŠ¡çš„çŠ¶æ€ç»Ÿè®¡å’Œæ´»åŠ¨æ‘˜è¦ã€‚"""
    project_root = _resolve_project_root(input.projectRoot)
    tasks_dir = project_root / "Docs" / ".tasks"
    
    if not tasks_dir.exists():
        return StatusReportOutput(
            totalTasks=0,
            statusBreakdown={},
            recentActivity=[],
            blockedTasks=[],
            summary={"message": "æ²¡æœ‰æ‰¾åˆ°ä»»åŠ¡ç›®å½•"}
        )
    
    # æ‰«ææ‰€æœ‰ä»»åŠ¡æ–‡ä»¶
    task_files = list(tasks_dir.glob("*.md"))
    total_tasks = 0
    status_breakdown = {}
    recent_activity = []
    blocked_tasks = []
    
    for task_file in task_files:
        try:
            task_key = task_file.stem
            
            # è¯»å–ä»»åŠ¡å…ƒæ•°æ®
            post = frontmatter.load(task_file)
            metadata = post.metadata or {}
            current_status = metadata.get("status", "DRAFT")
            
            # åº”ç”¨è¿‡æ»¤å™¨
            if input.statusFilter and current_status not in input.statusFilter:
                continue
                
            if input.userFilter:
                owner = metadata.get("owner", "")
                reviewers = metadata.get("reviewers", [])
                if input.userFilter not in [owner] + list(reviewers):
                    continue
            
            total_tasks += 1
            status_breakdown[current_status] = status_breakdown.get(current_status, 0) + 1
            
            # æ”¶é›†æœ€è¿‘æ´»åŠ¨
            reviews = metadata.get("reviews", [])
            if reviews:
                latest_review = max(reviews, key=lambda x: x.get("time", ""))
                recent_activity.append({
                    "taskKey": task_key,
                    "action": f"{latest_review.get('from', 'UNKNOWN')} -> {latest_review.get('to', 'UNKNOWN')}",
                    "by": latest_review.get("by", "unknown"),
                    "time": latest_review.get("time", ""),
                    "notes": latest_review.get("notes", "")
                })
            
            # è¯†åˆ«é˜»å¡çš„ä»»åŠ¡
            if current_status == "CHANGES_REQUESTED":
                blocked_tasks.append({
                    "taskKey": task_key,
                    "status": current_status,
                    "owner": metadata.get("owner", "unknown"),
                    "lastUpdate": metadata.get("updatedAt", "unknown")
                })
                
        except Exception as e:
            # è·³è¿‡æ— æ³•è§£æçš„æ–‡ä»¶
            continue
    
    # æŒ‰æ—¶é—´æ’åºæœ€è¿‘æ´»åŠ¨
    recent_activity.sort(key=lambda x: x.get("time", ""), reverse=True)
    recent_activity = recent_activity[:20]  # åªå–æœ€è¿‘20æ¡
    
    summary = {
        "totalFiles": len(task_files),
        "validTasks": total_tasks,
        "mostCommonStatus": max(status_breakdown.items(), key=lambda x: x[1])[0] if status_breakdown else "N/A",
        "blockedCount": len(blocked_tasks),
        "recentActivityCount": len(recent_activity)
    }
    
    return StatusReportOutput(
        totalTasks=total_tasks,
        statusBreakdown=status_breakdown,
        recentActivity=recent_activity,
        blockedTasks=blocked_tasks,
        summary=summary
    )

if __name__ == "__main__":
    # ä»¥ stdio æ–¹å¼å¯åŠ¨ MCPï¼ˆFastMCP ä¼šå¤„ç†åè®®ç»†èŠ‚ï¼‰
    app.run()
